{
    "metadata": {
        "description": "AI Models API - Models from AIHubMix",
        "lastUpdated": "2026-01-13T20:03:21.308Z",
        "provider": "AIHubMix",
        "totalModels": 597,
        "version": "0.0.0-development"
    },
    "models": [
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1,
                "inputCacheHit": null,
                "output": 3,
                "videoGeneration": null
            },
            "description": "Phi-3.5-mini is a lightweight, state-of-the-art open model built upon the dataset used for Phi-3—which includes synthetic data and carefully curated publicly available websites—focusing on very high-quality, reasoning-intensive data. This model is part of the Phi-3 model family and supports a context length of 128K tokens.",
            "extendedThinking": false,
            "id": "ahm-Phi-3-5-mini-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ahm-Phi-3-5-mini-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.4,
                "inputCacheHit": null,
                "output": 1.6,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "ahm-Phi-3-5-MoE-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ahm-Phi-3-5-MoE-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.4,
                "inputCacheHit": null,
                "output": 1.6,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "ahm-Phi-3-5-vision-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "ahm-Phi-3-5-vision-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 6,
                "inputCacheHit": null,
                "output": 18,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "ahm-Phi-3-medium-128k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ahm-Phi-3-medium-128k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1,
                "inputCacheHit": null,
                "output": 3,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "ahm-Phi-3-medium-4k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ahm-Phi-3-medium-4k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1,
                "inputCacheHit": null,
                "output": 3,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "ahm-Phi-3-small-128k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ahm-Phi-3-small-128k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.4,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": null
            },
            "description": "Mistral Medium 3 is a SOTA & versatile model designed for a wide range of tasks, including programming, mathematical reasoning, understanding long documents, summarization, and dialogue.\n\nIt boasts multi-modal capabilities, enabling it to process visual inputs, and supports dozens of languages, including over 80 coding languages. Additionally, it features function calling and agentic workflows.\n\nMistral Medium 3 is optimized for single-node inference, particularly for long-context applications. Its size allows it to achieve high throughput on a single node.",
            "extendedThinking": false,
            "id": "AiHubmix-mistral-medium",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "AiHubmix-mistral-medium",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.12,
                "inputCacheHit": null,
                "output": 0.12,
                "videoGeneration": null
            },
            "description": "Phi-4-mini-reasoning is a lightweight open model designed for advanced mathematical reasoning and logic-intensive problem-solving. It is particularly well-suited for tasks such as formal proofs, symbolic computation, and solving multi-step word problems. With its efficient architecture, the model balances high-quality reasoning performance with cost-effective deployment, making it ideal for educational applications, embedded tutoring, and lightweight edge or mobile systems.\n\nPhi-4-mini-reasoning supports a 128K token context length, enabling it to process and reason over long mathematical problems and proofs. Built on synthetic and high-quality math datasets, the model leverages advanced fine-tuning techniques such as supervised fine-tuning and preference modeling to enhance reasoning capabilities. Its training incorporates safety and alignment protocols, ensuring robust and reliable performance across supported use cases.",
            "extendedThinking": false,
            "id": "AiHubmix-Phi-4-mini-reasoning",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "AiHubmix-Phi-4-mini-reasoning",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2,
                "videoGeneration": null
            },
            "description": "Phi-4-Reasoning is a state-of-the-art open-weight reasoning model finetuned from Phi-4 using supervised fine-tuning on a dataset of chain-of-thought traces and reinforcement learning. The supervised fine-tuning dataset includes a blend of synthetic prompts and high-quality filtered data from public domain websites, focused on math, science, and coding skills as well as alignment data for safety and Responsible AI. The goal of this approach was to ensure that small capable models were trained with data focused on high quality and advanced reasoning.",
            "extendedThinking": true,
            "id": "AiHubmix-Phi-4-reasoning",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "AiHubmix-Phi-4-reasoning",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.12,
                "inputCacheHit": null,
                "output": 0.48,
                "videoGeneration": null
            },
            "description": "Phi-4 is a state-of-the-art open model based on a combination of synthetic datasets, curated public domain website data, and acquired academic books and QA datasets. The approach aims to ensure that small, efficient models are trained using data focused on high quality and advanced reasoning.",
            "extendedThinking": false,
            "id": "aihub-Phi-4",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16400,
                "output": 16400
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "aihub-Phi-4",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.12,
                "inputCacheHit": null,
                "output": 0.48,
                "videoGeneration": null
            },
            "description": "Microsoft's latest model",
            "extendedThinking": false,
            "id": "aihub-Phi-4-mini-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "aihub-Phi-4-mini-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.12,
                "inputCacheHit": null,
                "output": 0.48,
                "videoGeneration": null
            },
            "description": "Microsoft's latest model",
            "extendedThinking": false,
            "id": "aihub-Phi-4-multimodal-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4000
            },
            "modalities": {
                "input": ["text", "image", "audio"],
                "output": ["text"]
            },
            "name": "aihub-Phi-4-multimodal-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.4,
                "inputCacheHit": null,
                "output": 1.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "aihubmix-Codestral-2501",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "aihubmix-Codestral-2501",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.64,
                "inputCacheHit": null,
                "output": 1.92,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "aihubmix-Cohere-command-r",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "aihubmix-Cohere-command-r",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.8,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "aihubmix-command-r-08-2024",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "aihubmix-command-r-08-2024",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 3.84,
                "inputCacheHit": null,
                "output": 19.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "aihubmix-command-r-plus",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "aihubmix-command-r-plus",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2.8,
                "inputCacheHit": null,
                "output": 11.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "aihubmix-command-r-plus-08-2024",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "aihubmix-command-r-plus-08-2024",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2.2,
                "inputCacheHit": null,
                "output": 8.8,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "aihubmix-Jamba-1-5-Large",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "aihubmix-Jamba-1-5-Large",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 5,
                "inputCacheHit": null,
                "output": 15,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "aihubmix-Llama-3-1-405B-Instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "aihubmix-Llama-3-1-405B-Instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.6,
                "inputCacheHit": null,
                "output": 0.78,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "aihubmix-Llama-3-1-70B-Instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "aihubmix-Llama-3-1-70B-Instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.3,
                "inputCacheHit": null,
                "output": 0.6,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "aihubmix-Llama-3-1-8B-Instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "aihubmix-Llama-3-1-8B-Instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.4,
                "inputCacheHit": null,
                "output": 0.4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "aihubmix-Llama-3-2-11B-Vision",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "aihubmix-Llama-3-2-11B-Vision",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2.4,
                "inputCacheHit": null,
                "output": 2.4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "aihubmix-Llama-3-2-90B-Vision",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "aihubmix-Llama-3-2-90B-Vision",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.7,
                "inputCacheHit": null,
                "output": 0.7,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "aihubmix-Llama-3-70B-Instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "aihubmix-Llama-3-70B-Instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.6,
                "inputCacheHit": null,
                "output": 1.8,
                "videoGeneration": null
            },
            "description": "MAI-DS-R1 is a refined version of DeepSeek-R1 by Microsoft AI, designed to improve responsiveness to previously blocked topics while enhancing safety. It integrates 110k Tulu-3 SFT samples and 350k multilingual safety-alignment examples. The model retains strong reasoning and coding abilities, surpasses R1-1776 in handling sensitive queries, and reduces harmful content leakage. Based on a transformer MoE architecture, it suits general-purpose tasks—excluding legal, medical, or autonomous systems.",
            "extendedThinking": false,
            "id": "Aihubmix-MAI-DS-R1",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Aihubmix-MAI-DS-R1",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 4,
                "inputCacheHit": null,
                "output": 12,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "aihubmix-Mistral-large",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "aihubmix-Mistral-large",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 3,
                "inputCacheHit": null,
                "output": 9,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "aihubmix-Mistral-large-2407",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "aihubmix-Mistral-large-2407",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 6,
                "videoGeneration": null
            },
            "description": "The latest Mistral Large 2 model is deployed on Azure.",
            "extendedThinking": false,
            "id": "aihubmix-Mistral-Large-2411",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "aihubmix-Mistral-Large-2411",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.4,
                "inputCacheHit": 0.1,
                "output": 1.6,
                "videoGeneration": null
            },
            "description": "New model routing capability; request aihubmix-router to automatically route models based on question complexity, so everyone no longer needs to manually switch models; in our tests comparing the use of the model router versus only using GPT-4.1, we observed up to 60% cost savings while maintaining similar accuracy.  \nThe context length of the model router depends on the base model used for each prompt. Input size is 200,000, output size is 32,768.  \nCurrently, there are four routing models: gpt-4.1, gpt-4.1-mini, gpt-4.1-nano, o4-mini.  \nPricing: Due to our current billing structure system, requests through aihubmix-router are billed at the price of gpt-4.1-mini regardless of which final model is used; future billing will be based on the actual model invoked.  \nEveryone is welcome to try it out; the interface will return the name of the actual called model.",
            "extendedThinking": false,
            "id": "aihubmix-router",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "aihubmix-router",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1,
                "inputCacheHit": 0.25,
                "output": 0.4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "aistudio_gemini-2.0-flash",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "aistudio_gemini-2.0-flash",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.4,
                "inputCacheHit": 0.1,
                "output": 1.6,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "aistudio_gpt-4.1-mini",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "aistudio_gpt-4.1-mini",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.58,
                "inputCacheHit": null,
                "output": 1.680028,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "azure-deepseek-v3.2",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "azure-deepseek-v3.2",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.58,
                "inputCacheHit": null,
                "output": 1.680028,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "azure-deepseek-v3.2-speciale",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "azure-deepseek-v3.2-speciale",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.034,
                "inputCacheHit": null,
                "output": 0.034,
                "videoGeneration": null
            },
            "description": "BAAI/bge-large-en-v1.5 is a large English text embedding model and part of the BGE (BAAI General Embedding) series. It achieves excellent performance on the MTEB benchmark, with an average score of 64.23 across 56 datasets, excelling in tasks such as retrieval, clustering, and text pair classification. The model supports a maximum input length of 512 tokens and is suitable for various natural language processing tasks, such as text retrieval and semantic similarity computation.",
            "extendedThinking": false,
            "id": "BAAI/bge-large-en-v1.5",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["embedding"]
            },
            "name": "BAAI/bge-large-en-v1.5",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.034,
                "inputCacheHit": null,
                "output": 0.034,
                "videoGeneration": null
            },
            "description": "BAAI/bge-large-zh-v1.5 is a large Chinese text embedding model and part of the BGE (BAAI General Embedding) series. It performs excellently on the C-MTEB benchmark, achieving an average score of 64.53 across 31 datasets, with outstanding results in tasks such as retrieval, semantic similarity, and text pair classification. The model supports a maximum input length of 512 tokens and is suitable for various Chinese natural language processing tasks, such as text retrieval and semantic similarity computation.",
            "extendedThinking": false,
            "id": "BAAI/bge-large-zh-v1.5",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["embedding"]
            },
            "name": "BAAI/bge-large-zh-v1.5",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.034,
                "inputCacheHit": null,
                "output": 0.034,
                "videoGeneration": null
            },
            "description": "BAAI/bge-reranker-v2-m3 is a lightweight multilingual reranking model. It is developed based on the bge-m3 model, offering strong multilingual capabilities, easy deployment, and fast inference. The model takes a query and documents as input and directly outputs similarity scores instead of embedding vectors. It is suitable for multilingual scenarios and performs particularly well in both Chinese and English processing.",
            "extendedThinking": false,
            "id": "BAAI/bge-reranker-v2-m3",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["score"]
            },
            "name": "BAAI/bge-reranker-v2-m3",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.274,
                "inputCacheHit": null,
                "output": 1.096,
                "videoGeneration": null
            },
            "description": "The Qwen3 series open-source models include hybrid models, thinking models, and non-thinking models, with both reasoning capabilities and general abilities reaching industry SOTA levels at the same scale.",
            "extendedThinking": false,
            "id": "bai-qwen3-vl-235b-a22b-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "bai-qwen3-vl-235b-a22b-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.9,
                "inputCacheHit": null,
                "output": 1.9,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Baichuan3-Turbo",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Baichuan3-Turbo",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 3.8,
                "inputCacheHit": null,
                "output": 3.8,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Baichuan3-Turbo-128k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Baichuan3-Turbo-128k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 16,
                "inputCacheHit": null,
                "output": 16,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Baichuan4",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Baichuan4",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.16,
                "inputCacheHit": null,
                "output": 0.16,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Baichuan4-Air",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Baichuan4-Air",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2.4,
                "inputCacheHit": null,
                "output": 2.4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Baichuan4-Turbo",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Baichuan4-Turbo",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.274,
                "inputCacheHit": null,
                "output": 0.411,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "baidu-deepseek-v3.2",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "baidu-deepseek-v3.2",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.274,
                "inputCacheHit": 0.0274,
                "output": 0.411,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "baidu-deepseek-v3.2-exp",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "baidu-deepseek-v3.2-exp",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.32,
                "inputCacheHit": 0,
                "output": 1.28,
                "videoGeneration": null
            },
            "description": "ERNIE-4.5-300B-A47B is a large language model developed by Baidu based on a Mixture of Experts (MoE) architecture. The model has a total of 300 billion parameters, but only activates 47 billion parameters per token during inference, which balances strong performance with computational efficiency. As one of the core models in the ERNIE 4.5 series, it demonstrates outstanding capabilities in tasks such as text understanding, generation, reasoning, and programming. The model employs an innovative multimodal heterogeneous MoE pretraining approach, leveraging joint training of textual and visual modalities to effectively enhance the model’s overall abilities, particularly excelling in instruction following and world knowledge memorization. Baidu has open-sourced this model along with other models in the series, aiming to promote the research and application of AI technology.",
            "extendedThinking": false,
            "id": "baidu/ERNIE-4.5-300B-A47B",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 123000,
                "output": 12000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "baidu/ERNIE-4.5-300B-A47B",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2025-06-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.068,
                "inputCacheHit": null,
                "output": 0.068,
                "videoGeneration": null
            },
            "description": "Based on the dense foundational model of the Qwen3 series, it is specifically designed for ranking tasks. It inherits the base model’s outstanding multilingual capabilities, long-text understanding, and reasoning skills, achieving significant advancements in ranking tasks.",
            "extendedThinking": false,
            "id": "bce-reranker-base",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["score"]
            },
            "name": "bce-reranker-base",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.068,
                "inputCacheHit": null,
                "output": 0.068,
                "videoGeneration": null
            },
            "description": "bge-large-en, open-sourced by the Beijing Academy of Artificial Intelligence (BAAI), is currently the most powerful vector representation model for Chinese tasks, with its semantic representation capabilities comprehensively surpassing those of similar open-source models.",
            "extendedThinking": false,
            "id": "bge-large-en",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["embedding"]
            },
            "name": "bge-large-en",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.534,
                "videoGeneration": null
            },
            "description": "Seed-OSS is a series of open-source large language models developed by ByteDance's Seed team, designed specifically for powerful long-context processing, reasoning, agents, and general capabilities. Among this series, Seed-OSS-36B-Instruct is an instruction-tuned model with 36 billion parameters that natively supports ultra-long context lengths, enabling it to process massive documents or complex codebases in a single pass. This model is specially optimized for reasoning, code generation, and agent tasks (such as tool usage), while maintaining balanced and excellent general capabilities. A notable feature of this model is the \"Thinking Budget\" functionality, which allows users to flexibly adjust the inference length as needed, thereby effectively improving inference efficiency in practical applications.",
            "extendedThinking": false,
            "id": "ByteDance-Seed/Seed-OSS-36B-Instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 32000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "ByteDance-Seed/Seed-OSS-36B-Instruct",
            "openWeights": true,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2.25,
                "inputCacheHit": null,
                "output": 2.749995,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "cbs-glm-4.7",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cbs-glm-4.7",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.3,
                "inputCacheHit": null,
                "output": 0.3,
                "videoGeneration": null
            },
            "description": "For Claude code only",
            "extendedThinking": false,
            "id": "cc-deepseek-v3",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cc-deepseek-v3",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.56,
                "inputCacheHit": null,
                "output": 1.68,
                "videoGeneration": null
            },
            "description": "For Claude code only",
            "extendedThinking": false,
            "id": "cc-deepseek-v3.1",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cc-deepseek-v3.1",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2,
                "videoGeneration": null
            },
            "description": "claude code ",
            "extendedThinking": false,
            "id": "cc-doubao-seed-code-preview-latest",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cc-doubao-seed-code-preview-latest",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.32,
                "inputCacheHit": 0,
                "output": 1.28,
                "videoGeneration": null
            },
            "description": "For Claude code only",
            "extendedThinking": false,
            "id": "cc-ernie-4.5-300b-a47b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "cc-ernie-4.5-300b-a47b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.06,
                "inputCacheHit": null,
                "output": 0.22,
                "videoGeneration": null
            },
            "description": "for claude code",
            "extendedThinking": false,
            "id": "cc-glm-4.6",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cc-glm-4.6",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.06,
                "inputCacheHit": null,
                "output": 0.22,
                "videoGeneration": null
            },
            "description": "Supports Claude native interface, can be directly requested in Claude Code.",
            "extendedThinking": false,
            "id": "cc-glm-4.7",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cc-glm-4.7",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.32,
                "inputCacheHit": 0,
                "output": 1.28,
                "videoGeneration": null
            },
            "description": "For Claude code only",
            "extendedThinking": false,
            "id": "cc-kimi-dev-72b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cc-kimi-dev-72b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": 0.02,
                "output": 0.2,
                "videoGeneration": null
            },
            "description": "for claude code",
            "extendedThinking": false,
            "id": "cc-kimi-for-coding",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cc-kimi-for-coding",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.1,
                "inputCacheHit": null,
                "output": 3.3,
                "videoGeneration": null
            },
            "description": "For Claude code only",
            "extendedThinking": false,
            "id": "cc-kimi-k2-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cc-kimi-k2-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.1,
                "inputCacheHit": null,
                "output": 3.3,
                "videoGeneration": null
            },
            "description": "For Claude code only",
            "extendedThinking": false,
            "id": "cc-kimi-k2-instruct-0905",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cc-kimi-k2-instruct-0905",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.548,
                "inputCacheHit": null,
                "output": 2.192,
                "videoGeneration": null
            },
            "description": "Dedicated for Claude Code",
            "extendedThinking": false,
            "id": "cc-kimi-k2-thinking",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cc-kimi-k2-thinking",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1,
                "videoGeneration": null
            },
            "description": "For Claude Code only",
            "extendedThinking": false,
            "id": "cc-MiniMax-M2",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cc-MiniMax-M2",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1,
                "videoGeneration": null
            },
            "description": "For Claude Code only",
            "extendedThinking": false,
            "id": "cc-minimax-m2",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cc-minimax-m2",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1,
                "videoGeneration": null
            },
            "description": "For Claude Code only",
            "extendedThinking": false,
            "id": "cc-minimax-m2.1",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cc-minimax-m2.1",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.6,
                "inputCacheHit": null,
                "output": 0.6,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "cerebras-llama-3.3-70b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cerebras-llama-3.3-70b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2858,
                "inputCacheHit": null,
                "output": 0.2858,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "chatglm_lite",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "chatglm_lite",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.4286,
                "inputCacheHit": null,
                "output": 1.4286,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "chatglm_pro",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "chatglm_pro",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.7144,
                "inputCacheHit": null,
                "output": 0.7144,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "chatglm_std",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "chatglm_std",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.7144,
                "inputCacheHit": null,
                "output": 0.7144,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "chatglm_turbo",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "chatglm_turbo",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 5,
                "inputCacheHit": null,
                "output": 15,
                "videoGeneration": null
            },
            "description": "This model will point to the latest GPT-4o model used by ChatGPT.",
            "extendedThinking": false,
            "id": "chatgpt-4o-latest",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "chatgpt-4o-latest",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 8.8,
                "inputCacheHit": null,
                "output": 8.8,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "claude-2",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "claude-2",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 8.8,
                "inputCacheHit": null,
                "output": 39.6,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "claude-2.0",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "claude-2.0",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 8.8,
                "inputCacheHit": null,
                "output": 39.6,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "claude-2.1",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "claude-2.1",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.1,
                "inputCacheHit": null,
                "output": 5.5,
                "videoGeneration": null
            },
            "description": "Claude 3.5 Haiku is the next generation of Claude's fastest model.",
            "extendedThinking": false,
            "id": "claude-3-5-haiku",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "claude-3-5-haiku",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix",
            "providerModelsDevId": "google-vertex-partner"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 3.3,
                "inputCacheHit": null,
                "output": 16.5,
                "videoGeneration": null
            },
            "description": "Claude 3.5 Sonnet delivers performance superior to Opus and speeds faster than its predecessor, all at the same price point. Its core strengths include:\n\nCoding: Autonomously writes, edits, and executes code with advanced reasoning and troubleshooting.\nData Science: Augments human expertise by analyzing unstructured data and using multiple tools to generate insights.\nVisual Processing: Excels at interpreting charts, graphs, and images, accurately transcribing text to derive high-level insights.\nAgentic Tasks: Exceptional tool use makes it highly effective for complex, multi-step agentic workflows that interact with other systems.",
            "extendedThinking": false,
            "id": "claude-3-5-sonnet",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "claude-3-5-sonnet",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix",
            "providerModelsDevId": "google-vertex-partner"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 3.3,
                "inputCacheHit": null,
                "output": 16.5,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "claude-3-5-sonnet@20240620",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "claude-3-5-sonnet@20240620",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 3.3,
                "inputCacheHit": null,
                "output": 16.5,
                "videoGeneration": null
            },
            "description": "Claude 3.5 Sonnet delivers performance superior to Opus and speeds faster than its predecessor, all at the same price point. Its core strengths include:\n\nCoding: Autonomously writes, edits, and executes code with advanced reasoning and troubleshooting.\nData Science: Augments human expertise by analyzing unstructured data and using multiple tools to generate insights.\nVisual Processing: Excels at interpreting charts, graphs, and images, accurately transcribing text to derive high-level insights.\nAgentic Tasks: Exceptional tool use makes it highly effective for complex, multi-step agentic workflows that interact with other systems.",
            "extendedThinking": false,
            "id": "claude-3-5-sonnet-20240620",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "claude-3-5-sonnet-20240620",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 3.3,
                "inputCacheHit": null,
                "output": 16.5,
                "videoGeneration": null
            },
            "description": "Support for the thinking parameter through the original Claude SDK.",
            "extendedThinking": true,
            "id": "claude-3-7-sonnet",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "claude-3-7-sonnet",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix",
            "providerModelsDevId": "google-vertex-partner"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.275,
                "inputCacheHit": null,
                "output": 1.375,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "claude-3-haiku@20240307",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "claude-3-haiku@20240307",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.275,
                "inputCacheHit": null,
                "output": 0.275,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "claude-3-haiku-20240229",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "claude-3-haiku-20240229",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.275,
                "inputCacheHit": null,
                "output": 1.375,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "claude-3-haiku-20240307",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "claude-3-haiku-20240307",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 16.5,
                "inputCacheHit": null,
                "output": 82.5,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "claude-3-opus@20240229",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "claude-3-opus@20240229",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 16.5,
                "inputCacheHit": null,
                "output": 82.5,
                "videoGeneration": null
            },
            "description": "Claude’s previous generation strongest model",
            "extendedThinking": false,
            "id": "claude-3-opus-20240229",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "claude-3-opus-20240229",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 3.3,
                "inputCacheHit": null,
                "output": 16.5,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "claude-3-sonnet-20240229",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "claude-3-sonnet-20240229",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.793,
                "inputCacheHit": null,
                "output": 1.793,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "claude-instant-1",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "claude-instant-1",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.88,
                "inputCacheHit": null,
                "output": 3.96,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "claude-instant-1.2",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "claude-instant-1.2",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 16.5,
                "inputCacheHit": null,
                "output": 82.5,
                "videoGeneration": null
            },
            "description": "Alias \nclaude-opus-4-20250514",
            "extendedThinking": false,
            "id": "claude-opus-4-0",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 32000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "claude-opus-4-0",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 3.3,
                "inputCacheHit": 0.33,
                "output": 16.5,
                "videoGeneration": null
            },
            "description": "Claude Sonnet 4 is a significant upgrade to Sonnet 3.7, delivering superior performance in coding and reasoning with enhanced precision and control. Achieving a state-of-the-art 72.7% on SWE-bench, the model expertly balances advanced capability with computational efficiency. Key improvements include more reliable codebase navigation and complex instruction following, making it ideal for a wide range of applications, from routine coding to complex software development projects.",
            "extendedThinking": true,
            "id": "claude-sonnet-4-0",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1000000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "claude-sonnet-4-0",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 20,
                "inputCacheHit": null,
                "output": 20,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "code-davinci-edit-001",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "code-davinci-edit-001",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.4,
                "inputCacheHit": null,
                "output": 1.2,
                "videoGeneration": null
            },
            "description": "Mistral has launched a new code model - Codestral 25.01; https://mistral.ai/news/codestral-2501/",
            "extendedThinking": false,
            "id": "codestral-latest",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "codestral-latest",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.014,
                "inputCacheHit": null,
                "output": 0.084,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "coding-glm-4.5-air",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "coding-glm-4.5-air",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.06,
                "inputCacheHit": 0.010998,
                "output": 0.22,
                "videoGeneration": null
            },
            "extendedThinking": true,
            "id": "coding-glm-4.6",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "coding-glm-4.6",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0,
                "inputCacheHit": 0,
                "output": 0,
                "videoGeneration": null
            },
            "description": "coding-glm-4.6-free is the open and free version of coding-glm-4.6. To ensure stable service performance, usage limits are in place: up to 5 requests per minute, 500 requests per day, and a daily token allowance of 1 million.",
            "extendedThinking": true,
            "id": "coding-glm-4.6-free",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 128000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "coding-glm-4.6-free",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.06,
                "inputCacheHit": 0.010998,
                "output": 0.22,
                "videoGeneration": null
            },
            "description": "Only supports OpenAI-compatible formats.",
            "extendedThinking": true,
            "id": "coding-glm-4.7",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "coding-glm-4.7",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0,
                "inputCacheHit": 0,
                "output": 0,
                "videoGeneration": null
            },
            "description": "coding-glm-4.7-free is the open and free version of coding-glm-4.7. To ensure stable service performance, usage limits are in place: up to 5 requests per minute, 500 requests per day, and a daily token allowance of 1 million.",
            "extendedThinking": true,
            "id": "coding-glm-4.7-free",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "coding-glm-4.7-free",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2,
                "videoGeneration": null
            },
            "description": "coding-minimax-m2 is a free and open version offered by AIHubMix specifically for MiniMax users. To maintain stable service operations, the following usage limits apply: a maximum of 10 requests per minute, 1,000 total requests per day, and a daily quota of 5 million tokens.204800",
            "extendedThinking": true,
            "id": "coding-minimax-m2",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 204800,
                "output": 13100
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "coding-minimax-m2",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2,
                "videoGeneration": null
            },
            "extendedThinking": true,
            "id": "coding-minimax-m2.1",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 204800,
                "output": 13100
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "coding-minimax-m2.1",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0,
                "inputCacheHit": null,
                "output": 0,
                "videoGeneration": null
            },
            "description": "coding-minimax-m2.1-free is a free and open version offered by AIHubMix specifically for MiniMax users. To maintain stable service operations, the following usage limits apply: a maximum of 5 requests per minute, 500 total requests per day, and a daily quota of 1 million tokens.",
            "extendedThinking": false,
            "id": "coding-minimax-m2.1-free",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 204800,
                "output": 13100
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "coding-minimax-m2.1-free",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0,
                "inputCacheHit": 0,
                "output": 0,
                "videoGeneration": null
            },
            "description": "coding-minimax-m2-free is a free and open version offered by AIHubMix specifically for MiniMax users. To maintain stable service operations, the following usage limits apply: a maximum of 5 requests per minute, 500 total requests per day, and a daily quota of 1 million tokens.",
            "extendedThinking": true,
            "id": "coding-minimax-m2-free",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 204800,
                "output": 13100
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "coding-minimax-m2-free",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 35.5,
                "inputCacheHit": null,
                "output": 35.5,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "cogview-3",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cogview-3",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 10,
                "inputCacheHit": null,
                "output": 10,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "cogview-3-plus",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cogview-3-plus",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "command",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "command",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2.5,
                "inputCacheHit": 0,
                "output": 10,
                "videoGeneration": null
            },
            "description": "Command A is Cohere most performant model to date, excelling at tool use, agents, retrieval augmented generation (RAG), and multilingual use cases. Command A has a context length of 256K, only requires two GPUs to run, and has 150% higher throughput compared to Command R+ 08-2024.",
            "extendedThinking": false,
            "id": "command-a-03-2025",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "command-a-03-2025",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "command-light",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "command-light",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "command-light-nightly",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "command-light-nightly",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "command-nightly",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "command-nightly",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.64,
                "inputCacheHit": null,
                "output": 1.92,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "command-r",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "command-r",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.8,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "command-r-08-2024",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "command-r-08-2024",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 3.84,
                "inputCacheHit": null,
                "output": 19.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "command-r-plus",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "command-r-plus",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2.8,
                "inputCacheHit": null,
                "output": 11.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "command-r-plus-08-2024",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "command-r-plus-08-2024",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 3,
                "inputCacheHit": null,
                "output": 12,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "computer-use-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "computer-use-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0,
                "inputCacheHit": null,
                "output": 0,
                "videoGeneration": null
            },
            "description": "just for crush",
            "extendedThinking": false,
            "id": "crush-glm-4.6-free",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "crush-glm-4.6-free",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 16,
                "input": 16,
                "inputCacheHit": null,
                "output": 16,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "dall-e-2",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "dall-e-2",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 40,
                "input": 40,
                "inputCacheHit": null,
                "output": 40,
                "videoGeneration": null
            },
            "description": "dall-e-3 is an AI image generation model that converts natural language prompts into realistic visuals and artistic content. It delivers accurate semantic understanding, supports customizable output resolutions, and produces high-quality images across a wide range of styles, making it well-suited for concept design, creative prototyping, and professional content workflows.",
            "extendedThinking": false,
            "id": "dall-e-3",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "dall-e-3",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 20,
                "inputCacheHit": null,
                "output": 20,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "davinci",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "davinci",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "davinci-002",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "davinci-002",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.02,
                "inputCacheHit": null,
                "output": 0.02,
                "videoGeneration": null
            },
            "description": "DeepSeek-OCR is a vision-language model launched by DeepSeek AI, focusing on optical character recognition (OCR) and “contextual optical compression.” The model is designed to explore the limits of compressing contextual information from images, efficiently processing documents and converting them into structured text formats such as Markdown. The model requires an image as input.",
            "extendedThinking": false,
            "id": "DeepSeek-OCR",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "DeepSeek-OCR",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.4,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": null
            },
            "description": "DeepSeek R1 is a new open-source model with performance on par with OpenAI's o1 and features fully open reasoning tokens. It is a 671B-parameter Mixture-of-Experts (MoE) model that activates 37B parameters during inference.",
            "extendedThinking": false,
            "id": "DeepSeek-R1",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1638000,
                "output": 1638000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2025-01-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.28,
                "inputCacheHit": null,
                "output": 0.84,
                "videoGeneration": null
            },
            "description": "The model provider is the Sophnet platform. Deepseek-R1-Distill-Qwen-32B is a knowledge-distilled large language model based on Qwen 2.5 32B and trained using outputs from DeepSeek R1.\nDeepSeek-R1 addresses issues such as infinite repetition, poor readability, and language mixing by introducing cold-start data before reinforcement learning.\nDeepSeek-R1’s performance in mathematics, programming, and reasoning tasks is comparable to OpenAI-o1.\nTo support the research community, we have open-sourced DeepSeek-R1-Zero, DeepSeek-R1, and six dense models based on Llama and Qwen.\nDeepSeek-R1-Distill-Qwen-32B outperforms OpenAI-o1-mini on multiple benchmark tests, setting new state-of-the-art results for dense models.",
            "extendedThinking": false,
            "id": "DeepSeek-R1-Distill-Qwen-32B",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-Distill-Qwen-32B",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2025-01-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.06,
                "inputCacheHit": null,
                "output": 0.12,
                "videoGeneration": null
            },
            "description": "The model provider is the Sophnet platform. DeepSeek-R1-Distill-Qwen-7B is a distilled model based on the Qwen architecture, optimized for high reasoning speed and low cost. It achieves approximately 70% of the performance of the original model at the 7B scale, while reducing response latency by 40%, making it suitable for real-time interactive scenarios.\nThe API call cost is only one-quarter of the original Qwen-7B.\nIt supports streaming output, making it suitable for applications like chatbots.\nIt achieves an accuracy of over 65% on the GSM8K math task.",
            "extendedThinking": false,
            "id": "DeepSeek-R1-Distill-Qwen-7B",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-Distill-Qwen-7B",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.272,
                "inputCacheHit": null,
                "output": 1.088,
                "videoGeneration": null
            },
            "description": "It has been automatically upgraded to the latest released version, 250324.\nAutomatically upgraded to the latest released version 250324.",
            "extendedThinking": false,
            "id": "DeepSeek-V3",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1638000,
                "output": 1638000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.096,
                "inputCacheHit": null,
                "output": 3.288,
                "videoGeneration": null
            },
            "description": "The model provider is the Sophon platform. DeepSeek V3.1 Fast is the high-TPS speed version of DeepSeek V3.1.\nHybrid thinking mode: By modifying the chat template, a single model can simultaneously support both thinking and non-thinking modes.\nSmarter tool usage: Through post-training optimization, the model’s performance in tool utilization and agent tasks has improved significantly.",
            "extendedThinking": false,
            "id": "DeepSeek-V3.1-Fast",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163000,
                "output": 163000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.1-Fast",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.56,
                "inputCacheHit": null,
                "output": 1.68,
                "videoGeneration": null
            },
            "description": "DeepSeek-V3.1 non-thinking mode has now been updated to the DeepSeek-V3.1-Terminus version.",
            "extendedThinking": false,
            "id": "DeepSeek-V3.1-Terminus",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 160000,
                "output": 32000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.1-Terminus",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.56,
                "inputCacheHit": null,
                "output": 1.68,
                "videoGeneration": null
            },
            "description": "Thinking mode of DeepSeek-V3.1;  \nDeepSeek V3.1 is a text generation model provided by DeepSeek, featuring a hybrid reasoning architecture that achieves an effective integration of thinking and non-thinking modes.",
            "extendedThinking": true,
            "id": "DeepSeek-V3.1-Think",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 32000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.1-Think",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.274,
                "inputCacheHit": 0.0274,
                "output": 0.411,
                "videoGeneration": null
            },
            "description": "The model DeepSeek-V3.2-Exp is officially named deepseek-chat on the website. It is an experimental version. As an intermediate step towards the next-generation architecture, V3.2-Exp introduces DeepSeek Sparse Attention (a sparse attention mechanism) based on V3.1-Terminus, exploring and validating",
            "extendedThinking": false,
            "id": "DeepSeek-V3.2-Exp",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163000,
                "output": 163000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.2-Exp",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.274,
                "inputCacheHit": 0.0274,
                "output": 0.411,
                "videoGeneration": null
            },
            "description": "The model DeepSeek-V3.2-Exp-Think is officially named deepseek-reasoner. It is an experimental version. As an intermediate step towards the next-generation architecture, V3.2-Exp introduces DeepSeek Sparse Attention (a sparse attention mechanism) based on V3.1-Terminus, exploring and validating exploratory optimizations for training and inference efficiency on long texts.",
            "extendedThinking": true,
            "id": "DeepSeek-V3.2-Exp-Think",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131000,
                "output": 64000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.2-Exp-Think",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.56,
                "inputCacheHit": null,
                "output": 2.24,
                "videoGeneration": null
            },
            "description": "V3 Ultra-Fast Version,The current price is a limited-time 50% discount and will return to the original price on July 31st. The original price is: input: $0.55/M, output: $2.2/M. The model provider is the Sophnet platform. DeepSeek V3 Fast is a high-TPS, ultra-fast version of DeepSeek V3 0324, featuring full-precision (non-quantized) performance, enhanced code and math capabilities, and faster responses!\n\nDeepSeek V3 0324 is a powerful Mixture-of-Experts (MoE) model with a total parameter count of 671B, activating 37B parameters per token.\nIt adopts Multi-Head Latent Attention (MLA) and the DeepSeekMoE architecture to achieve efficient inference and economical training costs.\nIt innovatively implements a load balancing strategy without auxiliary loss and sets multi-token prediction training targets to enhance performance.\nThe model is pre-trained on 14.8 trillion diverse, high-quality tokens and further optimized through supervised fine-tuning and reinforcement learning stages to fully realize its capabilities.\nComprehensive evaluations show that DeepSeek V3 outperforms other open-source models and rivals leading closed-source models in performance.\nThe entire training process only requires 2.788M H800 GPU hours and remains highly stable, with no irrecoverable loss spikes or rollbacks.",
            "extendedThinking": false,
            "id": "DeepSeek-V3-Fast",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32000,
                "output": 32000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3-Fast",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.272,
                "inputCacheHit": null,
                "output": 1.088,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "DeepSeek-v3",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-v3",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.033,
                "inputCacheHit": null,
                "output": 0.054978,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "deepinfra-llama-3.1-8b-instant",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra-llama-3.1-8b-instant",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.11,
                "inputCacheHit": null,
                "output": 0.352,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "deepinfra-llama-3.3-70b-instant-turbo",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra-llama-3.3-70b-instant-turbo",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.65,
                "inputCacheHit": null,
                "output": 6.6,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "deepinfra-llama-4-maverick-17b-128e-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra-llama-4-maverick-17b-128e-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.088,
                "inputCacheHit": 0,
                "output": 0.33,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "deepinfra-llama-4-scout-17b-16e-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra-llama-4-scout-17b-16e-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.16,
                "inputCacheHit": null,
                "output": 0.32,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-Coder-V2-Instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-ai/DeepSeek-Coder-V2-Instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1,
                "videoGeneration": null
            },
            "description": "Provided by chutes.ai\nDeepSeek Prover V2 is a 671B parameter model, speculated to be geared towards logic and mathematics. Likely an upgrade from DeepSeek-Prover-V1.5 Not much is known about the model yet, as DeepSeek released it on Hugging Face without an announcement or description.",
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-Prover-V2-671B",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-ai/DeepSeek-Prover-V2-671B",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.01,
                "inputCacheHit": null,
                "output": 0.01,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1,
                "videoGeneration": null
            },
            "description": "Open source deployment from SiliconFlow, the model itself is obtained through knowledge distillation.",
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.01,
                "inputCacheHit": null,
                "output": 0.01,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2,
                "videoGeneration": null
            },
            "description": "Open source deployment from SiliconFlow, the model itself is obtained through knowledge distillation.",
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.01,
                "inputCacheHit": null,
                "output": 0.01,
                "videoGeneration": null
            },
            "description": "Open source deployment from SiliconFlow, the model itself is obtained through knowledge distillation.",
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2.2,
                "inputCacheHit": null,
                "output": 2.2,
                "videoGeneration": null
            },
            "description": "Openly deployed by chutes.ai; inference with FP8; zero is the initial preliminary version of R1 without optimizations and is not recommended for use unless for research purposes.",
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-R1-Zero",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-ai/DeepSeek-R1-Zero",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.16,
                "inputCacheHit": null,
                "output": 0.32,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-V2.5",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-ai/DeepSeek-V2.5",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.16,
                "inputCacheHit": null,
                "output": 0.32,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-V2-Chat",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-ai/DeepSeek-V2-Chat",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.16,
                "inputCacheHit": null,
                "output": 0.16,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "deepseek-ai/deepseek-llm-67b-chat",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-ai/deepseek-llm-67b-chat",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.16,
                "inputCacheHit": null,
                "output": 0.16,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "deepseek-ai/deepseek-vl2",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-ai/deepseek-vl2",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "deepseek-ai/Janus-Pro-7B",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-ai/Janus-Pro-7B",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.492,
                "inputCacheHit": 0.0984,
                "output": 1.968,
                "videoGeneration": null
            },
            "description": "The mathematical reasoning of large language models has shifted from pursuing correct answers to ensuring rigorous processes. Research proposes a new paradigm of \"self-verification,\" training specialized verifiers to evaluate proof steps and using this to train generators for self-error correction. The two co-evolve, pushing the boundaries of capability. Ultimately, the model achieves gold medal level in top competitions like the IMO, demonstrating the great potential of deep reasoning.",
            "extendedThinking": true,
            "id": "deepseek-math-v2",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163000,
                "output": 163000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-math-v2",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.02,
                "inputCacheHit": null,
                "output": 0.02,
                "videoGeneration": null
            },
            "description": "DeepSeek-OCR is a vision-language model launched by DeepSeek AI, focusing on optical character recognition (OCR) and “contextual optical compression.” The model is designed to explore the limits of compressing contextual information from images, efficiently processing documents and converting them into structured text formats such as Markdown. The model requires an image as input.",
            "extendedThinking": false,
            "id": "deepseek-ocr",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "deepseek-ocr",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.8,
                "inputCacheHit": null,
                "output": 1.6,
                "videoGeneration": null
            },
            "description": "Provided by Groq, the DeepSeek-R1-Distill model is fine-tuned based on an open-source model, using samples generated by DeepSeek-R1. We have made slight modifications to their configurations and tokenizers. Please use our settings to run these models.",
            "extendedThinking": true,
            "id": "deepseek-r1-distill-llama-70b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-r1-distill-llama-70b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": "2025-01-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.137,
                "inputCacheHit": null,
                "output": 0.548,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "deepseek-r1-distill-qianfan-llama-8b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-r1-distill-qianfan-llama-8b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.272,
                "inputCacheHit": 0,
                "output": 1.088,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "deepseek-v3",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-v3",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.302,
                "inputCacheHit": 0.0302,
                "output": 0.453,
                "videoGeneration": null
            },
            "description": "DeepSeek-V3.2 is an efficient large language model equipped with DeepSeek Sparse Attention and reinforced reasoning performance, but its core strength lies in powerful agentic capabilities—enabled by large-scale task-synthesis that tightly integrates reasoning with real-world tool use, delivering robust, compliant, and generalizable agent behaviour. Users can toggle deeper reasoning through the reasoning_enabled switch.",
            "extendedThinking": false,
            "id": "deepseek-v3.2",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 64000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-v3.2",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.096,
                "inputCacheHit": 1.096,
                "output": 3.288,
                "videoGeneration": null
            },
            "description": "SophNet's exclusively developed DeepSeek V3.2 Fast is the high-TPS, high-speed version of DeepSeek V3.2, achieving up to 100t/s with faster response!",
            "extendedThinking": false,
            "id": "deepseek-v3.2-fast",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 128000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-v3.2-fast",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.58,
                "inputCacheHit": null,
                "output": 1.680028,
                "videoGeneration": null
            },
            "description": "DeepSeek-V3.2-Speciale is an enhanced long-thinking variant of DeepSeek-V3.2 that integrates the theorem-proving capabilities of DeepSeek-Math-V2. It excels in instruction following, mathematical reasoning, and logical verification, achieving performance comparable to Gemini-3.0-Pro on major reasoning benchmarks and winning gold medals at IMO 2025, CMO 2025, ICPC World Finals 2025, and IOI 2025. However, due to its long-thinking mechanism, the model may overthink simple questions, so task complexity should be carefully controlled during usage. The model only supports the thinking version.",
            "extendedThinking": true,
            "id": "deepseek-v3.2-speciale",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 128000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-v3.2-speciale",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.302,
                "inputCacheHit": 0.0302,
                "output": 0.453,
                "videoGeneration": null
            },
            "description": "DeepSeek-V3.2 is an efficient large language model equipped with DeepSeek Sparse Attention and reinforced reasoning performance, but its core strength lies in powerful agentic capabilities—enabled by large-scale task-synthesis that tightly integrates reasoning with real-world tool use, delivering robust, compliant, and generalizable agent behaviour. Users can toggle deeper reasoning through the reasoning_enabled switch.",
            "extendedThinking": false,
            "id": "deepseek-v3.2-think",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 64000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-v3.2-think",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 0,
                "output": 2,
                "videoGeneration": null
            },
            "description": "This endpoint is used to describe an image.\nSupported image formats include JPEG, PNG, and WebP.\nUS $0.01/ IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.",
            "extendedThinking": false,
            "id": "DESCRIBE",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "DESCRIBE",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 5.556,
                "inputCacheHit": null,
                "output": 5.556,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "distil-whisper-large-v3-en",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["audio"],
                "output": ["text"]
            },
            "name": "distil-whisper-large-v3-en",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.05,
                "inputCacheHit": 0.01,
                "output": 0.1,
                "videoGeneration": null
            },
            "description": "Doubao-1.5-lite, a brand-new generation of lightweight model, offers exceptional response speed with both performance and latency reaching world-class levels. It supports a 32k context window and an output length of up to 12k tokens.",
            "extendedThinking": false,
            "id": "Doubao-1.5-lite-32k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Doubao-1.5-lite-32k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.8,
                "inputCacheHit": 0.8,
                "output": 1.44,
                "videoGeneration": null
            },
            "description": "Doubao-1.5-pro-256k, a fully upgraded version based on Doubao-1.5-Pro, delivers an overall performance improvement of 10%. It supports inference with a 256k context window and an output length of up to 12k tokens. With higher performance, larger window size, and exceptional cost-effectiveness, it is suitable for a wider range of application scenarios.",
            "extendedThinking": false,
            "id": "Doubao-1.5-pro-256k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Doubao-1.5-pro-256k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.684,
                "inputCacheHit": null,
                "output": 1.2312,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "doubao-1-5-pro-256k-250115",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "doubao-1-5-pro-256k-250115",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.134,
                "inputCacheHit": 0.0268,
                "output": 0.335,
                "videoGeneration": null
            },
            "description": "Doubao-1.5-pro, a brand-new generation of flagship model, features comprehensive performance upgrades and excels in knowledge, coding, reasoning, and other aspects. It supports a 32k context window and an output length of up to 12k tokens.",
            "extendedThinking": false,
            "id": "Doubao-1.5-pro-32k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Doubao-1.5-pro-32k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.108,
                "inputCacheHit": null,
                "output": 0.27,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "doubao-1-5-pro-32k-250115",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "doubao-1-5-pro-32k-250115",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.62,
                "inputCacheHit": 0.62,
                "output": 2.48,
                "videoGeneration": null
            },
            "description": "Doubao-1.5 is a brand-new deep thinking model that excels in specialized fields such as mathematics, programming, scientific reasoning, and general tasks like creative writing. It achieves or approaches the top-tier industry level on multiple authoritative benchmarks including AIME 2024, Codeforces, and GPQA. It supports a 128k context window and 16k output.",
            "extendedThinking": false,
            "id": "Doubao-1.5-thinking-pro",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Doubao-1.5-thinking-pro",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": 2,
                "output": 2,
                "videoGeneration": null
            },
            "description": "Deep Thinking  \nImage Understanding  \nVisual Localization  \nVideo Understanding  \nTool Invocation  \nStructured Output",
            "extendedThinking": false,
            "id": "doubao-1-5-thinking-vision-pro-250428",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "doubao-1-5-thinking-vision-pro-250428",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.46,
                "inputCacheHit": null,
                "output": 1.38,
                "videoGeneration": null
            },
            "description": "Doubao-1.5-vision-pro is a newly upgraded multimodal large model that supports image recognition at any resolution and extreme aspect ratios. It enhances visual reasoning, document recognition, detailed information understanding, and instruction-following capabilities. It supports a 32k context window and an output length of up to 12k tokens.",
            "extendedThinking": false,
            "id": "Doubao-1.5-vision-pro-32k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Doubao-1.5-vision-pro-32k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1,
                "videoGeneration": null
            },
            "description": "doubao-embedding-large-text-240915\nDoubao Embedding is a semantic vectorization model developed by ByteDance, primarily designed for vector search scenarios. It supports both Chinese and English languages and has a maximum context length of approximately 4K tokens.",
            "extendedThinking": false,
            "id": "doubao-embedding-large-text-240915",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "doubao-embedding-large-text-240915",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.7,
                "inputCacheHit": null,
                "output": 0.7,
                "videoGeneration": null
            },
            "description": "doubao-embedding-text-240715\nDoubao Embedding is a semantic vectorization model developed by ByteDance, primarily designed for vector search scenarios. It supports both Chinese and English languages and has a maximum context length of approximately 4K tokens.",
            "extendedThinking": false,
            "id": "doubao-embedding-text-240715",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "doubao-embedding-text-240715",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.14,
                "inputCacheHit": 0.14,
                "output": 0.28,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Doubao-lite-128k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Doubao-lite-128k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.06,
                "inputCacheHit": 0.012,
                "output": 0.12,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Doubao-lite-32k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Doubao-lite-32k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.06,
                "inputCacheHit": 0.06,
                "output": 0.12,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Doubao-lite-4k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Doubao-lite-4k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.8,
                "inputCacheHit": null,
                "output": 1.44,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Doubao-pro-128k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Doubao-pro-128k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.8,
                "inputCacheHit": 0.8,
                "output": 1.44,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Doubao-pro-256k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Doubao-pro-256k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.14,
                "inputCacheHit": 0.028,
                "output": 0.35,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Doubao-pro-32k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Doubao-pro-32k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.14,
                "inputCacheHit": null,
                "output": 0.35,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Doubao-pro-4k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Doubao-pro-4k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.18,
                "inputCacheHit": 0.036,
                "output": 1.8,
                "videoGeneration": null
            },
            "description": "Doubao-Seed-1.6 is a brand new multimodal deep reasoning model that supports four types of reasoning effort: minimal, low, medium, and high. It offers stronger model performance, serving complex tasks and challenging scenarios. It supports a 256k context window, with output length up to a maximum of 32k tokens.",
            "extendedThinking": false,
            "id": "doubao-seed-1-6",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 32000
            },
            "modalities": {
                "input": ["text", "image", "video"],
                "output": ["text"]
            },
            "name": "doubao-seed-1-6",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.18,
                "inputCacheHit": 0.036,
                "output": 2.52,
                "videoGeneration": null
            },
            "description": "Doubao-Seed-1.6 is a brand new multimodal deep reasoning model that supports four types of reasoning effort: minimal, low, medium, and high. It offers stronger model performance, serving complex tasks and challenging scenarios. It supports a 256k context window, with output length up to a maximum of 32k tokens.",
            "extendedThinking": false,
            "id": "doubao-seed-1-6-250615",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "doubao-seed-1-6-250615",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.044,
                "inputCacheHit": 0.0088,
                "output": 0.44,
                "videoGeneration": null
            },
            "description": "Doubao-Seed-1.6-flash is an extremely fast multimodal deep thinking model, with TPOT requiring only 10ms. It supports both text and visual understanding, with its text comprehension skills surpassing the previous generation lite model and its visual understanding on par with competitor's pro series models. It supports a 256k context window and an output length of up to 16k tokens.",
            "extendedThinking": false,
            "id": "doubao-seed-1-6-flash",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 33000
            },
            "modalities": {
                "input": ["text", "image", "video"],
                "output": ["text"]
            },
            "name": "doubao-seed-1-6-flash",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.044,
                "inputCacheHit": 0.0088,
                "output": 0.44,
                "videoGeneration": null
            },
            "description": "Doubao-Seed-1.6-flash is an extremely fast multimodal deep thinking model, with TPOT requiring only 10ms. It supports both text and visual understanding, with its text comprehension skills surpassing the previous generation lite model and its visual understanding on par with competitor's pro series models. It supports a 256k context window and an output length of up to 16k tokens.",
            "extendedThinking": false,
            "id": "doubao-seed-1-6-flash-250615",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "doubao-seed-1-6-flash-250615",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.082,
                "inputCacheHit": 0.0164,
                "output": 0.656,
                "videoGeneration": null
            },
            "description": "Doubao-Seed-1.6-lite is a brand new multimodal deep reasoning model that supports adjustable reasoning effort, with four modes: Minimal, Low, Medium, and High. It offers better cost performance, making it the best choice for common tasks, with a context window of up to 256k.",
            "extendedThinking": false,
            "id": "doubao-seed-1-6-lite",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 32000
            },
            "modalities": {
                "input": ["text", "image", "video"],
                "output": ["text"]
            },
            "name": "doubao-seed-1-6-lite",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.18,
                "inputCacheHit": 0.036,
                "output": 1.8,
                "videoGeneration": null
            },
            "description": "The Doubao-Seed-1.6-thinking model has significantly enhanced reasoning capabilities. Compared with Doubao-1.5-thinking-pro, it has further improvements in fundamental abilities such as coding, mathematics, and logical reasoning, and now also supports visual understanding. It supports a 256k context window, with output length supporting up to 16k tokens.",
            "extendedThinking": false,
            "id": "doubao-seed-1-6-thinking",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 32000
            },
            "modalities": {
                "input": ["text", "image", "video"],
                "output": ["text"]
            },
            "name": "doubao-seed-1-6-thinking",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.18,
                "inputCacheHit": 0.036,
                "output": 2.52,
                "videoGeneration": null
            },
            "description": "The Doubao-Seed-1.6-thinking model has significantly enhanced reasoning capabilities. Compared with Doubao-1.5-thinking-pro, it has further improvements in fundamental abilities such as coding, mathematics, and logical reasoning, and now also supports visual understanding. It supports a 256k context window, with output length supporting up to 16k tokens.",
            "extendedThinking": false,
            "id": "doubao-seed-1-6-thinking-250615",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "doubao-seed-1-6-thinking-250615",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.10959,
                "inputCacheHit": 0.021918,
                "output": 1.0959,
                "videoGeneration": null
            },
            "description": "Doubao-Seed-1.6-vision is a visual deep-thinking model that demonstrates stronger general multimodal understanding and reasoning capabilities in scenarios such as education, image moderation, inspection and security, and AI search Q&A. It supports a 256K context window and an output length of up to 64K tokens.",
            "extendedThinking": false,
            "id": "doubao-seed-1-6-vision-250815",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "doubao-seed-1-6-vision-250815",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.10959,
                "inputCacheHit": 0.021918,
                "output": 0.273975,
                "videoGeneration": null
            },
            "description": "Doubao's strongest multimodal Agent model Seed1.8 has powerful multimodal capabilities, supports image and text input, and can efficiently and accurately complete tasks in scenarios such as information retrieval, code generation, GUI interaction, and complex workflows, meeting increasingly diverse technical demands.",
            "extendedThinking": true,
            "id": "doubao-seed-1-8",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image", "video"],
                "output": ["text"]
            },
            "name": "doubao-seed-1-8",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2,
                "videoGeneration": null
            },
            "description": "chat",
            "extendedThinking": false,
            "id": "doubao-seed-code-preview-latest",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "doubao-seed-code-preview-latest",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 0,
                "output": 0,
                "videoGeneration": null
            },
            "description": "Seedream 4.0 is a SOTA-level multimodal image creation model based on leading architecture. It breaks the creative boundaries of traditional text-to-image models by natively supporting text, single image, and multiple image inputs. Users can freely combine text and images to achieve various creative styles within the same model, such as multi-image fusion creation based on subject consistency, image editing, and set image generation, making image creation more flexible and controllable.\nSeedream 4.0 supports composite editing with up to 10 images in a single input. Through deep reasoning of prompt words, it automatically adapts the optimal image aspect ratio and generation quantity, enabling continuous output of up to 15 content-related images at one time. Additionally, the model significantly improves the accuracy and content diversity of Chinese generation, supports 4K ultra-high-definition output, and provides a one-stop solution from generation to editing for professional image creation.",
            "extendedThinking": false,
            "id": "doubao-seedream-4-0",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "doubao-seedream-4-0",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 0,
                "output": 0,
                "videoGeneration": null
            },
            "description": "Seedream 4.5 is ByteDance's latest multimodal image model, integrating capabilities such as text-to-image, image-to-image, and multi-image output, along with incorporating common sense and reasoning abilities. Compared to the previous 4.0 model, it significantly improves generation quality, offering better editing consistency and multi-image fusion effects, with more precise control over image details. The generation of small text and small faces is more natural.",
            "extendedThinking": false,
            "id": "doubao-seedream-4-5",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "doubao-seedream-4-5",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.0686,
                "inputCacheHit": null,
                "output": 0.0686,
                "videoGeneration": null
            },
            "description": "A text vector model that converts input text information into vector representations so that, in conjunction with a vector database, it provides an external knowledge base for the large model, thereby improving the accuracy of the model’s reasoning.",
            "extendedThinking": false,
            "id": "embedding-2",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "embedding-2",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.0686,
                "inputCacheHit": null,
                "output": 0.0686,
                "videoGeneration": null
            },
            "description": "A text vector model that converts input text into vector representations to work with a vector database and provide an external knowledge base for a large model. The model supports custom vector dimensions; it is recommended to choose 256, 512, 1024, or 2048 dimensions.",
            "extendedThinking": false,
            "id": "embedding-3",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "embedding-3",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.068,
                "inputCacheHit": null,
                "output": 0.068,
                "videoGeneration": null
            },
            "description": "Embedding-V1 is a text representation model based on Baidu's Wenxin large model technology, capable of converting text into numerical vector forms for applications such as text retrieval, information recommendation, and knowledge mining. Embedding-V1 provides an Embeddings interface that generates corresponding vector representations based on the input content. By calling this interface, you can input text into the model and obtain the corresponding vector representations for subsequent text processing and analysis.",
            "extendedThinking": false,
            "id": "embedding-v1",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "embedding-v1",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.068,
                "inputCacheHit": null,
                "output": 0.272,
                "videoGeneration": null
            },
            "description": "Wenxin Large Model 4.5 is a next-generation native multimodal foundational model independently developed by Baidu. It achieves collaborative optimization through joint modeling of multiple modalities, demonstrating excellent multimodal understanding capabilities; it possesses more advanced language abilities, with comprehensive improvements in comprehension, generation, logic, and memory, as well as significant enhancements in hallucination reduction, logical reasoning, and coding capabilities.ERNIE-4.5-21B-A3B is an aligned open-source model with a MoE structure, having a total of 21 billion parameters and 3 billion activated parameters.",
            "extendedThinking": false,
            "id": "ernie-4.5",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 160000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "ernie-4.5",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.0136,
                "inputCacheHit": null,
                "output": 0.0544,
                "videoGeneration": null
            },
            "description": "Wenxin Large Model 4.5 is a next-generation native multimodal foundational large model independently developed by Baidu. It achieves collaborative optimization through joint modeling of multiple modalities, demonstrating excellent multimodal understanding capabilities. The model possesses enhanced language abilities, with comprehensive improvements in understanding, generation, reasoning, and memory. It significantly reduces hallucinations and shows notable advancements in logical reasoning and coding skills.",
            "extendedThinking": false,
            "id": "ernie-4.5-0.3b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "ernie-4.5-0.3b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.108,
                "inputCacheHit": null,
                "output": 0.432,
                "videoGeneration": null
            },
            "description": "Wenxin 4.5 Turbo also shows significant enhancements in reducing hallucinations, logical reasoning, and coding capabilities. Compared to Wenxin 4.5, it is faster and more cost-effective.",
            "extendedThinking": false,
            "id": "ernie-4.5-turbo-128k-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "ernie-4.5-turbo-128k-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.11,
                "inputCacheHit": null,
                "output": 0.44,
                "videoGeneration": null
            },
            "description": "Wenxin 4.5 Turbo also has significant improvements in hallucination reduction, logical reasoning, and coding capabilities. Compared to Wenxin 4.5, it is faster and more affordable.",
            "extendedThinking": false,
            "id": "ernie-4.5-turbo-latest",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 135000,
                "output": 12000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "ernie-4.5-turbo-latest",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.4,
                "inputCacheHit": null,
                "output": 1.2,
                "videoGeneration": null
            },
            "description": "The new version of the Wenxin Yiyan large model significantly improves capabilities in image understanding, creation, translation, and coding. It supports a context length of up to 32K tokens for the first time, with a notable reduction in the latency of the first token.",
            "extendedThinking": false,
            "id": "ernie-4.5-turbo-vl",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 139000,
                "output": 16000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "ernie-4.5-turbo-vl",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.822,
                "inputCacheHit": null,
                "output": 3.288,
                "videoGeneration": null
            },
            "description": "The new generation Wenxin model, Wenxin 5.0, is a native full-modal large model that adopts native full-modal unified modeling technology, jointly modeling text, images, audio, and video, possessing comprehensive full-modal capabilities. Wenxin 5.0's basic abilities are comprehensively upgraded, performing excellently on benchmark test sets, especially in multimodal understanding, instruction compliance, creative writing, factual accuracy, intelligent agent planning, and tool application.",
            "extendedThinking": true,
            "id": "ernie-5.0-thinking-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 183000,
                "output": 64000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ernie-5.0-thinking-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 0,
                "output": 0,
                "videoGeneration": null
            },
            "description": "Baidu's self-developed ERNIE iRAG Edit image editing model supports operations based on images such as erase (object removal), repaint (object redrawing), and variation (variant generation).",
            "extendedThinking": false,
            "id": "ernie-irag-edit",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "ernie-irag-edit",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.136,
                "inputCacheHit": null,
                "output": 0.544,
                "videoGeneration": null
            },
            "description": "The Wenxin large model X1.1 has made significant improvements in question answering, tool invocation, intelligent agents, instruction following, logical reasoning, mathematics, and coding tasks, with notable enhancements in factual accuracy. The context length has been extended to 64K tokens, supporting longer inputs and dialogue history, which improves the coherence of long-chain reasoning while maintaining response speed.",
            "extendedThinking": true,
            "id": "ERNIE-X1.1-Preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 119000,
                "output": 64000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ERNIE-X1.1-Preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.136,
                "inputCacheHit": null,
                "output": 0.544,
                "videoGeneration": null
            },
            "description": "The Wenxin large model X1.1 has made significant improvements in question answering, tool invocation, intelligent agents, instruction following, logical reasoning, mathematics, and coding tasks, with notable enhancements in factual accuracy. The context length has been extended to 64K tokens, supporting longer inputs and dialogue history, which improves the coherence of long-chain reasoning while maintaining response speed.",
            "extendedThinking": false,
            "id": "ernie-x1.1-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ernie-x1.1-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.136,
                "inputCacheHit": null,
                "output": 0.544,
                "videoGeneration": null
            },
            "description": "Wenxin Large Model X1 possesses enhanced abilities in understanding, planning, reflection, and evolution. As a more comprehensive deep-thinking model, Wenxin X1 combines accuracy, creativity, and literary elegance, excelling particularly in Chinese knowledge Q&A, literary creation, document writing, daily conversations, logical reasoning, complex calculations, and tool invocation.",
            "extendedThinking": true,
            "id": "ernie-x1-turbo",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 50500,
                "output": 28000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ernie-x1-turbo",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 40,
                "input": 40,
                "inputCacheHit": 0,
                "output": 40,
                "videoGeneration": null
            },
            "description": "FLUX-1.1-pro is an AI image generation tool for professional creators and content workflows. It understands complex semantic and structural instructions to deliver high consistency, multi-image coherence, and style customization from text prompts.",
            "extendedThinking": false,
            "id": "FLUX-1.1-pro",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX-1.1-pro",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 40,
                "input": 40,
                "inputCacheHit": null,
                "output": 40,
                "videoGeneration": null
            },
            "description": "Generate and edit images through both text and image prompts. Flux.1 Kontext is a multimodal flow matching model that enables both text-to-image generation and in-context image editing. Modify images while maintaining character consistency and performing local edits up to 8x faster than other leading models.",
            "extendedThinking": false,
            "id": "FLUX.1-Kontext-pro",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX.1-Kontext-pro",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 0,
                "output": 0,
                "videoGeneration": null
            },
            "description": "FLUX.2 is purpose-built for real-world creative production workflows. It delivers high-quality images while maintaining character and style consistency across multiple reference images, shows exceptional understanding and execution of structured prompts, and supports complex text reading and writing. It also adheres to brand guidelines, handles lighting, layout, and logo elements with stability, and enables image editing at resolutions up to 4MP — all while preserving fine details, striking a balance between creativity and professional-grade visual output.",
            "extendedThinking": false,
            "id": "flux-2-flex",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "flux-2-flex",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 0,
                "output": 0,
                "videoGeneration": null
            },
            "description": "FLUX.2 is purpose-built for real-world creative production workflows. It delivers high-quality images while maintaining character and style consistency across multiple reference images, shows exceptional understanding and execution of structured prompts, and supports complex text reading and writing. It also adheres to brand guidelines, handles lighting, layout, and logo elements with stability, and enables image editing at resolutions up to 4MP — all while preserving fine details, striking a balance between creativity and professional-grade visual output.",
            "extendedThinking": false,
            "id": "flux-2-pro",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "flux-2-pro",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": 0,
                "output": 0,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "flux-kontext-max",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "flux-kontext-max",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": 0,
                "output": 0,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "fx-flux-2-pro",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "fx-flux-2-pro",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1,
                "inputCacheHit": 0.025,
                "output": 0.4,
                "videoGeneration": null
            },
            "description": "Gemini 2.0 Flash is Google's latest lightweight model featuring extremely low hallucination rates while maintaining fast response times, offering developers high-precision and efficient AI solutions particularly suited for applications requiring high factual accuracy.",
            "extendedThinking": false,
            "id": "gemini-2.0-flash",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-2.0-flash",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1,
                "inputCacheHit": 0.25,
                "output": 0.4,
                "videoGeneration": null
            },
            "description": "Google Gemini's enterprise version VertexAI",
            "extendedThinking": false,
            "id": "gemini-2.0-flash-001",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemini-2.0-flash-001",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 0.02,
                "input": 0.02,
                "inputCacheHit": null,
                "output": 0.08,
                "videoGeneration": null
            },
            "description": "https://doc.aihubmix.com/en/api/Gemini%20%E5%9B%BE%E7%89%87%E7%94%9F%E6%88%90%E5%92%8C%E7%BC%96%E8%BE%91\nInstructions:\n\nNeed to add parameters to experience new features: \"modalities\":[\"text\",\"image\"]\nImages are passed and output in Base64 encoding\nAs an experimental model, it's recommended to explicitly specify \"output image\", otherwise it might only output text\nDefault height for output images is 1024px\nPython calls require the latest OpenAI SDK, run pip install -U openai first",
            "extendedThinking": false,
            "id": "gemini-2.0-flash-exp",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["image"]
            },
            "name": "gemini-2.0-flash-exp",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gemini-2.0-flash-exp-image-generation",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemini-2.0-flash-exp-image-generation",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.4,
                "videoGeneration": null
            },
            "description": "The gemini-2.0-flash-exp model supports internet connectivity, but the official version requires additional request parameters to enable it. Aihubmix has integrated this by automatically calling the official API's online functionality when the model name is requested with the \"search\" parameter.",
            "extendedThinking": false,
            "id": "gemini-2.0-flash-exp-search",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gemini-2.0-flash-exp-search",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0,
                "inputCacheHit": 0,
                "output": 0,
                "videoGeneration": null
            },
            "description": "gemini-2.0-flash-free is the free, publicly available version of gemini-2.0-flash, offering the same model capabilities with usage limits in place to ensure service stability. Limits include up to 5 requests per minute, a maximum of 500 requests per day, and a daily quota of 1,000,000 tokens. Free usage is based on shared capacity and is limited in availability. This version is intended for testing and light usage; for consistent and reliable access, please switch to the paid model.",
            "extendedThinking": false,
            "id": "gemini-2.0-flash-free",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-2.0-flash-free",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.076,
                "inputCacheHit": 0.076,
                "output": 0.304,
                "videoGeneration": null
            },
            "description": "Gemini-2.0-flash Lightweight Official Version",
            "extendedThinking": false,
            "id": "gemini-2.0-flash-lite",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-2.0-flash-lite",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.076,
                "inputCacheHit": 0.076,
                "output": 0.304,
                "videoGeneration": null
            },
            "description": "Google Gemini's enterprise version VertexAI",
            "extendedThinking": false,
            "id": "gemini-2.0-flash-lite-001",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemini-2.0-flash-lite-001",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.075,
                "inputCacheHit": 0.075,
                "output": 0.3,
                "videoGeneration": null
            },
            "description": "Gemini 2.0 Flash lightweight version",
            "extendedThinking": false,
            "id": "gemini-2.0-flash-lite-preview-02-05",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemini-2.0-flash-lite-preview-02-05",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 0.1,
                "input": 0.1,
                "inputCacheHit": 0,
                "output": 0.4,
                "videoGeneration": null
            },
            "description": "Gemini 2.0 Flash EXP is the official preview version of the drawing model. Compared to Imagen 3.0, Gemini’s image generation is better suited for scenarios that require contextual understanding and reasoning, rather than the pursuit of ultimate artistic performance and visual quality.",
            "extendedThinking": false,
            "id": "gemini-2.0-flash-preview-image-generation",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "gemini-2.0-flash-preview-image-generation",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1,
                "inputCacheHit": 0.025,
                "output": 0.4,
                "videoGeneration": null
            },
            "description": "Integrated with Google's official search and internet connectivity features.",
            "extendedThinking": false,
            "id": "gemini-2.0-flash-search",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-2.0-flash-search",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.076,
                "inputCacheHit": null,
                "output": 0.304,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gemini-2.0-flash-thinking-exp",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemini-2.0-flash-thinking-exp",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.076,
                "inputCacheHit": null,
                "output": 0.304,
                "videoGeneration": null
            },
            "description": "The latest version, Gemini 2.0 Flash Thinking mode, is an experimental model designed to generate the \"thought process\" that the model goes through during its responses. Therefore, Gemini 2.0 Flash Thinking mode has stronger reasoning capabilities in its responses compared to the base Gemini 2.0 Flash model.",
            "extendedThinking": true,
            "id": "gemini-2.0-flash-thinking-exp-01-21",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-2.0-flash-thinking-exp-01-21",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.076,
                "inputCacheHit": null,
                "output": 0.304,
                "videoGeneration": null
            },
            "description": "The Gemini 2.0 Flash Thinking mode is an experimental model designed to generate the \"thinking process\" that the model undergoes during its response. Therefore, the Gemini 2.0 Flash Thinking mode possesses stronger reasoning capabilities in its responses compared to the base Gemini 2.0 Flash model.",
            "extendedThinking": false,
            "id": "gemini-2.0-flash-thinking-exp-1219",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemini-2.0-flash-thinking-exp-1219",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 1.25,
                "input": 1.25,
                "inputCacheHit": null,
                "output": 5,
                "videoGeneration": null
            },
            "description": "The latest experimental version of Gemini-2.0-Pro",
            "extendedThinking": false,
            "id": "gemini-2.0-pro-exp-02-05",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["image"]
            },
            "name": "gemini-2.0-pro-exp-02-05",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": null,
                "output": 5,
                "videoGeneration": null
            },
            "description": "Integrated with Google's official search and internet connectivity features.",
            "extendedThinking": false,
            "id": "gemini-2.0-pro-exp-02-05-search",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-2.0-pro-exp-02-05-search",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.3,
                "inputCacheHit": 0.03,
                "output": 2.499,
                "videoGeneration": null
            },
            "description": "Gemini 2.5 Flash is Google’s best model in terms of both performance and cost efficiency, offering a comprehensive set of capabilities. It is the first Flash model to support visible reasoning, allowing insight into the thought process behind its responses. With its strong price–performance ratio, the model is well suited for large-scale processing, low-latency, high-throughput tasks that require reasoning, as well as agent-based application scenarios.",
            "extendedThinking": false,
            "id": "gemini-2.5-flash",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-2.5-flash",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 0.3,
                "input": 0.3,
                "inputCacheHit": 0.3,
                "output": 2.499,
                "videoGeneration": null
            },
            "description": "Gemini 2.5 Flash Image (Nano-Banana) is a state-of-the-art image generation and editing model that enables seamless blending of multiple images into a single composition while maintaining character consistency for rich visual storytelling. It supports precise, targeted image transformations through natural language instructions and leverages built-in world knowledge for both image generation and editing, making it well suited for creative design, content production, advertising, and visual expression workflows.",
            "extendedThinking": false,
            "id": "gemini-2.5-flash-image",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32800,
                "output": 8000
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["image"]
            },
            "name": "gemini-2.5-flash-image",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 0.3,
                "input": 0.3,
                "inputCacheHit": 0.3,
                "output": 1.2,
                "videoGeneration": null
            },
            "description": "Aihubmix supports the gemini-2.5-flash-image-preview model; you can add extra parameters modalities=[\"text\", \"image\"] through the OpenAI-compatible chat interface; https://docs.aihubmix.com/en/api/Gemini-Guides#gemini-2-5-flash%3A-quick-task-support",
            "extendedThinking": false,
            "id": "gemini-2.5-flash-image-preview",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32800,
                "output": 8000
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["image"]
            },
            "name": "gemini-2.5-flash-image-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1,
                "inputCacheHit": 0.01,
                "output": 0.4,
                "videoGeneration": null
            },
            "description": "Gemini 2.5 Flash-Lite is a balanced model from Google, optimized for applications that require low-latency performance. It retains the practical capabilities of the Gemini 2.5 family, including configurable reasoning based on budget, integration with tools such as grounding via Google Search and code execution, multimodal input support, and an ultra-long context window of up to 1 million tokens, delivering a strong balance between efficiency, functionality, and cost.",
            "extendedThinking": false,
            "id": "gemini-2.5-flash-lite",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-2.5-flash-lite",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1,
                "inputCacheHit": 0.01,
                "output": 0.4,
                "videoGeneration": null
            },
            "description": "gemini-2.5-flash-lite latest preview version",
            "extendedThinking": false,
            "id": "gemini-2.5-flash-lite-preview-09-2025",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-2.5-flash-lite-preview-09-2025",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.3,
                "inputCacheHit": 0.03,
                "output": 2.499,
                "videoGeneration": null
            },
            "description": "Gemini-2.5-flash defaults to thinking enabled; to disable thinking, request the name gemini-2.5-flash-nothink, which only supports OpenAI-compatible format calls and does not support Gemini SDK; for the native Gemini SDK, please set the parameter budget=0 directly.",
            "extendedThinking": false,
            "id": "gemini-2.5-flash-nothink",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-2.5-flash-nothink",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.3,
                "inputCacheHit": 0.03,
                "output": 2.499,
                "videoGeneration": null
            },
            "description": "Gemini-2.5-flash-preview-05-20 is enabled by default for thinking; to disable it, request the name gemini-2.5-flash-preview-05-20-nothink.Only OpenAI-compatible format calls are supported; Gemini SDK is not supported. For the native Gemini SDK, please set the parameter budget=0 directly.",
            "extendedThinking": false,
            "id": "gemini-2.5-flash-preview-05-20-nothink",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-2.5-flash-preview-05-20-nothink",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.3,
                "inputCacheHit": 0.03,
                "output": 2.499,
                "videoGeneration": null
            },
            "description": "Gemini-2.5 Flash Preview 05-20 Search integrates Google's official search functionality; the search feature will have an additional separate fee log directly integrated into the scoring deduction, with detailed logs not displayed. It will be fixed and displayed later. Only OpenAI-compatible formats are supported for invocation; Gemini SDK is not supported. For Gemini's native SDK, please set parameters directly using the official search parameters.",
            "extendedThinking": false,
            "id": "gemini-2.5-flash-preview-05-20-search",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-2.5-flash-preview-05-20-search",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.3,
                "inputCacheHit": 0.03,
                "output": 2.499,
                "videoGeneration": null
            },
            "description": "This latest 2.5 Flash model comes with improvements in two key areas we heard consistent feedback on:\n\nBetter agentic tool use: We've improved how the model uses tools, leading to better performance in more complex, agentic and multi-step applications. This model shows noticeable improvements on key agentic benchmarks, including a 5% gain on SWE-Bench Verified, compared to our last release (48.9% → 54%). More efficient: With thinking on, the model is now significantly more cost-efficient—achieving higher quality outputs while using fewer tokens, reducing latency and cost (see charts above).",
            "extendedThinking": false,
            "id": "gemini-2.5-flash-preview-09-2025",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-2.5-flash-preview-09-2025",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.5,
                "inputCacheHit": 0,
                "output": 0.5,
                "videoGeneration": null
            },
            "description": "Gemini 2.5 Flash Preview TTS is a lightweight, low-latency text-to-speech model designed for real-time voice generation. It produces natural, expressive speech with accurate control over tone, style, and pacing, while dynamically adjusting speaking speed based on context and instructions. The model also maintains consistent and distinguishable voices across multi-turn and multi-speaker conversations, making it well-suited for interactive and conversational applications that require stable, high-quality audio output.",
            "extendedThinking": false,
            "id": "gemini-2.5-flash-preview-tts",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["audio"]
            },
            "name": "gemini-2.5-flash-preview-tts",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.3,
                "inputCacheHit": 0.03,
                "output": 2.499,
                "videoGeneration": null
            },
            "description": "gemini-2.5-flash-search integrates Google's official search functionality; the search feature will have an additional separate fee log directly incorporated into the scoring, with detailed logs not displayed; this will be fixed and displayed later; only supports OpenAI-compatible formats for invocation, does not support Gemini SDK; for Gemini's native SDK, please set parameters directly using the official search parameters.",
            "extendedThinking": false,
            "id": "gemini-2.5-flash-search",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-2.5-flash-search",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": 0.125,
                "output": 10,
                "videoGeneration": null
            },
            "description": "Gemini 2.5 Pro is an advanced reasoning model developed by Google, optimized for solving highly complex problems across multiple domains. It can deeply understand large-scale information from diverse sources, including text, audio, images, video, and even entire codebases. The model demonstrates strong reasoning capabilities in coding, mathematics, and STEM-related tasks, and supports long-context analysis for large datasets, codebases, and technical documentation.",
            "extendedThinking": true,
            "id": "gemini-2.5-pro",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image", "audio", "video", "pdf"],
                "output": ["text"]
            },
            "name": "gemini-2.5-pro",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": 0.125,
                "output": 5,
                "videoGeneration": null
            },
            "description": "Google’s latest experimental model, highly unstable, for experience only.\nIt boasts strong reasoning and coding capabilities, able to \"think\" before responding, enhancing performance and accuracy in complex tasks. It supports multimodal inputs (text, audio, images, video) and a 1 million token context window, suitable for advanced programming, math, and science tasks.\n\nThis means Gemini 2.5 can handle more complex problems in coding, science and math, and support more context-aware agents.",
            "extendedThinking": false,
            "id": "gemini-2.5-pro-exp-03-25",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-2.5-pro-exp-03-25",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": 0.125,
                "output": 10,
                "videoGeneration": null
            },
            "description": "Supports high concurrency.  \nThe Gemini 2.5 Pro preview version is here, with higher limits for production testing.  \nGoogle's latest and most powerful model;",
            "extendedThinking": true,
            "id": "gemini-2.5-pro-preview-03-25",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gemini-2.5-pro-preview-03-25",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": 0.125,
                "output": 10,
                "videoGeneration": null
            },
            "description": "Integrated with Google's official search function.",
            "extendedThinking": true,
            "id": "gemini-2.5-pro-preview-03-25-search",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-2.5-pro-preview-03-25-search",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": 0.125,
                "output": 10,
                "videoGeneration": null
            },
            "description": "gemini-2.5-pro latest model",
            "extendedThinking": true,
            "id": "gemini-2.5-pro-preview-05-06",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-2.5-pro-preview-05-06",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": 0.125,
                "output": 10,
                "videoGeneration": null
            },
            "description": "Integrated with Google's official search function.",
            "extendedThinking": true,
            "id": "gemini-2.5-pro-preview-05-06-search",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-2.5-pro-preview-05-06-search",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": 0.125,
                "output": 10,
                "videoGeneration": null
            },
            "description": "Google’s latest multimodal flagship model, combining exceptional coding and reasoning capabilities. Its massive 1 million token context window (soon to expand to 2 million) places it at the top of the WebDevArena and LMArena leaderboards. It is particularly well-suited for developing aesthetically pleasing and highly functional interactive web applications, code transformation, and complex workflows. The newly introduced \"reasoning budget\" feature cleverly balances cost and performance, while optimized tool calls and response styles further enhance development efficiency, making it the ideal choice for rapid prototyping and advanced coding.",
            "extendedThinking": true,
            "id": "gemini-2.5-pro-preview-06-05",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-2.5-pro-preview-06-05",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": 0.125,
                "output": 10,
                "videoGeneration": null
            },
            "description": "Integrated with Google's official search function.",
            "extendedThinking": true,
            "id": "gemini-2.5-pro-preview-06-05-search",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-2.5-pro-preview-06-05-search",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1,
                "inputCacheHit": 0,
                "output": 1,
                "videoGeneration": null
            },
            "description": "Gemini 2.5 Pro Preview TTS is a high-fidelity text-to-speech model designed for premium voice experiences and complex speech generation scenarios. It delivers highly natural and expressive audio with precise control over tone, style, and emotional nuance, while maintaining smooth, context-aware pacing across long-form content. The model excels in multi-speaker and dialogue-heavy use cases, preserving consistent character voices and conversational coherence, making it well-suited for narration, storytelling, and advanced conversational AI applications.",
            "extendedThinking": false,
            "id": "gemini-2.5-pro-preview-tts",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["audio"]
            },
            "name": "gemini-2.5-pro-preview-tts",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": 0.125,
                "output": 10,
                "videoGeneration": null
            },
            "description": "gemini-2.5-pro-search integrates Google's official search functionality; the search feature will have an additional separate fee log directly incorporated into the scoring, with detailed logs not displayed; this will be fixed and displayed later; only supports OpenAI-compatible formats for invocation, does not support Gemini SDK; for Gemini's native SDK, please set parameters directly using the official search parameters.",
            "extendedThinking": true,
            "id": "gemini-2.5-pro-search",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image", "audio", "video", "pdf"],
                "output": ["text"]
            },
            "name": "gemini-2.5-pro-search",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.5,
                "inputCacheHit": 0.05,
                "output": 3,
                "videoGeneration": null
            },
            "description": "Gemini 3 Flash Preview is a low-latency model in the Gemini 3 family, designed for real-time and high-throughput inference. It retains Gemini 3’s core multimodal and reasoning capabilities while prioritizing responsiveness and execution efficiency.",
            "extendedThinking": true,
            "id": "gemini-3-flash-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-3-flash-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0,
                "inputCacheHit": 0,
                "output": 0,
                "videoGeneration": null
            },
            "description": "gemini-3-flash-preview-free is the free, publicly available version of gemini-3-flash-preview, offering the same model capabilities with usage limits in place to ensure service stability. Limits include up to 5 requests per minute, a maximum of 250 requests per day, and a daily quota of 500,000 tokens. Free usage is based on shared capacity and is limited in availability. This version is intended for testing and light usage; for consistent and reliable access, please switch to the paid model.",
            "extendedThinking": true,
            "id": "gemini-3-flash-preview-free",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-3-flash-preview-free",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.5,
                "inputCacheHit": 0.05,
                "output": 3,
                "videoGeneration": null
            },
            "description": "Gemini-3-flash-preview-search integrates Google's official search functionality; the search feature incurs an additional separate fee log directly incorporated into the scoring, but the log details are not displayed; this will be fixed in the future to show the details; it only supports OpenAI-compatible format calls and does not support the Gemini SDK; for the Gemini native SDK, please directly set the official search parameters.",
            "extendedThinking": true,
            "id": "gemini-3-flash-preview-search",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image", "audio"],
                "output": ["text"]
            },
            "name": "gemini-3-flash-preview-search",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 2,
                "output": 12,
                "videoGeneration": null
            },
            "description": "Gemini-3-Pro-Image-Preview (Nano Banana Pro) is a high-performance image generation and editing model built on Gemini 3 Pro. It delivers enhanced multimodal understanding and real-world semantic reasoning, enabling fast creation of well-structured visual content such as infographics, product sketches, and multi-subject scenes. It can also leverage real-time knowledge through Search grounding. The model excels in text rendering, consistent multi-image blending, and identity preservation, while offering fine-grained creative controls like localized edits, lighting and focus adjustments, camera transformations, and flexible aspect ratios. It’s ideal for rapid design, concept previews, product visualization, and everyday image generation workflows.",
            "extendedThinking": false,
            "id": "gemini-3-pro-image-preview",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "gemini-3-pro-image-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": 0.2,
                "output": 12,
                "videoGeneration": null
            },
            "description": "google state-of-the-art thinking model, capable of reasoning over complex problems in code, math, and STEM, as well as analyzing large datasets, codebases, and documents using long context.",
            "extendedThinking": true,
            "id": "gemini-3-pro-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-3-pro-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": 0.2,
                "output": 12,
                "videoGeneration": null
            },
            "description": "Gemini-3-pro-search integrates Google's official search functionality; the search feature incurs an additional separate fee log directly incorporated into the scoring, but the log details are not displayed; this will be fixed in the future to show the details; it only supports OpenAI-compatible format calls and does not support the Gemini SDK; for the Gemini native SDK, please directly set the official search parameters.",
            "extendedThinking": true,
            "id": "gemini-3-pro-preview-search",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["text"]
            },
            "name": "gemini-3-pro-preview-search",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.15,
                "inputCacheHit": null,
                "output": 0.15,
                "videoGeneration": null
            },
            "description": "Latest version",
            "extendedThinking": false,
            "id": "gemini-embedding-001",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "gemini-embedding-001",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.02,
                "inputCacheHit": null,
                "output": 0.02,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gemini-embedding-exp-03-07",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "gemini-embedding-exp-03-07",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": null,
                "output": 5,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gemini-exp-1114",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemini-exp-1114",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": null,
                "output": 5,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gemini-exp-1121",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemini-exp-1121",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": null,
                "output": 5,
                "videoGeneration": null
            },
            "description": "Google's latest experimental model, currently Google's most powerful model.",
            "extendedThinking": false,
            "id": "gemini-exp-1206",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemini-exp-1206",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.6,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gemini-pro",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemini-pro",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1,
                "inputCacheHit": null,
                "output": 1,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gemini-pro-vision",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemini-pro-vision",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.4,
                "inputCacheHit": null,
                "output": 0.4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gemma2-9b-it",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemma2-9b-it",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": 0,
                "output": 0.2,
                "videoGeneration": null
            },
            "description": "Gemma 3 models are multimodal, handling text and image input and generating text output, with open weights for both pre-trained variants and instruction-tuned variants. Gemma 3 has a large, 128K context window, multilingual support in over 140 languages, and is available in more sizes than previous versions. Gemma 3 models are well-suited for a variety of text generation and image understanding tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as laptops, desktops or your own cloud infrastructure, democratizing access to state of the art AI models and helping foster innovation for everyone.",
            "extendedThinking": false,
            "id": "gemma-3-1b-it",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemma-3-1b-it",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": 0,
                "output": 0.2,
                "videoGeneration": null
            },
            "description": "Gemma 3 models are multimodal, handling text and image input and generating text output, with open weights for both pre-trained variants and instruction-tuned variants. Gemma 3 has a large, 128K context window, multilingual support in over 140 languages, and is available in more sizes than previous versions. Gemma 3 models are well-suited for a variety of text generation and image understanding tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as laptops, desktops or your own cloud infrastructure, democratizing access to state of the art AI models and helping foster innovation for everyone.",
            "extendedThinking": false,
            "id": "gemma-3-27b-it",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemma-3-27b-it",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": 0,
                "output": 0.2,
                "videoGeneration": null
            },
            "description": "Gemma 3 models are multimodal, handling text and image input and generating text output, with open weights for both pre-trained variants and instruction-tuned variants. Gemma 3 has a large, 128K context window, multilingual support in over 140 languages, and is available in more sizes than previous versions. Gemma 3 models are well-suited for a variety of text generation and image understanding tasks, including question answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as laptops, desktops or your own cloud infrastructure, democratizing access to state of the art AI models and helping foster innovation for everyone.",
            "extendedThinking": false,
            "id": "gemma-3-4b-it",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemma-3-4b-it",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": 0,
                "output": 0.2,
                "videoGeneration": null
            },
            "description": "Gemma 3n is a generative AI model optimized for use in everyday devices, such as phones, laptops, and tablets. This model includes innovations in parameter-efficient processing, including Per-Layer Embedding (PLE) parameter caching and a MatFormer model architecture that provides the flexibility to reduce compute and memory requirements. These models feature audio input handling, as well as text and visual data.",
            "extendedThinking": false,
            "id": "gemma-3n-e4b-it",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemma-3n-e4b-it",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.71,
                "inputCacheHit": null,
                "output": 0.71,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "glm-3-turbo",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "glm-3-turbo",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 14.2,
                "inputCacheHit": null,
                "output": 14.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "glm-4",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "glm-4",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.4,
                "inputCacheHit": null,
                "output": 1.6,
                "videoGeneration": null
            },
            "description": "GLM-4.5",
            "extendedThinking": false,
            "id": "glm-4.5",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 98304
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "glm-4.5",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.14,
                "inputCacheHit": null,
                "output": 0.84,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "glm-4.5-air",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 98304
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "glm-4.5-air",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.1,
                "inputCacheHit": 0.22,
                "output": 4.51,
                "videoGeneration": null
            },
            "description": "GLM-4.5-AirX is the high-speed version of GLM-4.5-Air, with faster response times, specifically designed for large-scale high-speed demands.",
            "extendedThinking": false,
            "id": "glm-4.5-airx",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "glm-4.5-airx",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.274,
                "inputCacheHit": 0.274,
                "output": 0.822,
                "videoGeneration": null
            },
            "description": "GLM-4.5V is a vision-language foundational model designed for multimodal agent applications. Based on a mixture-of-experts (MoE) architecture, it has 106 billion parameters and 12 billion active parameters. It delivers outstanding performance in video understanding, image question answering, OCR, and document parsing, and achieves significant improvements in front-end web encoding, basic reasoning, and spatial reasoning.",
            "extendedThinking": false,
            "id": "glm-4.5v",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 64000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image", "video"],
                "output": ["text"]
            },
            "name": "glm-4.5v",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2.2,
                "inputCacheHit": 0.44,
                "output": 8.91,
                "videoGeneration": null
            },
            "description": "GLM-4.5-X is the high-speed version of GLM-4.5, offering powerful performance with a generation speed of up to 100 tokens per second.",
            "extendedThinking": false,
            "id": "glm-4.5-x",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "glm-4.5-x",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0,
                "inputCacheHit": 0,
                "output": 0,
                "videoGeneration": null
            },
            "description": "GLM-4.6 is Zhipu’s latest flagship model (total parameters 355B, activation parameters 32B), comprehensively surpassing GLM-4.5. Its coding capability is aligned with Claude Sonnet 4, making it a top domestic coding model; the context window has been expanded from 128K to 200K, better suited for long code and agent tasks; inference capabilities have been significantly enhanced and support tool invocation during processing; improvements have been made in tool calling, search agents, writing style, role play, and multilingual translation. The model is named glm-4.6 and is provided by three vendors, with calls prioritized to the Sophnet platform.",
            "extendedThinking": true,
            "id": "glm-4.6",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 204800,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "glm-4.6",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.137,
                "inputCacheHit": 0.0274,
                "output": 0.411,
                "videoGeneration": null
            },
            "description": "Zhipu's latest visual reasoning model achieves state-of-the-art visual understanding accuracy at the same scale upon release. It natively supports tool invocation, can automatically complete tasks, supports ultra-long 128K context length, and allows flexible toggling of reasoning.",
            "extendedThinking": false,
            "id": "glm-4.6v",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image", "video"],
                "output": ["text"]
            },
            "name": "glm-4.6v",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.273974,
                "inputCacheHit": 0.054795,
                "output": 1.095896,
                "videoGeneration": null
            },
            "description": "GLM-4.7 is Zhiyuan's latest flagship model. GLM-4.7 enhances coding capabilities, long-range task planning, and tool collaboration for Agentic Coding scenarios, achieving leading performance among open-source models on several current public benchmarks. It features improved general capabilities, with responses that are more concise and natural, and writing that is more immersive. When executing complex agent tasks and tool usage, it follows instructions more strictly, with further improvements in the frontend aesthetics of Artifacts and Agentic Coding as well as the efficiency of completing long-range tasks.",
            "extendedThinking": true,
            "id": "glm-4.7",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 128000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "glm-4.7",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "glm-4-flash",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "glm-4-flash",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 8,
                "inputCacheHit": null,
                "output": 8,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "glm-4-plus",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "glm-4-plus",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 14.2,
                "inputCacheHit": null,
                "output": 14.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "glm-4v",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "glm-4v",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "glm-4v-plus",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "glm-4v-plus",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": null
            },
            "description": "Simply put, it is the intelligent enhanced version of O1.",
            "extendedThinking": false,
            "id": "glm-zero-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "glm-zero-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.138,
                "inputCacheHit": null,
                "output": 0.138,
                "videoGeneration": null
            },
            "description": "The GME-Qwen2VL series is a unified multimodal Embedding model trained based on the Qwen2-VL multimodal large language model (MLLMs). The GME model supports three types of inputs: text, images, and image-text pairs. All these input types can generate universal vector representations and exhibit excellent retrieval performance.",
            "extendedThinking": false,
            "id": "gme-qwen2-vl-2b-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image", "video"],
                "output": ["embedding"]
            },
            "name": "gme-qwen2-vl-2b-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": null,
                "output": 5,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "google/gemini-exp-1114",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "google/gemini-exp-1114",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "google-gemma-3-12b-it",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "google-gemma-3-12b-it",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": 0,
                "output": 0.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "google-gemma-3-27b-it",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "google-gemma-3-27b-it",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": 0,
                "output": 0.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "google-gemma-3-4b-it",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "google-gemma-3-4b-it",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.5,
                "inputCacheHit": null,
                "output": 1.5,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-3.5-turbo-0301",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-3.5-turbo-0301",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.5,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-3.5-turbo-0613",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-3.5-turbo-0613",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-3.5-turbo-1106",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-3.5-turbo-1106",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 3,
                "inputCacheHit": null,
                "output": 4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-3.5-turbo-16k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-3.5-turbo-16k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 3,
                "inputCacheHit": null,
                "output": 4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-3.5-turbo-16k-0613",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-3.5-turbo-16k-0613",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.5,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-3.5-turbo-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-3.5-turbo-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 10,
                "inputCacheHit": null,
                "output": 30,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-4-0125-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-4-0125-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 30,
                "inputCacheHit": null,
                "output": 60,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-4-0314",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-4-0314",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 30,
                "inputCacheHit": null,
                "output": 60,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-4-0613",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-4-0613",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 10,
                "inputCacheHit": null,
                "output": 30,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-4-1106-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-4-1106-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 60,
                "inputCacheHit": null,
                "output": 120,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-4-32k-0314",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-4-32k-0314",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 60,
                "inputCacheHit": null,
                "output": 120,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-4-32k-0613",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-4-32k-0613",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 5,
                "inputCacheHit": 5,
                "output": 15,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-4o-2024-05-13",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-4o-2024-05-13",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2.5,
                "inputCacheHit": 1.25,
                "output": 10,
                "videoGeneration": null
            },
            "description": "Supports caching, with automatic halving of charges upon a cache hit.",
            "extendedThinking": false,
            "id": "gpt-4o-2024-08-06",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-4o-2024-08-06",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2.5,
                "inputCacheHit": 1.25,
                "output": 10,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-4o-2024-08-06-global",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-4o-2024-08-06-global",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2.5,
                "inputCacheHit": 1.25,
                "output": 10,
                "videoGeneration": null
            },
            "description": "The latest version of the GPT-4o model; it is recommended to use this version, as it is currently smarter than the regular 4o.",
            "extendedThinking": false,
            "id": "gpt-4o-2024-11-20",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-4o-2024-11-20",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2.5,
                "inputCacheHit": null,
                "output": 10,
                "videoGeneration": null
            },
            "description": "OpenAI voice input and output model, with prices consistent with the official ones. For now, only the text portion prices are displayed; voice prices can be found on the official OpenAI website. Backend billing is the same as the official.",
            "extendedThinking": false,
            "id": "gpt-4o-audio-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "audio"],
                "output": ["text"]
            },
            "name": "gpt-4o-audio-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 3,
                "input": 3,
                "inputCacheHit": 0,
                "output": 3,
                "videoGeneration": null
            },
            "description": "First Taste of GPT-4o's Image Generation API: Perfectly mirrors the web version's raw image creation capabilities, supporting both text-to-image and image+text-to-image generation. Each creation costs as little as $0.005.",
            "extendedThinking": false,
            "id": "gpt-4o-image",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "gpt-4o-image",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 7,
                "input": 7,
                "inputCacheHit": 0,
                "output": 7,
                "videoGeneration": null
            },
            "description": "First Taste of GPT-4o's Image Generation API: Perfectly mirrors the web version's raw image creation capabilities, supporting both text-to-image and image+text-to-image generation. Each creation costs as little as $0.009.",
            "extendedThinking": false,
            "id": "gpt-4o-image-vip",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "gpt-4o-image-vip",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.15,
                "inputCacheHit": 0.075,
                "output": 0.6,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-4o-mini-2024-07-18",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-4o-mini-2024-07-18",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.15,
                "inputCacheHit": null,
                "output": 0.6,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-4o-mini-audio-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "audio"],
                "output": ["text"]
            },
            "name": "gpt-4o-mini-audio-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.15,
                "inputCacheHit": 0.075,
                "output": 0.6,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-4o-mini-global",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-4o-mini-global",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.15,
                "inputCacheHit": 0.075,
                "output": 0.6,
                "videoGeneration": null
            },
            "description": "Using the Chat Completions API, you can directly access the fine-tuned models and tool used by Search in ChatGPT.\n\nWhen using Chat Completions, the model always retrieves information from the web before responding to your query. To use web_search_preview as a tool that models like gpt-4o and gpt-4o-mini invoke only when necessary, switch to using the Responses API.\n\nCurrently, you need to use one of these models to use web search in Chat Completions:\n\ngpt-4o-search-preview\ngpt-4o-mini-search-preview\nWeb search parameter example\nimport OpenAI from \"openai\";\nconst client = new OpenAI();\n\nconst completion = await client.chat.completions.create({\n    model: \"gpt-4o-search-preview\",\n    web_search_options: {},\n    messages: [{\n        \"role\": \"user\",\n        \"content\": \"What was a positive news story from today?\"\n    }],\n});\n\nconsole.log(completion.choices[0].message.content);\nOutput and citations\nThe API response item in the choices array will include:\n\nmessage.content with the text result from the model, inclusive of any inline citations\nannotations with a list of cited URLs\nBy default, the model's response will include inline citations for URLs found in the web search results. In addition to this, the url_citation annotation object will contain the URL and title of the cited source, as well as the start and end index characters in the model's response where those sources were used.",
            "extendedThinking": false,
            "id": "gpt-4o-mini-search-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-4o-mini-search-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 15,
                "inputCacheHit": null,
                "output": 15,
                "videoGeneration": null
            },
            "description": "OpenAI’s latest TTS model, gpt-4o-mini-tts, uses the same API endpoint (/v1/audio/speech) as tts-1. However, OpenAI introduced a new pricing method without providing billing details via API, causing discrepancies between official pricing and aihubmix’s charges—some requests may cost more, others less. Avoid using this model if precise billing accuracy is essential.",
            "extendedThinking": false,
            "id": "gpt-4o-mini-tts",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["audio"],
                "output": ["audio"]
            },
            "name": "gpt-4o-mini-tts",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2.5,
                "inputCacheHit": 1.25,
                "output": 10,
                "videoGeneration": null
            },
            "description": "Using the Chat Completions API, you can directly access the fine-tuned models and tool used by Search in ChatGPT.\n\nWhen using Chat Completions, the model always retrieves information from the web before responding to your query. To use web_search_preview as a tool that models like gpt-4o and gpt-4o-mini invoke only when necessary, switch to using the Responses API.\n\nCurrently, you need to use one of these models to use web search in Chat Completions:\n\ngpt-4o-search-preview\ngpt-4o-mini-search-preview\nWeb search parameter example\nimport OpenAI from \"openai\";\nconst client = new OpenAI();\n\nconst completion = await client.chat.completions.create({\n    model: \"gpt-4o-search-preview\",\n    web_search_options: {},\n    messages: [{\n        \"role\": \"user\",\n        \"content\": \"What was a positive news story from today?\"\n    }],\n});\n\nconsole.log(completion.choices[0].message.content);\nOutput and citations\nThe API response item in the choices array will include:\n\nmessage.content with the text result from the model, inclusive of any inline citations\nannotations with a list of cited URLs\nBy default, the model's response will include inline citations for URLs found in the web search results. In addition to this, the url_citation annotation object will contain the URL and title of the cited source, as well as the start and end index characters in the model's response where those sources were used.",
            "extendedThinking": false,
            "id": "gpt-4o-search-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-4o-search-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2.5,
                "inputCacheHit": null,
                "output": 10,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-4o-zh",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-4o-zh",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 10,
                "inputCacheHit": null,
                "output": 30,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-4-turbo-2024-04-09",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-4-turbo-2024-04-09",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 10,
                "inputCacheHit": null,
                "output": 30,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-4-turbo-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-4-turbo-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 10,
                "inputCacheHit": null,
                "output": 30,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-4-vision-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-4-vision-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": 0.125,
                "output": 10,
                "videoGeneration": null
            },
            "description": "GPT-5 is OpenAI’s most advanced general-purpose model, delivering major improvements in reasoning, code quality, and overall user experience. It is optimized for complex tasks that require step-by-step reasoning, precise instruction following, and high accuracy in high-stakes scenarios. The model supports test-time routing and advanced prompt understanding, including user-specified intent such as “think hard about this,” while significantly reducing hallucination and sycophancy and improving performance in coding, writing, and health-related tasks.",
            "extendedThinking": true,
            "id": "gpt-5",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-5",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix",
            "providerModelsDevId": "github-copilot"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": 0.125,
                "output": 10,
                "videoGeneration": null
            },
            "description": "GPT-5 is OpenAI’s most advanced language model, designed for complex tasks that require step-by-step reasoning, precise instruction following, and high reliability. It improves reasoning, code generation, and prompt understanding—including test-time routing and intent cues like “think hard about this”—while reducing hallucination and sycophancy.",
            "extendedThinking": true,
            "id": "gpt-5.1",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-5.1",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": 0.125,
                "output": 10,
                "videoGeneration": null
            },
            "description": "GPT-5.1 Chat refers to the GPT-5.1 snapshot currently used in ChatGPT and is optimized for conversational use cases. While GPT-5.1 is recommended for most API applications, GPT-5.1 Chat is ideal for testing the latest improvements in chat-based interactions.",
            "extendedThinking": false,
            "id": "gpt-5.1-chat-latest",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-5.1-chat-latest",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": 0.125,
                "output": 10,
                "videoGeneration": null
            },
            "description": "GPT-5.1-Codex is a version of GPT-5 optimized for agentic coding tasks in Codex or similar environments. It's available in the Responses API only and the underlying model snapshot will be regularly updated. ",
            "extendedThinking": true,
            "id": "gpt-5.1-codex",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-5.1-codex",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": 0.125,
                "output": 10,
                "videoGeneration": null
            },
            "description": "GPT-5.1-Codex-Max is a frontier programming model built for the agent-driven era. Powered by an upgraded core reasoning architecture, it is specially trained for complex agentic tasks in software engineering, mathematics, and scientific research. It delivers faster performance, greater stability, and higher token efficiency across the entire development lifecycle, including code generation, refactoring, debugging, and engineering collaboration. With native support for multiple context windows and a built-in compaction mechanism, the model can coherently process millions of tokens within a single task.",
            "extendedThinking": true,
            "id": "gpt-5.1-codex-max",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-5.1-codex-max",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.25,
                "inputCacheHit": 0.025,
                "output": 2,
                "videoGeneration": null
            },
            "description": "GPT-5.1 Codex mini is a smaller, more cost-effective, less-capable version of GPT-5.1-Codex.",
            "extendedThinking": true,
            "id": "gpt-5.1-codex-mini",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-5.1-codex-mini",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.75,
                "inputCacheHit": 0.175,
                "output": 14,
                "videoGeneration": null
            },
            "description": "GPT‑5.2 builds on GPT‑5.1 with improvements that make interactions more reliable, flexible, and user-friendly. The focus is on delivering clearer responses, better adaptability, and enhanced control for diverse tasks. Key highlights include:\n\nAccelerate agent development: Build AI agents for analytics, decision support, code modernization, and data pipelines.\nGreater consistency: Produces more predictable and accurate outputs aligned with user instructions.\nAdaptive reasoning: Handles complex queries with improved depth while remaining efficient for simpler tasks.\nExpanded context handling: Supports longer inputs for multi-step workflows and richer conversations.\nRefined customization: Offers better control over tone, style, and structured output for tailored experiences.\nBroader applicability: Strengthens performance across a wide range of domains while maintaining clarity and safety.",
            "extendedThinking": true,
            "id": "gpt-5.2",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-5.2",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.75,
                "inputCacheHit": 0.175,
                "output": 14,
                "videoGeneration": null
            },
            "description": "GPT-5.2Chat refers to the GPT-5.2 snapshot currently used in ChatGPT and is optimized for conversational use cases. While GPT-5.2 is recommended for most API applications, GPT-5.2Chat is ideal for testing the latest improvements in chat-based interactions.",
            "extendedThinking": false,
            "id": "gpt-5.2-chat-latest",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-5.2-chat-latest",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 21,
                "inputCacheHit": 2.1,
                "output": 168,
                "videoGeneration": null
            },
            "description": "GPT-5.2 pro is available in the Responses API only to enable support for multi-turn model interactions before responding to API requests, and other advanced API features in the future. Since GPT-5.2 pro is designed to tackle tough problems, some requests may take several minutes to finish. To avoid timeout, please set a longer timeout duration. It is recommended to use this under good network conditions.",
            "extendedThinking": true,
            "id": "gpt-5.2-pro",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-5.2-pro",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": 0.125,
                "output": 10,
                "videoGeneration": null
            },
            "description": "GPT-5 Chat points to the GPT-5 snapshot currently used in ChatGPT. GPT-5 is our next-generation, high-intelligence flagship model. It accepts both text and image inputs, and produces text outputs.",
            "extendedThinking": false,
            "id": "gpt-5-chat-latest",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-5-chat-latest",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": 0.125,
                "output": 10,
                "videoGeneration": null
            },
            "description": "GPT-5-Codex is a version of GPT-5 optimized for autonomous coding tasks in Codex or similar environments. It is only available in the Responses API, and the underlying model snapshots will be updated regularly. https://docs.aihubmix.com/en/api/Responses-API You can also use it in codex-cll; see https://docs.aihubmix.com/en/api/Codex-CLI for using codex-cll through Aihubmix.",
            "extendedThinking": true,
            "id": "gpt-5-codex",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-5-codex",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix",
            "providerModelsDevId": "github-copilot"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.25,
                "inputCacheHit": 0.025,
                "output": 2,
                "videoGeneration": null
            },
            "description": "GPT-5 mini is a faster, more cost-efficient version of GPT-5. It's great for well-defined tasks and precise prompts.",
            "extendedThinking": true,
            "id": "gpt-5-mini",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-5-mini",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix",
            "providerModelsDevId": "github-copilot"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.05,
                "inputCacheHit": 0.005,
                "output": 0.4,
                "videoGeneration": null
            },
            "description": "GPT-5-Nano is the smallest and fastest variant in the GPT-5 system, designed specifically for developer tools and environments that demand rapid interactions and ultra-low latency. While it offers a more lightweight solution with limited reasoning depth compared to its larger counterparts, GPT-5-Nano excels in core capabilities such as instruction-following and maintaining critical safety features. As the successor to GPT-4.1-nano, it provides an optimal choice for cost-sensitive or real-time applications, where efficiency and speed are paramount. Particularly well-suited for summarization and classification tasks, GPT-5-Nano is a powerful tool for developers needing a swift, reliable AI model for streamlined processes.",
            "extendedThinking": true,
            "id": "gpt-5-nano",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-5-nano",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 15,
                "inputCacheHit": null,
                "output": 120,
                "videoGeneration": null
            },
            "description": "GPT-5 pro uses more compute to think harder and provide consistently better answers.\n\nGPT-5 pro is available in the Responses API only to enable support for multi-turn model interactions before responding to API requests, and other advanced API features in the future. Since GPT-5 pro is designed to tackle tough problems, some requests may take several minutes to finish. To avoid timeouts, try using background mode. As our most advanced reasoning model, GPT-5 pro defaults to (and only supports) reasoning.effort: high. GPT-5 pro does not support code interpreter.",
            "extendedThinking": true,
            "id": "gpt-5-pro",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-5-pro",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 5,
                "input": 5,
                "inputCacheHit": 5,
                "output": 40,
                "videoGeneration": null
            },
            "description": "Azure OpenAI’s gpt-image-1 image generation API offers both text-to-image generation and image-to-image editing with text guidance capabilities.\nBefore using this API, please ensure you have the latest OpenAI package installed by running pip install -U openai.",
            "extendedThinking": false,
            "id": "gpt-image-1",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "gpt-image-1",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 5,
                "input": 5,
                "inputCacheHit": 5,
                "output": 10,
                "videoGeneration": null
            },
            "description": "GPT Image 1.5 is a new image generation model powered by OpenAI’s flagship visual capabilities, comprehensively upgraded for high-quality creative and production workflows. It delivers significant improvements in instruction understanding, fine-grained image editing, and detail preservation, while achieving up to 4× faster generation compared to previous versions — reducing latency without compromising quality.\n\nGPT Image 1.5 is well suited for image generation, precise visual editing, and professional content creation, balancing performance with efficiency.",
            "extendedThinking": false,
            "id": "gpt-image-1.5",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "gpt-image-1.5",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 5,
                "input": 5,
                "inputCacheHit": 5,
                "output": 40,
                "videoGeneration": null
            },
            "description": "OpenAI image generation model gpt-image-1-mini\nBefore use, please run pip install -U openai to upgrade to the latest openai package.",
            "extendedThinking": false,
            "id": "gpt-image-1-mini",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "gpt-image-1-mini",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 5,
                "inputCacheHit": 0,
                "output": 40,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "gpt-image-test",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-image-test",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.18,
                "inputCacheHit": null,
                "output": 0.9,
                "videoGeneration": null
            },
            "description": "gpt-oss-120b is a 117B-parameter open-weight Mixture-of-Experts (MoE) language model from OpenAI, designed for high-reasoning, agentic, and general-purpose production use cases. Activating just 5.1B parameters per pass, it is optimized to run on a single H100 GPU with native MXFP4 quantization. The model features configurable reasoning depth, full chain-of-thought access, and native tool use, including function calling, browsing, and structured output generation.",
            "extendedThinking": true,
            "id": "gpt-oss-120b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-oss-120b",
            "openWeights": true,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix",
            "audioGeneration": false,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.11,
                "inputCacheHit": null,
                "output": 0.55,
                "videoGeneration": null
            },
            "description": "gpt-oss-20b is a 21-billion parameter open-weight model released by OpenAI under the Apache 2.0 license. Its core feature is a Mixture-of-Experts (MoE) architecture that uses only 3.6B active parameters, enabling low-latency inference and deployment on consumer GPUs. The model also supports fine-tuning, function calling, tool use, and structured outputs.",
            "extendedThinking": true,
            "id": "gpt-oss-20b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 128000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-oss-20b",
            "openWeights": true,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix",
            "audioGeneration": false,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.11,
                "inputCacheHit": null,
                "output": 0.55,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "GPT-OSS-20B",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GPT-OSS-20B",
            "openWeights": true,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.8,
                "inputCacheHit": null,
                "output": 9,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "grok-2-1212",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "grok-2-1212",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 3,
                "inputCacheHit": 0,
                "output": 15,
                "videoGeneration": null
            },
            "description": "Grok's latest model\nThis model ID with beta has been officially taken offline. Using this model grok-3-beta will automatically point to grok-3.",
            "extendedThinking": false,
            "id": "grok-3-beta",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "grok-3-beta",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 5.5,
                "inputCacheHit": 0,
                "output": 27.5,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "grok-3-fast-beta",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "grok-3-fast-beta",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.33,
                "inputCacheHit": 0,
                "output": 0.5511,
                "videoGeneration": null
            },
            "description": "This model ID with beta has been officially taken offline. Using this model grok-3-mini-beta will automatically point to grok-3-mini.",
            "extendedThinking": false,
            "id": "grok-3-mini-beta",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "grok-3-mini-beta",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.33,
                "inputCacheHit": null,
                "output": 2.20011,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "grok-3-mini-fast-beta",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "grok-3-mini-fast-beta",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 3.3,
                "inputCacheHit": 0.825,
                "output": 16.5,
                "videoGeneration": null
            },
            "description": "Grok, their latest and greatest flagship model, offers unparalleled performance in natural language, math, and reasoning – the perfect jack of all trades.\nThe current pointing model version is grok-4-0709.",
            "extendedThinking": false,
            "id": "grok-4",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 64000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "grok-4",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": 0.05,
                "output": 0.5,
                "videoGeneration": null
            },
            "description": "Grok 4.1 is a new conversational model with significant improvements in real-world usability, delivering exceptional performance in creative, emotional, and collaborative interactions. It is more perceptive to nuanced user intent, more engaging to converse with, and more coherent in personality, while fully preserving its core intelligence and reliability. Built on large-scale reinforcement learning infrastructure, the model is optimized for style, personality, helpfulness, and alignment, and leverages frontier agentic reasoning models as reward evaluators to autonomously assess and iterate on responses at scale, significantly enhancing overall interaction quality.",
            "extendedThinking": true,
            "id": "grok-4-1-fast-non-reasoning",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2000000,
                "output": 2000000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "grok-4-1-fast-non-reasoning",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": 0.05,
                "output": 0.5,
                "videoGeneration": null
            },
            "description": "Grok 4.1 is a new conversational model with significant improvements in real-world usability, delivering exceptional performance in creative, emotional, and collaborative interactions. It is more perceptive to nuanced user intent, more engaging to converse with, and more coherent in personality, while fully preserving its core intelligence and reliability. Built on large-scale reinforcement learning infrastructure, the model is optimized for style, personality, helpfulness, and alignment, and leverages frontier agentic reasoning models as reward evaluators to autonomously assess and iterate on responses at scale, significantly enhancing overall interaction quality.",
            "extendedThinking": true,
            "id": "grok-4-1-fast-reasoning",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2000000,
                "output": 2000000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "grok-4-1-fast-reasoning",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": 0.05,
                "output": 0.5,
                "videoGeneration": null
            },
            "description": "Grok-4-fast is a cost-effective inference model developed by xAI that delivers cutting-edge performance with excellent token efficiency. The model features a 2 million token context window, advanced Web and X search capabilities, and a unified architecture supporting both \"inference\" and \"non-inference\" modes. Compared to Grok 4, it reduces thinking tokens by an average of 40% and lowers the price by 98% while achieving the same performance.",
            "extendedThinking": false,
            "id": "grok-4-fast-non-reasoning",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2000000,
                "output": 30000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "grok-4-fast-non-reasoning",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": 0.05,
                "output": 0.5,
                "videoGeneration": null
            },
            "description": "Grok-4-fast is a cost-effective inference model developed by xAI that delivers cutting-edge performance with excellent token efficiency. The model features a 2 million token context window, advanced Web and X search capabilities, and a unified architecture supporting both \"inference\" and \"non-inference\" modes. Compared to Grok 4, it reduces thinking tokens by an average of 40% and lowers the price by 98% while achieving the same performance.",
            "extendedThinking": false,
            "id": "grok-4-fast-reasoning",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2000000,
                "output": 30000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "grok-4-fast-reasoning",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": 0.05,
                "output": 0.5,
                "videoGeneration": null
            },
            "description": "Grok 4.1 is a new conversational model with significant improvements in real-world usability, delivering exceptional performance in creative, emotional, and collaborative interactions. It is more perceptive to nuanced user intent, more engaging to converse with, and more coherent in personality, while fully preserving its core intelligence and reliability. Built on large-scale reinforcement learning infrastructure, the model is optimized for style, personality, helpfulness, and alignment, and leverages frontier agentic reasoning models as reward evaluators to autonomously assess and iterate on responses at scale, significantly enhancing overall interaction quality.",
            "extendedThinking": true,
            "id": "grok-code-fast-1",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2000000,
                "output": 2000000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "grok-code-fast-1",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix",
            "providerModelsDevId": "github-copilot"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 5.6,
                "inputCacheHit": null,
                "output": 16.8,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "grok-vision-beta",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "grok-vision-beta",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.055,
                "inputCacheHit": null,
                "output": 0.088,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "groq-llama-3.1-8b-instant",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "groq-llama-3.1-8b-instant",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.649,
                "inputCacheHit": null,
                "output": 0.869011,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "groq-llama-3.3-70b-versatile",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "groq-llama-3.3-70b-versatile",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.22,
                "inputCacheHit": null,
                "output": 0.66,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "groq-llama-4-maverick-17b-128e-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "groq-llama-4-maverick-17b-128e-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.122,
                "inputCacheHit": null,
                "output": 0.366,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "groq-llama-4-scout-17b-16e-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "groq-llama-4-scout-17b-16e-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.4,
                "inputCacheHit": null,
                "output": 0.4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Gryphe/MythoMax-L2-13b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gryphe/MythoMax-L2-13b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.11,
                "inputCacheHit": null,
                "output": 0.11,
                "videoGeneration": null
            },
            "description": "gte-rerank-v2 is a multilingual unified text ranking model developed by Tongyi Lab, covering multiple major languages worldwide and providing high-quality text ranking services. It is typically used in scenarios such as semantic retrieval and RAG, and can simply and effectively improve text retrieval performance. Given a query and a set of candidate texts (documents), the model ranks the candidates from highest to lowest based on their semantic relevance to the query.",
            "extendedThinking": false,
            "id": "gte-rerank-v2",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["score"]
            },
            "name": "gte-rerank-v2",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 0,
                "output": 2,
                "videoGeneration": null
            },
            "description": "Imagen 3.0 is Google's latest text-to-image generation model, capable of creating high-quality images from natural language prompts. Compared to its predecessors, Imagen 3.0 offers significant improvements in detail, lighting, and reduced visual artifacts. It supports rendering in various artistic styles, from photorealism to impressionism, as well as abstract and anime styles.",
            "extendedThinking": false,
            "id": "imagen-3.0-generate-002",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "imagen-3.0-generate-002",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 0,
                "output": 2,
                "videoGeneration": null
            },
            "description": "Imagen 4 is a high-quality text-to-image model developed by Google, designed for strong visual fidelity, diverse artistic styles, and precise controllability. It delivers near photographic realism with sharp details and natural lighting while significantly reducing common artifacts such as distorted hands. The model supports a wide range of styles including photorealistic, illustration, anime, oil painting, and pixel art, and offers flexible aspect ratios for use cases from content covers to mobile wallpapers. It also enables image editing and secondary creation on existing images, provides fast and stable generation, and offers strong commercial usability with high visual quality and reliable content safety.",
            "extendedThinking": false,
            "id": "imagen-4.0",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "imagen-4.0",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": null
            },
            "description": "Imagen 4 is a new-generation image generation model designed to balance high-quality output, inference efficiency, and content safety. It supports image generation, digital watermarking with authenticity verification, user-configurable safety settings, and prompt enhancement via the Prompt Rewriter, while also delivering reliable person generation capabilities. The model ID is imagen-4.0-generate-001, making it suitable for professional creation, design workflows, and various generative AI applications.",
            "extendedThinking": false,
            "id": "imagen-4.0-fast-generate-001",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "imagen-4.0-fast-generate-001",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "imagen-4.0-fast-generate-preview-06-06",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "imagen-4.0-fast-generate-preview-06-06",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": null
            },
            "description": "Imagen 4 is a new-generation image generation model designed to balance high-quality output, inference efficiency, and content safety. It supports image generation, digital watermarking with authenticity verification, user-configurable safety settings, and prompt enhancement via the Prompt Rewriter, while also delivering reliable person generation capabilities. The model ID is imagen-4.0-generate-001, making it suitable for professional creation, design workflows, and various generative AI applications.",
            "extendedThinking": false,
            "id": "imagen-4.0-generate-001",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "imagen-4.0-generate-001",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 0,
                "output": 2,
                "videoGeneration": null
            },
            "description": "Google's latest raw image model",
            "extendedThinking": false,
            "id": "imagen-4.0-generate-preview-05-20",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "imagen-4.0-generate-preview-05-20",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 0,
                "output": 2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "imagen-4.0-ultra",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "imagen-4.0-ultra",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "imagen-4.0-ultra-generate-001",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "imagen-4.0-ultra-generate-001",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 0,
                "output": 2,
                "videoGeneration": null
            },
            "description": "Image 4.0 Beta version, for testing purposes only. For production environment, it is recommended to use imagen-4.0-generate-preview-05-20.",
            "extendedThinking": false,
            "id": "imagen-4.0-ultra-generate-exp-05-20",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "imagen-4.0-ultra-generate-exp-05-20",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.548,
                "inputCacheHit": null,
                "output": 2.192,
                "videoGeneration": null
            },
            "description": "Ling-1T is the first flagship non-thinking model in the “Ling 2.0” series, featuring 1 trillion total parameters and approximately 50 billion active parameters per token. Built on the Ling 2.0 architecture, Ling-1T is designed to push the limits of efficient inference and scalable cognition. Ling-1T-base was pretrained on over 20 trillion high-quality, reasoning-intensive tokens, supports up to a 128K context length, and incorporates an Evolutionary Chain of Thought (Evo-CoT) process during mid-stage and post-stage training. This training regimen greatly enhances the model’s efficiency and depth of reasoning, enabling Ling-1T to achieve top performance across multiple complex reasoning benchmarks, balancing accuracy and efficiency.",
            "extendedThinking": false,
            "id": "inclusionAI/Ling-1T",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "inclusionAI/Ling-1T",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.136,
                "inputCacheHit": null,
                "output": 0.544,
                "videoGeneration": null
            },
            "description": "Ling-flash-2.0 is a language model from inclusionAI with a total of 100 billion parameters, of which 6.1 billion are activated per token (4.8 billion non-embedding). As part of the Ling 2.0 architecture series, it is designed as a lightweight yet powerful Mixture-of-Experts (MoE) model. It aims to deliver performance comparable to or even exceeding that of 40B-level dense models and other larger MoE models, but with a significantly smaller active parameter count. The model represents a strategy focused on achieving high performance and efficiency through extreme architectural design and training methods.",
            "extendedThinking": false,
            "id": "inclusionAI/Ling-flash-2.0",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "inclusionAI/Ling-flash-2.0",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.068,
                "inputCacheHit": null,
                "output": 0.272,
                "videoGeneration": null
            },
            "description": "Ling-mini-2.0 is a small-sized, high-performance large language model based on the MoE architecture. It has a total of 16 billion parameters, but only activates 1.4 billion parameters per token (non-embedding 789 million), achieving extremely high generation speed. Thanks to the efficient MoE design and large-scale high-quality training data, despite activating only 1.4 billion parameters, Ling-mini-2.0 still demonstrates top-tier performance on downstream tasks comparable to dense LLMs under 10 billion parameters and even larger-scale MoE models.",
            "extendedThinking": false,
            "id": "inclusionAI/Ling-mini-2.0",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "inclusionAI/Ling-mini-2.0",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.548,
                "inputCacheHit": null,
                "output": 2.192,
                "videoGeneration": null
            },
            "description": "Ring-1T is an open-source idea model with a trillion parameters released by the Bailing team. It is based on the Ling 2.0 architecture and the Ling-1T-base foundational model for training, with a total parameter count of 1 trillion, an active parameter count of 50 billion, and supports up to a 128K context window. The model is trained via large-scale verifiable reward reinforcement learning (RLVR), combined with the self-developed Icepop reinforcement learning stabilization method and the efficient ASystem reinforcement learning system, significantly improving the model’s deep reasoning and natural language reasoning capabilities. Ring-1T achieves leading performance among open-source models on high-difficulty reasoning benchmarks such as mathematics competitions (e.g., IMO 2025), code generation (e.g., ICPC World Finals 2025), and logical reasoning.",
            "extendedThinking": true,
            "id": "inclusionAI/Ring-1T",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "inclusionAI/Ring-1T",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.136,
                "inputCacheHit": null,
                "output": 0.544,
                "videoGeneration": null
            },
            "description": "Ring-flash-2.0 is a high-performance thinking model deeply optimized based on the Ling-flash-2.0-base. It uses a mixture-of-experts (MoE) architecture with a total of 100 billion parameters, but only activates 6.1 billion parameters per inference. The model employs the original Icepop algorithm to solve the instability issues of large MoE models during reinforcement learning (RL) training, enabling its complex reasoning capabilities to continuously improve over long training cycles. Ring-flash-2.0 has achieved significant breakthroughs on multiple high-difficulty benchmarks, including mathematics competitions, code generation, and logical reasoning. Its performance not only surpasses top dense models under 40 billion parameters but also rivals larger open-source MoE models and closed-source high-performance thinking models. Although the model focuses on complex reasoning, it also performs exceptionally well on creative writing tasks. Furthermore, thanks to its efficient architecture, Ring-flash-2.0 delivers high performance with low-latency inference, significantly reducing deployment costs in high-concurrency scenarios.",
            "extendedThinking": true,
            "id": "inclusionAI/Ring-flash-2.0",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "inclusionAI/Ring-flash-2.0",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 0,
                "output": 0,
                "videoGeneration": null
            },
            "description": "Baidu's self-developed ERNIE iRAG (ERNIE image-based RAG), a retrieval-augmented text-to-image technology, combines Baidu Search's hundreds of millions of image resources with powerful foundational model capabilities to generate various ultra-realistic images. The overall effect far surpasses native text-to-image systems, eliminating the typical AI feel while maintaining low costs. ERNIE iRAG features no hallucinations, ultra-realism, and instant usability.",
            "extendedThinking": false,
            "id": "irag-1.0",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image"]
            },
            "name": "irag-1.0",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 0,
                "videoGeneration": 2
            },
            "description": "DreamVideo 3.0 Pro is a professional-grade text-to-video and image-to-video model built on the Dream framework, delivering a major breakthrough in video generation quality. This version demonstrates strong performance across multiple dimensions, including narrative coherence, instruction following, dynamic fluidity, and visual detail. It supports multi-shot storytelling and generates 1080P high-definition videos with a professional cinematic texture. The model also enables diverse and expressive stylistic rendering, making it well suited for creative production and visual storytelling.",
            "extendedThinking": false,
            "id": "jimeng-3.0-1080p",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["video"]
            },
            "name": "jimeng-3.0-1080p",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 0,
                "videoGeneration": 2
            },
            "description": "DreamVideo 3.0 Pro is a professional-grade text-to-video and image-to-video model built on the Dream framework, delivering a major breakthrough in video generation quality. This version demonstrates strong performance across multiple dimensions, including narrative coherence, instruction following, dynamic fluidity, and visual detail. It supports multi-shot storytelling and generates 1080P high-definition videos with a professional cinematic texture. The model also enables diverse and expressive stylistic rendering, making it well suited for creative production and visual storytelling.",
            "extendedThinking": false,
            "id": "jimeng-3.0-720p",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["video"]
            },
            "name": "jimeng-3.0-720p",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 0,
                "videoGeneration": 2
            },
            "description": "DreamVideo 3.0 Pro is a professional-grade text-to-video and image-to-video model built on the Dream framework, delivering a major breakthrough in video generation quality. This version demonstrates strong performance across multiple dimensions, including narrative coherence, instruction following, dynamic fluidity, and visual detail. It supports multi-shot storytelling and generates 1080P high-definition videos with a professional cinematic texture. The model also enables diverse and expressive stylistic rendering, making it well suited for creative production and visual storytelling.",
            "extendedThinking": false,
            "id": "jimeng-3.0-pro",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["video"]
            },
            "name": "jimeng-3.0-pro",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.05,
                "inputCacheHit": null,
                "output": 0.05,
                "videoGeneration": null
            },
            "description": "Multi-modal Embeddings Model, multilingual, 1024-dimensional, 865M parameters.",
            "extendedThinking": false,
            "id": "jina-clip-v2",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["embedding"]
            },
            "name": "jina-clip-v2",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.05,
                "inputCacheHit": null,
                "output": 0.05,
                "videoGeneration": null
            },
            "description": "Multi-language ColBERT embeddings model, 560M parameters, used for embedding and reranking.",
            "extendedThinking": false,
            "id": "jina-colbert-v2",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "jina-colbert-v2",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.05,
                "inputCacheHit": null,
                "output": 0.05,
                "videoGeneration": null
            },
            "description": "DeepSearch combines search, reading, and reasoning capabilities to pursue the best possible answer. It's fully compatible with OpenAI's Chat API format—just replace api.openai.com with aihubmix.com to get started.  \nThe stream will return the thinking process.",
            "extendedThinking": true,
            "id": "jina-deepsearch-v1",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1000000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "jina-deepsearch-v1",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.05,
                "inputCacheHit": null,
                "output": 0.05,
                "videoGeneration": null
            },
            "description": "Model optimized for code and document search, 768-dimensional, 137M parameters.",
            "extendedThinking": false,
            "id": "jina-embeddings-v2-base-code",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "jina-embeddings-v2-base-code",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.05,
                "inputCacheHit": 0,
                "output": 0.05,
                "videoGeneration": null
            },
            "description": "Text Embeddings Model, multilingual, 1024-dimensional, 570M parameters.",
            "extendedThinking": false,
            "id": "jina-embeddings-v3",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "jina-embeddings-v3",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.05,
                "inputCacheHit": null,
                "output": 0.05,
                "videoGeneration": null
            },
            "description": "A general-purpose vector model with 3.8 billion parameters, used for multimodal and multilingual retrieval, supporting both unidirectional and multi-vector embedding outputs.",
            "extendedThinking": false,
            "id": "jina-embeddings-v4",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["embedding"]
            },
            "name": "jina-embeddings-v4",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.05,
                "inputCacheHit": null,
                "output": 0.05,
                "videoGeneration": null
            },
            "description": "Multimodal multilingual document reranker, 10K context, 2.4B parameters, for visual document sorting.",
            "extendedThinking": false,
            "id": "jina-reranker-m0",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["score"]
            },
            "name": "jina-reranker-m0",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.05,
                "inputCacheHit": null,
                "output": 0.05,
                "videoGeneration": null
            },
            "description": "Multimodal multilingual document reranker, 131K context, 0.6B parameters, for visual document sorting.",
            "extendedThinking": false,
            "id": "jina-reranker-v3",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["score"]
            },
            "name": "jina-reranker-v3",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.137,
                "inputCacheHit": null,
                "output": 0.548,
                "videoGeneration": null
            },
            "description": "KAT-Dev (32B) is an open-source 32B parameter model specifically designed for software engineering tasks. It achieved a 62.4% resolution rate on the SWE-Bench Verified benchmark, ranking fifth among all open-source models of various scales. The model is optimized through multiple stages, including intermediate training, supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT), as well as large-scale agent reinforcement learning (RL). Based on Qwen3-32B, its training process lays the foundation for subsequent fine-tuning and reinforcement learning stages by enhancing fundamental abilities such as tool usage, multi-turn interaction, and instruction following. During the fine-tuning phase, the model not only learns eight carefully curated task types and programming scenarios but also innovatively introduces a reinforcement fine-tuning (RFT) stage guided by human engineer-annotated “teacher trajectories.” The final agent reinforcement learning phase addresses scalability challenges through multi-level prefix caching, entropy-based trajectory pruning, and efficient architecture.",
            "extendedThinking": false,
            "id": "kat-dev",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "kat-dev",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0,
                "inputCacheHit": 0,
                "output": 0,
                "videoGeneration": null
            },
            "description": "kimi-for-coding-free is a free and open version offered by AIHubMix specifically for Kimi users. To maintain stable service operations, the following usage limits apply: a maximum of 5 requests per minute 500 total requests per day, and a daily quota of 1 million tokens.",
            "extendedThinking": true,
            "id": "kimi-for-coding-free",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 256000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "kimi-for-coding-free",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.548,
                "inputCacheHit": null,
                "output": 2.192,
                "videoGeneration": null
            },
            "description": "Kimi-K2-0905 is a large-scale Mixture of Experts (MoE) language model developed by Moonshot AI, with a total of 1 trillion parameters and 32 billion active parameters per forward pass. It supports long-context inference of up to 256k tokens, an expansion from the previous 128k.",
            "extendedThinking": false,
            "id": "Kimi-K2-0905",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 262144
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kimi-K2-0905",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.54,
                "inputCacheHit": null,
                "output": 2.16,
                "videoGeneration": null
            },
            "description": "Kimi-K2 is a MoE architecture foundational model with extremely powerful coding and agent capabilities, featuring a total of 1 trillion parameters and activating 32 billion parameters. In benchmark performance tests across major categories such as general knowledge reasoning, programming, mathematics, and agents, the K2 model outperforms other mainstream open-source models.\nThe Kimi-K2 model supports a context length of 128k tokens.\nIt does not support visual capabilities.",
            "extendedThinking": false,
            "id": "kimi-k2-0711",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131000,
                "output": 131000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "kimi-k2-0711",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.2,
                "inputCacheHit": 0.3,
                "output": 4.8,
                "videoGeneration": null
            },
            "description": "The kimi-k2-turbo-preview model is a high-speed version of kimi-k2, with the same model parameters as kimi-k2, but the output speed has been increased from 10 tokens per second to 40 tokens per second.",
            "extendedThinking": false,
            "id": "kimi-k2-turbo-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 262144
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "kimi-k2-turbo-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 30,
                "inputCacheHit": null,
                "output": 30,
                "videoGeneration": null
            },
            "description": "The latest kimi model.",
            "extendedThinking": false,
            "id": "kimi-thinking-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "kimi-thinking-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.25,
                "inputCacheHit": null,
                "output": 5,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "learnlm-1.5-pro-experimental",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "learnlm-1.5-pro-experimental",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.5,
                "inputCacheHit": null,
                "output": 0.5,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "llama2-70b-4096",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama2-70b-4096",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.5,
                "inputCacheHit": null,
                "output": 0.5,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "llama2-70b-40960",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama2-70b-40960",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "llama2-7b-2048",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama2-7b-2048",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 4,
                "inputCacheHit": null,
                "output": 4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "llama-3.1-405b-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3.1-405b-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 4,
                "inputCacheHit": null,
                "output": 4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "llama-3.1-405b-reasoning",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3.1-405b-reasoning",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.44,
                "inputCacheHit": null,
                "output": 0.44,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "llama-3.1-70b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3.1-70b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.6,
                "inputCacheHit": null,
                "output": 0.6,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "llama-3.1-70b-versatile",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3.1-70b-versatile",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.3,
                "inputCacheHit": null,
                "output": 0.6,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "llama-3.1-8b-instant",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3.1-8b-instant",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 5.6,
                "inputCacheHit": null,
                "output": 5.6,
                "videoGeneration": null
            },
            "description": "On February 22, 2025, this model will be officially discontinued. The Perplexity AI official fine-tuned LLMA internet-connected interface is currently only supported at the api.aihubmix.com address.",
            "extendedThinking": false,
            "id": "llama-3.1-sonar-huge-128k-online",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3.1-sonar-huge-128k-online",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.2,
                "inputCacheHit": null,
                "output": 1.2,
                "videoGeneration": null
            },
            "description": "On February 22, 2025, this model will be officially discontinued; Perplexity AI's official fine-tuned LLMA internet-connected interface is currently only supported at the api.aihubmix.com address.",
            "extendedThinking": false,
            "id": "llama-3.1-sonar-large-128k-online",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3.1-sonar-large-128k-online",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.3,
                "inputCacheHit": null,
                "output": 0.3,
                "videoGeneration": null
            },
            "description": "On February 22, 2025, this model will be officially discontinued. The Perplexity AI official fine-tuned LLMA online interface is currently supported only at the api.aihubmix.com address.",
            "extendedThinking": false,
            "id": "llama-3.1-sonar-small-128k-online",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3.1-sonar-small-128k-online",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "llama-3.2-11b-vision-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3.2-11b-vision-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "llama-3.2-1b-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3.2-1b-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "llama-3.2-3b-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3.2-3b-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2.4,
                "inputCacheHit": null,
                "output": 2.4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "llama-3.2-90b-vision-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3.2-90b-vision-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.6,
                "inputCacheHit": null,
                "output": 0.6,
                "videoGeneration": null
            },
            "description": "The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out). The Llama 3.3 instruction tuned text only model is optimized for multilingual dialogue use cases and outperforms many of the available open source and closed chat models on common industry benchmarks.",
            "extendedThinking": false,
            "id": "llama-3.3-70b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3.3-70b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2.65,
                "inputCacheHit": null,
                "output": 2.65,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "llama3-70b-8192(33)",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama3-70b-8192(33)",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.7,
                "inputCacheHit": null,
                "output": 0.937288,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "llama3-70b-8192",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama3-70b-8192",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.3,
                "inputCacheHit": null,
                "output": 0.3,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "llama3-8b-8192(33)",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama3-8b-8192(33)",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.06,
                "inputCacheHit": null,
                "output": 0.12,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "llama3-8b-8192",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama3-8b-8192",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.00089,
                "inputCacheHit": null,
                "output": 0.00089,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "llama3-groq-70b-8192-tool-use-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama3-groq-70b-8192-tool-use-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.00019,
                "inputCacheHit": null,
                "output": 0.00019,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "llama3-groq-8b-8192-tool-use-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama3-groq-8b-8192-tool-use-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2,
                "videoGeneration": null
            },
            "description": "Llama 4 Maverick is a high-capacity Mixture-of-Experts (MoE) model from Meta, featuring 400B total parameters and 128 experts, while activating an efficient 17B parameters per inference. Engineered for peak performance, it excels at advanced multimodal tasks.\n\nMaverick natively supports text and image input, producing multilingual text and code. With a 1-million-token context window and instruction tuning, it is optimized for complex image reasoning and general-purpose assistant-like interactions.\n\nReleased under the Llama 4 Community License, Maverick is ideal for research and commercial applications demanding state-of-the-art multimodal understanding and high throughput.",
            "extendedThinking": false,
            "id": "llama-4-maverick",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 32000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "llama-4-maverick",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2,
                "videoGeneration": null
            },
            "description": "Llama 4 Scout is a highly efficient Mixture-of-Experts (MoE) model from Meta, activating 17B out of 109B total parameters per inference. It natively supports multimodal input (text and image) and multilingual output (text and code) across 12 languages.\n\nDesigned for assistant-style interaction and visual reasoning, Scout features a massive 10-million-token context window. It is instruction-tuned for tasks like multilingual chat and image understanding and is released under the Llama 4 Community License for local or commercial deployment.",
            "extendedThinking": false,
            "id": "llama-4-scout",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131000,
                "output": 131000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "llama-4-scout",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.14,
                "inputCacheHit": null,
                "output": 0.7,
                "videoGeneration": null
            },
            "description": "Meituan has officially released and open-sourced LongCat-Flash-Chat, which utilizes an innovative Mixture of Experts (MoE) and \"zero-computation expert\" mechanism to achieve a total of 560B parameters, while only activating around 27B parameters per token as needed. At the same time, end-to-end optimization for agents (including a self-built evaluation set and multi-agent trajectory data) significantly enhances its performance in tool usage and complex task orchestration.",
            "extendedThinking": false,
            "id": "LongCat-Flash-Chat",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "LongCat-Flash-Chat",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 5,
                "inputCacheHit": null,
                "output": 5,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "meta/llama-3.1-405b-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 10000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "meta/llama-3.1-405b-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2024-07-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 4.795,
                "inputCacheHit": null,
                "output": 4.795,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "meta-llama-3-70b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "meta-llama-3-70b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.3,
                "inputCacheHit": null,
                "output": 0.3,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "meta/llama3-8B-chat",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "meta/llama3-8B-chat",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.02,
                "inputCacheHit": null,
                "output": 0.02,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-3.1-70b-instruct:free",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "meta-llama/llama-3.1-70b-instruct:free",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.02,
                "inputCacheHit": null,
                "output": 0.02,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-3.1-8b-instruct:free",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "meta-llama/llama-3.1-8b-instruct:free",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.5,
                "inputCacheHit": null,
                "output": 0.5,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "meta-llama/Llama-3.2-90B-Vision-Instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "meta-llama/Llama-3.2-90B-Vision-Instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1918,
                "inputCacheHit": 0.03836,
                "output": 0.5754,
                "videoGeneration": null
            },
            "description": "MiMo-V2-Flash is a mixture of experts (MoE) language model with a total of 309 billion parameters and 15 billion activated parameters. It is designed for high-speed inference and proxy workflows, adopting a novel hybrid attention architecture and multi-token prediction (MTP), significantly reducing inference costs while achieving state-of-the-art performance.",
            "extendedThinking": false,
            "id": "mimo-v2-flash",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mimo-v2-flash",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0,
                "inputCacheHit": 0,
                "output": 0,
                "videoGeneration": null
            },
            "description": "MiMo-V2-Flash is an open-source foundation language model developed by Xiaomi. It adopts a MoE architecture with 309B total parameters and 15B active parameters per inference, balancing performance and efficiency. The model features a hybrid attention architecture, supports a hybrid-thinking toggle, and offers a 256K context window, enabling strong capabilities in complex reasoning, code generation, and agent-based scenarios. On SWE-bench Verified and SWE-bench Multilingual, MiMo-V2-Flash ranks #1 among open-source models globally, delivering performance comparable to Claude Sonnet 4.5 while costing only about 3.5% as much.",
            "extendedThinking": false,
            "id": "mimo-v2-flash-free",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 256000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mimo-v2-flash-free",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.6,
                "inputCacheHit": null,
                "output": 2.4,
                "videoGeneration": null
            },
            "description": "MiniMax-M1 is an open-source large-scale hybrid attention model with 456B total parameters (45.9B activated per token). It natively supports 1M-token context and reduces FLOPs by 75% versus DeepSeek R1 in 100K-token generation tasks via lightning attention. Built on MoE architecture and optimized by CISPO algorithm, it achieves state-of-the-art performance in long-context reasoning and real-world software engineering scenarios.",
            "extendedThinking": false,
            "id": "MiniMaxAI/MiniMax-M1-80k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniMaxAI/MiniMax-M1-80k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.14,
                "inputCacheHit": null,
                "output": 1.12,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "MiniMax-Text-01",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniMax-Text-01",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.288,
                "inputCacheHit": null,
                "output": 1.152,
                "videoGeneration": null
            },
            "description": "MiniMax-M2 redefines efficiency for intelligent agents. It is a compact, fast, and cost-effective MoE model with a total of 230 billion parameters and 10 billion active parameters, designed for top performance in coding and intelligent agent tasks while maintaining strong general intelligence. With only 10 billion active parameters, MiniMax-M2 delivers the complex end-to-end tool usage performance expected from today's leading models, but in a more streamlined form factor, making deployment and scaling easier than ever before.",
            "extendedThinking": false,
            "id": "minimax-m2",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 204800,
                "output": 192000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "minimax-m2",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.288,
                "inputCacheHit": null,
                "output": 1.152,
                "videoGeneration": null
            },
            "description": "MiniMax-M2.1 redefines efficiency for intelligent agents. It is a compact, fast, and cost-effective MoE model with a total of 230 billion parameters and 10 billion active parameters, designed for top performance in coding and intelligent agent tasks while maintaining strong general intelligence. With only 10 billion active parameters, MiniMax-M2 delivers the complex end-to-end tool usage performance expected from today's leading models, but in a more streamlined form factor, making deployment and scaling easier than ever before.",
            "extendedThinking": false,
            "id": "minimax-m2.1",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 204800,
                "output": 192000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "minimax-m2.1",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 3,
                "inputCacheHit": null,
                "output": 9,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Mistral-large-2407",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral-large-2407",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2024-11-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.5,
                "inputCacheHit": null,
                "output": 1.5,
                "videoGeneration": null
            },
            "description": "Mistral Large 3 is a MoE model with 67.5B total parameters and 41B active parameters, supporting a 256K-token context window. Trained from scratch on 3,000 NVIDIA H200 GPUs, it is one of the strongest permissively licensed open-weight models available.\n\nDesigned for advanced reasoning and long-context understanding, Mistral Large 3 delivers performance on par with the best instruction-tuned open-weight models for general-purpose tasks, while also offering image understanding capabilities. Its multilingual strengths are particularly notable for non-English/Chinese languages, making it well-suited for global applications.\n\nTypical use cases include enterprise assistants, multilingual customer support, content generation and editing, data analysis over long documents, code assistance, and research workflows that require handling large corpora or complex instructions. With its MoE architecture, Mistral Large 3 balances strong performance with efficient inference, providing a versatile backbone for building reliable, production-grade AI systems.",
            "extendedThinking": false,
            "id": "mistral-large-3",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 256000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "mistral-large-3",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.288,
                "inputCacheHit": null,
                "output": 1.152,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "mm-minimax-m2.1",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mm-minimax-m2.1",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 10,
                "inputCacheHit": null,
                "output": 10,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "moonshot-v1-128k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "moonshot-v1-128k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 10,
                "inputCacheHit": null,
                "output": 10,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "moonshot-v1-128k-vision-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "moonshot-v1-128k-vision-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 4,
                "inputCacheHit": null,
                "output": 4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "moonshot-v1-32k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "moonshot-v1-32k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 4,
                "inputCacheHit": null,
                "output": 4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "moonshot-v1-32k-vision-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "moonshot-v1-32k-vision-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "moonshot-v1-8k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "moonshot-v1-8k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "moonshot-v1-8k-vision-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "moonshot-v1-8k-vision-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.32,
                "inputCacheHit": 0,
                "output": 1.28,
                "videoGeneration": null
            },
            "description": "Kimi-Dev-72B is a new generation open-source programming large model that achieved a leading performance of 60.4% on SWE-bench Verified. Through large-scale reinforcement learning optimization, it can automatically fix code in real Docker environments, receiving rewards only when passing the complete test suite, thereby ensuring the correctness and robustness of solutions and aligning more closely with real software development standards.",
            "extendedThinking": false,
            "id": "moonshotai/Kimi-Dev-72B",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "moonshotai/Kimi-Dev-72B",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2025-06-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": 0,
                "output": 0.2,
                "videoGeneration": null
            },
            "description": "Provided by chutes.ai.",
            "extendedThinking": false,
            "id": "moonshotai/Moonlight-16B-A3B-Instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "moonshotai/Moonlight-16B-A3B-Instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.32,
                "inputCacheHit": null,
                "output": 1.32,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "nvidia-llama-3.1-nemotron-70b-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nvidia-llama-3.1-nemotron-70b-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2024-10-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.5,
                "inputCacheHit": 0,
                "output": 0.5,
                "videoGeneration": null
            },
            "description": "Llama-3.1-Nemotron-Ultra-253B is a 253 billion parameter reasoning-focused language model optimized for efficiency that excels at math, coding, and general instruction-following tasks while running on a single 8xH100 node.",
            "extendedThinking": false,
            "id": "nvidia/Llama-3_1-Nemotron-Ultra-253B-v1",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nvidia/Llama-3_1-Nemotron-Ultra-253B-v1",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2025-04-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.11,
                "inputCacheHit": null,
                "output": 0.44,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "nvidia-llama-3.3-nemotron-super-49b-v1.5",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nvidia-llama-3.3-nemotron-super-49b-v1.5",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2025-10-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.066,
                "inputCacheHit": null,
                "output": 0.264,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "nvidia-nemotron-3-nano-30b-a3b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 262144
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nvidia-nemotron-3-nano-30b-a3b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2025-12-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.22,
                "inputCacheHit": null,
                "output": 0.66,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "nvidia-nemotron-nano-12b-v2-vl",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nvidia-nemotron-nano-12b-v2-vl",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.044,
                "inputCacheHit": null,
                "output": 0.176,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "nvidia-nemotron-nano-9b-v2",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nvidia-nemotron-nano-9b-v2",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2025-09-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 15,
                "inputCacheHit": 7.5,
                "output": 60,
                "videoGeneration": null
            },
            "extendedThinking": true,
            "id": "o1-2024-12-17",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "o1-2024-12-17",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 15,
                "inputCacheHit": 7.5,
                "output": 60,
                "videoGeneration": null
            },
            "description": "OpenAI new model",
            "extendedThinking": false,
            "id": "o1-global",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "o1-global",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 3,
                "inputCacheHit": 1.5,
                "output": 12,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "o1-mini-2024-09-12",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "o1-mini-2024-09-12",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 15,
                "inputCacheHit": 7.5,
                "output": 60,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "o1-preview-2024-09-12",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "o1-preview-2024-09-12",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 170,
                "inputCacheHit": 170,
                "output": 680,
                "videoGeneration": null
            },
            "description": "The o1 series of models are trained with reinforcement learning to think before they answer and perform complex reasoning. The o1-pro model uses more compute to think harder and provide consistently better answers.",
            "extendedThinking": true,
            "id": "o1-pro",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "o1-pro",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": 0.5,
                "output": 8,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "o3-global",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "o3-global",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.1,
                "inputCacheHit": 0.55,
                "output": 4.4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "o3-mini-global",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "o3-mini-global",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 20,
                "inputCacheHit": null,
                "output": 80,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "o3-pro-global",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "o3-pro-global",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "omni-moderation-latest",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "omni-moderation-latest",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 0,
                "videoGeneration": null
            },
            "description": "PaddleOCR-VL is an advanced and efficient document parsing model specifically designed for element recognition within documents. Its core component, PaddleOCR-VL-0.9B, is a compact yet powerful vision-language model (VLM) composed of a NaViT-style dynamic resolution visual encoder and the ERNIE-4.5-0.3B language model, enabling precise element recognition. This model supports 109 languages and excels at recognizing complex elements such as text, tables, formulas, and charts while maintaining extremely low resource consumption. Through comprehensive evaluations on widely used public benchmarks and internal benchmarks, PaddleOCR-VL achieves state-of-the-art (SOTA) performance in both page-level document parsing and element-level recognition. It significantly outperforms existing pipeline-based solutions, multimodal document parsing approaches, and advanced general-purpose multimodal large models, while also offering faster inference speed.",
            "extendedThinking": false,
            "id": "paddleocr-vl-0.9b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "paddleocr-vl-0.9b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 0,
                "videoGeneration": null
            },
            "description": "PP-StructureV3 is an efficient and comprehensive document parsing solution that can effectively convert document images and PDF files into structured content (such as Markdown format). It features powerful capabilities including layout area detection, table recognition, formula recognition, chart understanding, and multi-column reading order recovery. This tool performs excellently across various document types and can handle complex document data.",
            "extendedThinking": false,
            "id": "pp-structurev3",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "pp-structurev3",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.04,
                "inputCacheHit": 0,
                "output": 0.16,
                "videoGeneration": null
            },
            "description": "GLM-4.1V-9B-Thinking is an open-source Vision Language Model (VLM) jointly released by Zhipu AI and the KEG Laboratory at Tsinghua University, designed specifically for handling complex multimodal cognitive tasks. Based on the GLM-4-9B-0414 foundation model, it significantly enhances cross-modal reasoning ability and stability by introducing the “Chain-of-Thought” reasoning mechanism and using reinforcement learning strategies. As a lightweight model with 9 billion parameters, it strikes a balance between deployment efficiency and performance. In 28 authoritative benchmark evaluations, it matched or even outperformed the 72-billion-parameter Qwen-2.5-VL-72B model in 18 tasks. The model excels not only in image-text understanding, mathematical and scientific reasoning, and video understanding, but also supports images up to 4K resolution and inputs of arbitrary aspect ratios.",
            "extendedThinking": false,
            "id": "Pro/THUDM/GLM-4.1V-9B-Thinking",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Pro/THUDM/GLM-4.1V-9B-Thinking",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.822,
                "inputCacheHit": null,
                "output": 0.822,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "qianfan-chinese-llama-2-13b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qianfan-chinese-llama-2-13b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.274,
                "inputCacheHit": null,
                "output": 0.685,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "qianfan-llama-vl-8b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qianfan-llama-vl-8b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.6,
                "videoGeneration": null
            },
            "description": "The Qianfan-QI-VL model is a proprietary image quality inspection and visual understanding large model (Quality Inspection Large Vision Language Model, Qianfan-QI-VL) developed by Baidu Cloud’s Qianfan platform. It is designed for quality inspection of product images uploaded in e-commerce scenarios, with detection capabilities including AIGC human defect detection, mosaic recognition, watermark recognition, and trademark detection.",
            "extendedThinking": false,
            "id": "qianfan-qi-vl",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qianfan-qi-vl",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.28,
                "inputCacheHit": null,
                "output": 0.84,
                "videoGeneration": null
            },
            "description": "The model provider is the Sophnet platform. QwQ is an inference model from the Qianwen series, featuring outstanding thinking and reasoning capabilities.\nCompared to traditional instruction-finetuned models, QwQ can achieve significantly enhanced performance on downstream tasks, especially on difficult problems.\nQwQ-32B is a medium-sized inference model capable of delivering competitive performance compared to state-of-the-art inference models such as DeepSeek-R1 and o1-mini.\nIt supports long context lengths of up to 128K tokens and can generate text up to 128K tokens.",
            "extendedThinking": false,
            "id": "QwQ-32B",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "QwQ-32B",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.4,
                "inputCacheHit": null,
                "output": 1.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "qwen2.5-14b-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen2.5-14b-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.6,
                "inputCacheHit": null,
                "output": 1.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "qwen2.5-32b-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen2.5-32b-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.4,
                "inputCacheHit": null,
                "output": 0.8,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "qwen2.5-3b-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen2.5-3b-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.8,
                "inputCacheHit": null,
                "output": 2.4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "qwen2.5-72b-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen2.5-72b-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2024-09-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.4,
                "inputCacheHit": null,
                "output": 0.8,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "qwen2.5-7b-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen2.5-7b-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "qwen2.5-coder-1.5b-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen2.5-coder-1.5b-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "qwen2.5-coder-7b-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen2.5-coder-7b-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "qwen2.5-math-1.5b-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen2.5-math-1.5b-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.8,
                "inputCacheHit": null,
                "output": 2.4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "qwen2.5-math-72b-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen2.5-math-72b-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "qwen2.5-math-7b-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen2.5-math-7b-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2.4,
                "inputCacheHit": null,
                "output": 7.2,
                "videoGeneration": null
            },
            "description": "Strong capability in Chinese domain recognition, comparable to ChatGPT-4.0.",
            "extendedThinking": false,
            "id": "qwen2.5-vl-72b-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "qwen2.5-vl-72b-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.62,
                "inputCacheHit": null,
                "output": 0.62,
                "videoGeneration": null
            },
            "description": "The model provider is the Sophon platform. Qwen2.5-VL-72B-Instruct is the latest vision-language model released by the Qwen team. This model excels not only at recognizing common objects such as flowers, birds, fish, and insects, but also at efficiently analyzing text, charts, icons, graphics, and layouts within images. As a visual agent, it is capable of reasoning and dynamically guiding tool usage, supporting both computer and mobile operations. Moreover, it can understand videos longer than one hour and accurately locate relevant video segments.",
            "extendedThinking": false,
            "id": "Qwen2.5-VL-72B-Instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image", "video"],
                "output": ["text"]
            },
            "name": "Qwen2.5-VL-72B-Instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2.18,
                "inputCacheHit": null,
                "output": 6.54,
                "videoGeneration": null
            },
            "description": "The model provider is the Sophnet platform. Qwen2-VL-72B-Instruct is the latest iteration in the Qwen2-VL series launched by Alibaba Cloud, representing nearly a year of innovative achievements. This model has 72 billion parameters and can understand images of various resolutions and aspect ratios. Additionally, it supports video understanding of over 20 minutes, enabling high-quality video question answering, dialogue, and content creation, along with complex reasoning and decision-making capabilities.\n\n- State-of-the-art image understanding: capable of processing images of various resolutions and aspect ratios, performing excellently across multiple visual understanding benchmarks.\n- Long video understanding: supports video comprehension exceeding 20 minutes, enabling high-quality video Q&A, dialogues, and content creation.\n- Agent operation capability: equipped with complex reasoning and decision-making abilities, it can integrate with devices such as phones and robots to perform automated operations based on visual environments and textual instructions.\n- Multilingual support: in addition to English and Chinese, it supports understanding text in images in multiple languages, including most European languages, Japanese, Korean, Arabic, Vietnamese, and more.\n- Supports a maximum context length of 128K tokens, offering powerful processing capabilities.",
            "extendedThinking": false,
            "id": "Qwen2-VL-72B-Instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image", "video"],
                "output": ["text"]
            },
            "name": "Qwen2-VL-72B-Instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.28,
                "inputCacheHit": null,
                "output": 0.7,
                "videoGeneration": null
            },
            "description": "The model provider is the Sophnet platform. Qwen2-VL-7B-Instruct is the latest vision-language model launched by Alibaba Cloud and the newest member of the Qwen family. This model is proficient not only in recognizing common objects but also in analyzing text, charts, icons, and layouts within images. As a visual agent, it can reason and dynamically guide tool usage, supporting operations on computers and mobile phones. Additionally, it can understand long videos exceeding one hour and capture key events, accurately locate objects in images, and generate structured outputs for data such as invoices and tables, making it suitable for various scenarios including finance and business.\n\n- Vision understanding capability: not only recognizes common objects but also analyzes text, charts, icons, and layouts within images.\n- Agent capability: functions as a visual agent capable of reasoning and dynamically guiding tool usage, supporting operations on computers and mobile phones.\n- Long video understanding: can comprehend video content over one hour in length and accurately localize relevant video segments.\n- Visual localization: precisely locates objects within images by generating bounding boxes or points, providing stable JSON coordinate outputs.\n- Structured output: supports structured data output for invoices, tables, and other data, suitable for finance, business, and various other scenarios.",
            "extendedThinking": false,
            "id": "Qwen2-VL-7B-Instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image", "video"],
                "output": ["text"]
            },
            "name": "Qwen2-VL-7B-Instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.046,
                "inputCacheHit": 0,
                "output": 0.46,
                "videoGeneration": null
            },
            "description": "Effectively integrates thinking and non-thinking modes, allowing mode switching during conversations. Its general capabilities significantly surpass those of the Qwen2.5 small-scale series.",
            "extendedThinking": false,
            "id": "qwen3-0.6b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen3-0.6b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.16,
                "inputCacheHit": 0,
                "output": 1.6,
                "videoGeneration": null
            },
            "description": "Achieves effective integration of thinking and non-thinking modes, enabling mode switching during conversations. Its reasoning ability reaches state-of-the-art (SOTA) levels among models of the same scale, and its general capability significantly surpasses Qwen2.5-14B.",
            "extendedThinking": false,
            "id": "qwen3-14b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen3-14b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.046,
                "inputCacheHit": 0,
                "output": 0.46,
                "videoGeneration": null
            },
            "description": "Effectively integrates thinking and non-thinking modes, allowing mode switching during conversations. Its general capabilities significantly surpass those of the Qwen2.5 small-scale series, with greatly enhanced human preference alignment. There are notable improvements in creative writing, role-playing, multi-turn dialogue, and instruction following, resulting in a significantly better expected user experience.",
            "extendedThinking": false,
            "id": "qwen3-1.7b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen3-1.7b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.28,
                "inputCacheHit": null,
                "output": 1.12,
                "videoGeneration": null
            },
            "description": "Qwen3-235B-A22B is a massive 235B parameter Mixture-of-Experts (MoE) model that operates with the efficiency of a 22B model. Its standout feature is the ability to seamlessly switch between a \"thinking\" mode for complex reasoning and a \"non-thinking\" mode for fast conversation, offering both world-class power and practical speed.",
            "extendedThinking": false,
            "id": "qwen3-235b-a22b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131100,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "qwen3-235b-a22b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.28,
                "inputCacheHit": null,
                "output": 2.8,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Qwen3-235B-A22B-Thinking-2507",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-235B-A22B-Thinking-2507",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.12,
                "inputCacheHit": 0,
                "output": 1.2,
                "videoGeneration": null
            },
            "description": "Achieves effective integration of thinking and non-thinking modes, allowing mode switching during conversations. Its reasoning ability matches that of QwQ-32B with a smaller parameter size, and its general capability significantly surpasses Qwen2.5-14B, reaching state-of-the-art (SOTA) levels among industry models of the same scale.",
            "extendedThinking": false,
            "id": "qwen3-30b-a3b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen3-30b-a3b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1028,
                "inputCacheHit": null,
                "output": 0.4112,
                "videoGeneration": null
            },
            "description": "Significantly improved performance on reasoning tasks, including logical reasoning, mathematics, science, coding, and academic benchmarks that typically require human expertise.\nMarkedly better general capabilities, such as instruction following, tool usage, text generation, and alignment with human preferences.\nEnhanced 256K long-context understanding capabilities.",
            "extendedThinking": false,
            "id": "qwen3-30b-a3b-instruct-2507",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen3-30b-a3b-instruct-2507",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.12,
                "inputCacheHit": null,
                "output": 1.2,
                "videoGeneration": null
            },
            "description": "Significantly improved performance on reasoning tasks, including logical reasoning, mathematics, science, coding, and academic benchmarks that typically require human expertise.\nMarkedly better general capabilities, such as instruction following, tool usage, text generation, and alignment with human preferences.\nEnhanced 256K long-context understanding capabilities.",
            "extendedThinking": false,
            "id": "qwen3-30b-a3b-thinking-2507",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen3-30b-a3b-thinking-2507",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.046,
                "inputCacheHit": 0,
                "output": 0.46,
                "videoGeneration": null
            },
            "description": "Achieves effective integration of thinking and non-thinking modes, allowing mode switching during conversations. Its reasoning ability reaches state-of-the-art (SOTA) levels among models of the same scale, with significantly enhanced human preference alignment. There are notable improvements in creative writing, role-playing, multi-turn dialogue, and instruction following, resulting in a noticeably better user experience.",
            "extendedThinking": false,
            "id": "qwen3-4b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen3-4b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.08,
                "inputCacheHit": 0,
                "output": 0.8,
                "videoGeneration": null
            },
            "description": "Achieves effective integration of thinking and non-thinking modes, enabling mode switching during conversations. Its reasoning ability reaches state-of-the-art (SOTA) levels among models of the same scale, and its general capability significantly surpasses Qwen2.5-7B.",
            "extendedThinking": false,
            "id": "qwen3-8b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen3-8b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": 0.2,
                "output": 0.8,
                "videoGeneration": null
            },
            "description": "The code generation model based on Qwen3 has powerful Coding Agent capabilities, achieving state-of-the-art performance compared to open-source models.The model adopts tiered pricing.",
            "extendedThinking": false,
            "id": "qwen3-coder-30b-a3b-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2000000,
                "output": 262000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen3-coder-30b-a3b-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.82,
                "inputCacheHit": 0.82,
                "output": 3.28,
                "videoGeneration": null
            },
            "description": "The code generation model based on Qwen3 has powerful Coding Agent capabilities, achieving state-of-the-art performance compared to open-source models.The model adopts tiered pricing.",
            "extendedThinking": false,
            "id": "qwen3-coder-480b-a35b-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262000,
                "output": 262000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen3-coder-480b-a35b-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.136,
                "inputCacheHit": 0.136,
                "output": 0.544,
                "videoGeneration": null
            },
            "description": "Qwen3 Coder Flash is Alibaba's fast and cost efficient version of their proprietary Qwen3 Coder Plus. It is a powerful coding agent model specializing in autonomous programming via tool calling and environment interaction, combining coding proficiency with versatile general-purpose abilities.",
            "extendedThinking": false,
            "id": "qwen3-coder-flash",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen3-coder-flash",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.54,
                "inputCacheHit": 0.108,
                "output": 2.16,
                "videoGeneration": null
            },
            "description": "The code generation model based on Qwen3 has powerful Coding Agent capabilities, excels in tool invocation and environment interaction, and can achieve autonomous programming with outstanding coding abilities while also possessing general capabilities.The model adopts tiered pricing.",
            "extendedThinking": false,
            "id": "qwen3-coder-plus",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen3-coder-plus",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.54,
                "inputCacheHit": 0.54,
                "output": 2.16,
                "videoGeneration": null
            },
            "description": "The code generation model based on Qwen3 has powerful Coding Agent capabilities, excels in tool invocation and environment interaction, and can achieve autonomous programming with outstanding coding abilities while also possessing general capabilities.The model adopts tiered pricing.",
            "extendedThinking": false,
            "id": "qwen3-coder-plus-2025-07-22",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen3-coder-plus-2025-07-22",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.068,
                "inputCacheHit": null,
                "output": 0.068,
                "videoGeneration": null
            },
            "description": "The Qwen3 Embedding model series is the latest proprietary model family from Qwen, specifically designed for text embedding and ranking tasks. Based on the dense base models of the Qwen3 series, it offers comprehensive text embedding and reranking models in various sizes (0.6B, 4B, and 8B). This series inherits the excellent multilingual capabilities, long-text understanding, and reasoning skills of its base models. The Qwen3 Embedding series demonstrates significant advancements in various text embedding and ranking tasks, including text retrieval, code retrieval, text classification, text clustering, and bilingual text mining.",
            "extendedThinking": false,
            "id": "qwen3-embedding-0.6b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "qwen3-embedding-0.6b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix",
            "audioGeneration": false,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.068,
                "inputCacheHit": null,
                "output": 0.068,
                "videoGeneration": null
            },
            "description": "The Qwen3 Embedding model series is the latest proprietary model family from Qwen, specifically designed for text embedding and ranking tasks. Based on the dense base models of the Qwen3 series, it offers comprehensive text embedding and reranking models in various sizes (0.6B, 4B, and 8B). This series inherits the excellent multilingual capabilities, long-text understanding, and reasoning skills of its base models. The Qwen3 Embedding series demonstrates significant advancements in various text embedding and ranking tasks, including text retrieval, code retrieval, text classification, text clustering, and bilingual text mining.",
            "extendedThinking": false,
            "id": "qwen3-embedding-4b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "qwen3-embedding-4b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.068,
                "inputCacheHit": null,
                "output": 0.068,
                "videoGeneration": null
            },
            "description": "The Qwen3 Embedding model series is the latest proprietary model family from Qwen, specifically designed for text embedding and ranking tasks. Based on the dense base models of the Qwen3 series, it offers comprehensive text embedding and reranking models in various sizes (0.6B, 4B, and 8B). This series inherits the excellent multilingual capabilities, long-text understanding, and reasoning skills of its base models. The Qwen3 Embedding series demonstrates significant advancements in various text embedding and ranking tasks, including text retrieval, code retrieval, text classification, text clustering, and bilingual text mining.",
            "extendedThinking": false,
            "id": "qwen3-embedding-8b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "qwen3-embedding-8b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.822,
                "inputCacheHit": 0.822,
                "output": 3.288,
                "videoGeneration": null
            },
            "description": "The Tongyi Qianwen 3 series Max model has undergone special upgrades in intelligent agent programming and tool invocation compared to the preview version. The officially released model this time reaches SOTA level in the field and is adapted to more complex intelligent agent scenarios.",
            "extendedThinking": false,
            "id": "qwen3-max",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "qwen3-max",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.822,
                "inputCacheHit": 0.822,
                "output": 3.288,
                "videoGeneration": null
            },
            "description": "Qwen3-Max-Preview is the latest preview model in the Qwen3 series. This version is functionally equivalent to Qwen3-Max-Thinking — simply set extra_body={\"enable_thinking\": True} to enable the thinking mode. Compared to the Qwen2.5 series, it delivers significant improvements in overall general capabilities, including English–Chinese text understanding, complex instruction following, open-ended reasoning, multilingual processing, and tool-use proficiency. The model also exhibits fewer hallucinations and stronger overall reliability.",
            "extendedThinking": false,
            "id": "qwen3-max-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "qwen3-max-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.138,
                "inputCacheHit": null,
                "output": 0.552,
                "videoGeneration": null
            },
            "description": "Qwen3-Next-80B-A3B-Instruct is an instruction-tuned model in the Qwen3-Next series, optimized for delivering fast, stable, and direct final answers without showing its reasoning steps (\"thinking traces\").\n\nUnlike chain-of-thought models, it focuses on generating consistent, instruction-following outputs, making it ideal for production environments. It excels at complex tasks like reasoning and coding while maintaining high throughput and stability, especially with ultra-long inputs and multi-turn dialogues.\n\nEngineered for efficiency, its performance rivals larger Qwen3 systems, making it perfectly suited for RAG, tool use, and agentic workflows where deterministic results are critical.",
            "extendedThinking": false,
            "id": "qwen3-next-80b-a3b-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 256000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "qwen3-next-80b-a3b-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.138,
                "inputCacheHit": null,
                "output": 1.38,
                "videoGeneration": null
            },
            "description": "Qwen3-Next-80B-A3B-Thinking is a reasoning-first chat model in the Qwen3-Next line that excels by outputting structured 'thinking' traces (Chain-of-Thought) by default.\n\nDesigned for hard, multi-step problems, it is ideal for tasks like math proofs, code synthesis, logic puzzles, and agentic planning. Compared to other Qwen3 variants, it offers greater stability during long reasoning chains and is tuned to follow complex instructions without getting repetitive or off-task.\n\nThis model is perfectly suited for agent frameworks, tool use (function calling), and benchmarks where a step-by-step breakdown is required. It leverages throughput-oriented techniques for fast generation of detailed, procedural outputs.",
            "extendedThinking": true,
            "id": "qwen3-next-80b-a3b-thinking",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 256000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "qwen3-next-80b-a3b-thinking",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.11,
                "inputCacheHit": null,
                "output": 0.11,
                "videoGeneration": null
            },
            "description": "Based on the dense foundational model of the Qwen3 series, it is specifically designed for ranking tasks. It inherits the base model’s outstanding multilingual capabilities, long-text understanding, and reasoning skills, achieving significant advancements in ranking tasks.",
            "extendedThinking": false,
            "id": "qwen3-reranker-0.6b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16000,
                "output": 8000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["score"]
            },
            "name": "qwen3-reranker-0.6b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.11,
                "inputCacheHit": null,
                "output": 0.11,
                "videoGeneration": null
            },
            "description": "Based on the dense foundational model of the Qwen3 series, it is specifically designed for ranking tasks. It inherits the base model’s outstanding multilingual capabilities, long-text understanding, and reasoning skills, achieving significant advancements in ranking tasks.",
            "extendedThinking": false,
            "id": "qwen3-reranker-4b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["score"]
            },
            "name": "qwen3-reranker-4b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.11,
                "inputCacheHit": null,
                "output": 0.11,
                "videoGeneration": null
            },
            "description": "Based on the dense foundational model of the Qwen3 series, it is specifically designed for ranking tasks. It inherits the base model’s outstanding multilingual capabilities, long-text understanding, and reasoning skills, achieving significant advancements in ranking tasks.",
            "extendedThinking": false,
            "id": "qwen3-reranker-8b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["score"]
            },
            "name": "qwen3-reranker-8b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.274,
                "inputCacheHit": null,
                "output": 1.096,
                "videoGeneration": null
            },
            "description": "The Qwen3 series open-source models include hybrid models, thinking models, and non-thinking models, with both reasoning capabilities and general abilities reaching industry SOTA levels at the same scale.",
            "extendedThinking": false,
            "id": "qwen3-vl-235b-a22b-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131000,
                "output": 33000
            },
            "modalities": {
                "input": ["text", "image", "video"],
                "output": ["text"]
            },
            "name": "qwen3-vl-235b-a22b-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.274,
                "inputCacheHit": null,
                "output": 2.74,
                "videoGeneration": null
            },
            "description": "The Qwen3 series open-source models include hybrid models, thinking models, and non-thinking models, with both reasoning capabilities and general abilities reaching industry SOTA levels at the same scale.",
            "extendedThinking": true,
            "id": "qwen3-vl-235b-a22b-thinking",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131000,
                "output": 33000
            },
            "modalities": {
                "input": ["text", "image", "video"],
                "output": ["text"]
            },
            "name": "qwen3-vl-235b-a22b-thinking",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1028,
                "inputCacheHit": null,
                "output": 0.4112,
                "videoGeneration": null
            },
            "description": "The Qwen3-VL series’ second-largest MoE model Instruct version offers fast response speed and supports ultra-long contexts such as long videos and long documents; it features comprehensive upgrades in image/video understanding, spatial perception, and universal recognition abilities; it also provides visual 2DD/3D localization capabilities, making it capable of handling complex real-world tasks.",
            "extendedThinking": false,
            "id": "qwen3-vl-30b-a3b-instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 32000
            },
            "modalities": {
                "input": ["text", "image", "video"],
                "output": ["text"]
            },
            "name": "qwen3-vl-30b-a3b-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1028,
                "inputCacheHit": null,
                "output": 1.028,
                "videoGeneration": null
            },
            "description": "The Qwen3-VL series’ second-largest MoE model Thinking version offers fast response speed, stronger multimodal understanding and reasoning, visual agent capabilities, and ultra-long context support for long videos and long documents; it features comprehensive upgrades in image/video understanding, spatial perception, and universal recognition abilities, making it capable of handling complex real-world tasks.",
            "extendedThinking": true,
            "id": "qwen3-vl-30b-a3b-thinking",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 32000
            },
            "modalities": {
                "input": ["text", "image", "video"],
                "output": ["text"]
            },
            "name": "qwen3-vl-30b-a3b-thinking",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.137,
                "inputCacheHit": 0.0274,
                "output": 1.37,
                "videoGeneration": null
            },
            "description": "The Qwen3 series visual understanding model achieves an effective fusion of thinking and non-thinking modes. Its visual agent capabilities reach world-class levels on public test sets such as OS World. This version features comprehensive upgrades in visual coding, spatial perception, and multimodal reasoning; visual perception and recognition abilities are greatly enhanced, supporting ultra-long video understanding.",
            "extendedThinking": false,
            "id": "qwen3-vl-plus",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 32000
            },
            "modalities": {
                "input": ["text", "image", "video"],
                "output": ["text"]
            },
            "name": "qwen3-vl-plus",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.02,
                "inputCacheHit": 0.02,
                "output": 0.2,
                "videoGeneration": null
            },
            "description": "The model adopts tiered pricing.",
            "extendedThinking": false,
            "id": "qwen-flash",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen-flash",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.02,
                "inputCacheHit": 0.02,
                "output": 0.2,
                "videoGeneration": null
            },
            "description": "The model adopts tiered pricing.",
            "extendedThinking": false,
            "id": "qwen-flash-2025-07-28",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen-flash-2025-07-28",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 0,
                "output": 0,
                "videoGeneration": null
            },
            "description": "Qwen-Image is a foundational image generation model in the Qwen series, achieving significant progress in complex text rendering and precise image editing. Experiments show that the model has strong general capabilities in image generation and editing, especially excelling in Chinese text rendering.",
            "extendedThinking": false,
            "id": "qwen-image-plus",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "qwen-image-plus",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "qwen-long",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen-long",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.38,
                "inputCacheHit": null,
                "output": 1.52,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "qwen-max",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen-max",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.38,
                "inputCacheHit": null,
                "output": 1.52,
                "videoGeneration": null
            },
            "description": "Qwen 2.5-Max latest model",
            "extendedThinking": false,
            "id": "qwen-max-0125",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen-max-0125",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 7,
                "inputCacheHit": null,
                "output": 21,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "qwen-max-longcontext",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen-max-longcontext",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.492,
                "inputCacheHit": null,
                "output": 1.476,
                "videoGeneration": null
            },
            "description": "Based on the comprehensive upgrade of Qwen3, this flagship translation large model supports bidirectional translation across 92 languages. It offers fully enhanced model performance and translation quality, along with more stable terminology customization, format fidelity, and domain-prompting capabilities, making translations more accurate and natural.",
            "extendedThinking": false,
            "id": "qwen-mt-plus",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16000,
                "output": 8000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen-mt-plus",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.192,
                "inputCacheHit": null,
                "output": 0.534912,
                "videoGeneration": null
            },
            "description": "Based on the comprehensive upgrade of Qwen3, this flagship translation large model supports bidirectional translation across 92 languages. It offers fully enhanced model performance and translation quality, along with more stable terminology customization, format fidelity, and domain-prompting capabilities, making translations more accurate and natural.",
            "extendedThinking": false,
            "id": "qwen-mt-turbo",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16000,
                "output": 8000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen-mt-turbo",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.7,
                "inputCacheHit": null,
                "output": 2.1,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "qwen-plus",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen-plus",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.13,
                "inputCacheHit": 0,
                "output": 2.6,
                "videoGeneration": null
            },
            "description": "The Qwen3 series Plus model effectively integrates thinking and non-thinking modes, allowing for mode switching during conversations. Its reasoning abilities significantly surpass those of QwQ, and its general capabilities are markedly superior to Qwen2.5-Plus, reaching state-of-the-art (SOTA) levels among models of the same scale. This version is a snapshot model as of April 28, 2025.",
            "extendedThinking": false,
            "id": "qwen-plus-2025-04-28",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen-plus-2025-04-28",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.11,
                "inputCacheHit": 0.11,
                "output": 0.275,
                "videoGeneration": null
            },
            "description": "The Tongyi Qianwen series balanced capability model has inference performance and speed between Tongyi Qianwen-Max and Tongyi Qianwen-Turbo, making it suitable for moderately complex tasks. This model adopts tiered pricing.",
            "extendedThinking": false,
            "id": "qwen-plus-2025-07-28",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen-plus-2025-07-28",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.11,
                "inputCacheHit": 0.11,
                "output": 0.275,
                "videoGeneration": null
            },
            "description": "The Qwen series models with balanced capabilities have inference performance and speed between Qwen-Max and Qwen-Turbo, making them suitable for moderately complex tasks. This model is a dynamically updated version, and updates will not be announced in advance. The current version is qwen-plus-2025-04-28.The model adopts tiered pricing.",
            "extendedThinking": false,
            "id": "qwen-plus-latest",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen-plus-latest",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.2,
                "inputCacheHit": null,
                "output": 1.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Qwen/QVQ-72B-Preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/QVQ-72B-Preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.14,
                "inputCacheHit": null,
                "output": 0.56,
                "videoGeneration": null
            },
            "description": "Silicon-based flow provision",
            "extendedThinking": false,
            "id": "Qwen/QwQ-32B",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/QwQ-32B",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2025-03-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "aihubmix",
            "providerModelsDevId": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.16,
                "inputCacheHit": null,
                "output": 0.16,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Qwen/QwQ-32B-Preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/QwQ-32B-Preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2024-11-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen2-1.5B-Instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen2-1.5B-Instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.24,
                "inputCacheHit": null,
                "output": 0.24,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen2-57B-A14B-Instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen2-57B-A14B-Instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.6,
                "inputCacheHit": null,
                "output": 0.6,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen2.5-32B-Instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen2.5-32B-Instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.8,
                "inputCacheHit": null,
                "output": 0.8,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen2.5-72B-Instruct-128K",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen2.5-72B-Instruct-128K",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.4,
                "inputCacheHit": null,
                "output": 0.4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen2.5-7B-Instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen2.5-7B-Instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2024-10-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.24,
                "inputCacheHit": null,
                "output": 0.24,
                "videoGeneration": null
            },
            "description": "Qwen2.5-VL-32B-Instruct is an advanced multimodal model from the Tongyi Qianwen team that can recognize objects, analyze text and graphics in images, operate tools, locate objects in images, and generate structured outputs. Through reinforcement learning, it has improved mathematics and problem-solving capabilities, with a more concise and natural response style.",
            "extendedThinking": false,
            "id": "Qwen/Qwen2.5-VL-32B-Instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image", "video"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen2.5-VL-32B-Instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2025-03-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.5,
                "inputCacheHit": 0,
                "output": 0.5,
                "videoGeneration": null
            },
            "description": "Qwen2.5-VL is a visual language model from the Qwen2.5 series, equipped with strong visual understanding and reasoning capabilities. It can recognize objects, analyze text and charts, understand key events in long videos, and accurately locate targets within images. The model supports structured output, making it suitable for data such as invoices and forms, and performs excellently in multiple benchmark tests.",
            "extendedThinking": false,
            "id": "Qwen/Qwen2.5-VL-72B-Instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image", "video"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen2.5-VL-72B-Instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2025-02-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.8,
                "inputCacheHit": null,
                "output": 0.8,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen2-72B-Instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen2-72B-Instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.08,
                "inputCacheHit": null,
                "output": 0.08,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen2-7B-Instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen2-7B-Instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.5,
                "inputCacheHit": null,
                "output": 0.5,
                "videoGeneration": null
            },
            "description": "Provided by chutes.ai",
            "extendedThinking": false,
            "id": "Qwen/Qwen3-14B",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": 40960
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen3-14B",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix",
            "providerModelsDevId": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1,
                "inputCacheHit": null,
                "output": 1,
                "videoGeneration": null
            },
            "description": "Provided by chutes.ai",
            "extendedThinking": false,
            "id": "Qwen/Qwen3-30B-A3B",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": 40960
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen3-30B-A3B",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix",
            "providerModelsDevId": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.4,
                "inputCacheHit": null,
                "output": 0.8,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen3-32B",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": 40960
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen3-32B",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix",
            "providerModelsDevId": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2,
                "videoGeneration": null
            },
            "description": "Provided by chutes.ai",
            "extendedThinking": false,
            "id": "Qwen/Qwen3-8B",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 20000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen3-8B",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.4,
                "inputCacheHit": null,
                "output": 0.8,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "qwen-qwq-32b",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen-qwq-32b",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2025-03-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.36,
                "inputCacheHit": null,
                "output": 1.08,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "qwen-turbo",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen-turbo",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.36,
                "inputCacheHit": null,
                "output": 1.08,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "qwen-turbo-2024-11-01",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen-turbo-2024-11-01",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.046,
                "inputCacheHit": 0,
                "output": 0.92,
                "videoGeneration": null
            },
            "description": "The Qwen3 series Turbo model effectively integrates thinking and non-thinking modes, allowing seamless switching between modes during conversations. With a smaller parameter size, its reasoning ability rivals that of QwQ-32B, and its general capabilities significantly surpass those of Qwen2.5-Turbo, reaching state-of-the-art (SOTA) levels among models of the same scale. This version is a snapshot model as of April 28, 2025.",
            "extendedThinking": false,
            "id": "qwen-turbo-2025-04-28",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen-turbo-2025-04-28",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.046,
                "inputCacheHit": 0,
                "output": 0.92,
                "videoGeneration": null
            },
            "description": "The Qwen series model with the fastest speed and lowest cost, suitable for simple tasks. This model is a dynamically updated version, and updates will not be announced in advance. The model's overall Chinese and English abilities have been significantly improved, human preference alignment has been greatly enhanced, inference capability and complex instruction understanding have been substantially strengthened, performance on difficult tasks is better, and mathematics and coding skills have been significantly improved. The current version is qwen-turbo-2025-04-28.",
            "extendedThinking": false,
            "id": "qwen-turbo-latest",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen-turbo-latest",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.548,
                "inputCacheHit": null,
                "output": 2.192,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "sf-kimi-k2-thinking",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "sf-kimi-k2-thinking",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.6,
                "inputCacheHit": null,
                "output": 1.6,
                "videoGeneration": null
            },
            "description": "Latest Perplexity Model",
            "extendedThinking": false,
            "id": "sonar",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "sonar",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.6,
                "inputCacheHit": null,
                "output": 8,
                "videoGeneration": null
            },
            "description": "Perplexity inference model",
            "extendedThinking": false,
            "id": "sonar-reasoning",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "sonar-reasoning",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 3,
                "inputCacheHit": null,
                "output": 12,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "sonar-reasoning-pro",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "sonar-reasoning-pro",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.273974,
                "inputCacheHit": 0.273974,
                "output": 1.095896,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "sophnet-glm-4.7",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "sophnet-glm-4.7",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2876,
                "inputCacheHit": null,
                "output": 1.1504,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "sophnet-minimax-m2.1",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "sophnet-minimax-m2.1",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": 2
            },
            "description": "Sora-2 is the next-generation text-to-video model evolved from Sora, optimized for higher visual realism, stronger physical consistency, and longer temporal coherence. It delivers more stable character consistency, complex motion rendering, camera control, and narrative continuity, while supporting higher resolutions and minute-level video generation for film production, advertising, virtual content creation, and creative multimedia workflows.",
            "extendedThinking": false,
            "id": "sora-2",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["video"]
            },
            "name": "sora-2",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": 2
            },
            "description": "OpenAI video model Sora2-pro official API.",
            "extendedThinking": false,
            "id": "sora-2-pro",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["video"]
            },
            "name": "sora-2-pro",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 4,
                "input": 4,
                "inputCacheHit": 0,
                "output": 4,
                "videoGeneration": null
            },
            "description": "Stable Diffusion 3.5 Large, developed by Stability AI, is a text-to-image generation model that supports high-quality image creation with excellent prompt responsiveness and customization, suitable for professional applications.",
            "extendedThinking": false,
            "id": "Stable-Diffusion-3-5-Large",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Stable-Diffusion-3-5-Large",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "step-2-16k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "step-2-16k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.068,
                "inputCacheHit": null,
                "output": 0.068,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "tao-8k",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "tao-8k",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.14,
                "inputCacheHit": null,
                "output": 0.56,
                "videoGeneration": null
            },
            "description": "Hunyuan-A13B-Instruct has 8 billion parameters and can match larger models by activating only 1.3 billion parameters, supporting \"fast thinking/slow thinking\" hybrid inference. It offers stable long text understanding. Verified by BFCL-v3 and τ-Bench, its Agent capabilities are leading in the field. Combined with GQA and multiple quantization formats, it enables efficient inference.",
            "extendedThinking": false,
            "id": "tencent/Hunyuan-A13B-Instruct",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "tencent/Hunyuan-A13B-Instruct",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2025-07-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2,
                "videoGeneration": null
            },
            "description": "Hunyuan-MT-7B is a lightweight translation model with 7 billion parameters, designed to translate source text into target languages. The model supports translation among 33 languages as well as 5 Chinese minority languages. In the WMT25 International Machine Translation Competition, Hunyuan-MT-7B achieved first place in 30 out of 31 language categories it participated in, demonstrating its exceptional translation capabilities. For translation scenarios, Tencent Hunyuan proposed a complete training paradigm from pre-training to supervised fine-tuning, followed by translation reinforcement and ensemble reinforcement, enabling it to achieve industry-leading performance among models of similar scale. The model is computationally efficient, easy to deploy, and suitable for various application scenarios.",
            "extendedThinking": false,
            "id": "tencent/Hunyuan-MT-7B",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "tencent/Hunyuan-MT-7B",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.4,
                "inputCacheHit": null,
                "output": 0.4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "text-ada-001",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "text-ada-001",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.5,
                "inputCacheHit": null,
                "output": 0.5,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "text-babbage-001",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "text-babbage-001",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "text-curie-001",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "text-curie-001",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 20,
                "inputCacheHit": null,
                "output": 20,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "text-davinci-002",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "text-davinci-002",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 20,
                "inputCacheHit": null,
                "output": 20,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "text-davinci-003",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "text-davinci-003",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 20,
                "inputCacheHit": null,
                "output": 20,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "text-davinci-edit-001",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "text-davinci-edit-001",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.02,
                "inputCacheHit": null,
                "output": 0.02,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "text-embedding-004",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "text-embedding-004",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.13,
                "inputCacheHit": null,
                "output": 0.13,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "text-embedding-3-large",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "text-embedding-3-large",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.02,
                "inputCacheHit": null,
                "output": 0.02,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "text-embedding-3-small",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "text-embedding-3-small",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "text-embedding-ada-002",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "text-embedding-ada-002",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "text-embedding-v1",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "text-embedding-v1",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.08,
                "inputCacheHit": null,
                "output": 0.08,
                "videoGeneration": null
            },
            "description": "This is the Tongyi Laboratory's multilingual unified text vector model trained based on Qwen3, which significantly improves performance in text retrieval, clustering, and classification compared to version V3; it achieves a 15% to 40% improvement on evaluation tasks such as MTEB multilingual, Chinese-English, and code retrieval; supports user-defined vector dimensions ranging from 64 to 2048.",
            "extendedThinking": false,
            "id": "text-embedding-v4",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "text-embedding-v4",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "text-moderation-007",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "text-moderation-007",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "text-moderation-latest",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "text-moderation-latest",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "text-moderation-stable",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "text-moderation-stable",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 20,
                "inputCacheHit": null,
                "output": 20,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "text-search-ada-doc-001",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "text-search-ada-doc-001",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.1,
                "inputCacheHit": 0,
                "output": 0.1,
                "videoGeneration": null
            },
            "description": "GLM-4.1V-9B-Thinking is an open-source Vision Language Model (VLM) jointly released by Zhipu AI and the KEG Laboratory at Tsinghua University, designed specifically for handling complex multimodal cognitive tasks. Based on the GLM-4-9B-0414 foundation model, it significantly enhances cross-modal reasoning ability and stability by introducing the “Chain-of-Thought” reasoning mechanism and using reinforcement learning strategies. As a lightweight model with 9 billion parameters, it strikes a balance between deployment efficiency and performance. In 28 authoritative benchmark evaluations, it matched or even outperformed the 72-billion-parameter Qwen-2.5-VL-72B model in 18 tasks. The model excels not only in image-text understanding, mathematical and scientific reasoning, and video understanding, but also supports images up to 4K resolution and inputs of arbitrary aspect ratios.",
            "extendedThinking": false,
            "id": "THUDM/GLM-4.1V-9B-Thinking",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": 8000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "THUDM/GLM-4.1V-9B-Thinking",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": "2025-07-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.08,
                "inputCacheHit": null,
                "output": 0.08,
                "videoGeneration": null
            },
            "description": "GLM-4-32B-0414 is a next-generation open-source model with 32 billion parameters, delivering performance comparable to OpenAI’s GPT series and DeepSeek V3/R1. It supports smooth local deployment.\n\nThe base model was pre-trained on 15T of high-quality data, including a large amount of reasoning-focused synthetic content, setting the stage for advanced reinforcement learning.\n\nIn the post-training phase, techniques like human preference alignment, rejection sampling, and reinforcement learning were used to improve the model’s ability to follow instructions, generate code, and handle function calls—core skills needed for agent-style tasks.\n\nGLM-4-32B-0414 has shown strong results in engineering code, artifact generation, function calling, search-based QA, and report writing—sometimes matching or even surpassing larger models like GPT-4o and DeepSeek-V3 (671B) on specific benchmarks.",
            "extendedThinking": false,
            "id": "THUDM/GLM-4-32B-0414",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "THUDM/GLM-4-32B-0414",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.05,
                "inputCacheHit": null,
                "output": 0.05,
                "videoGeneration": null
            },
            "description": "GLM-4-9B-0414 is a lightweight model in the GLM family, with 9 billion parameters. It inherits the core tech from GLM-4-32B and offers an efficient option for deployment on limited resources.\n\nDespite its smaller size, it performs well in tasks like code generation, web design, SVG graphics creation, and search-based writing. It also supports function calling to interact with external tools, enhancing its versatility.\n\nGLM-4-9B-0414 strikes a solid balance between efficiency and performance, making it a strong choice for low-resource environments—while remaining competitive on various benchmarks.",
            "extendedThinking": false,
            "id": "THUDM/GLM-4-9B-0414",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "THUDM/GLM-4-9B-0414",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.08,
                "inputCacheHit": null,
                "output": 0.08,
                "videoGeneration": null
            },
            "description": "GLM-Z1-32B-0414 is a reasoning-focused AI model built on GLM-4-32B-0414. It has been enhanced through cold-start methods and reinforcement learning, with a strong emphasis on math, coding, and logic tasks. Despite having only 32B parameters, it performs comparably to the 671B DeepSeek-R1 on some benchmarks. It excels in complex reasoning tasks, as shown in evaluations like AIME 24/25, LiveCodeBench, and GPQA.",
            "extendedThinking": false,
            "id": "THUDM/GLM-Z1-32B-0414",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "THUDM/GLM-Z1-32B-0414",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.05,
                "inputCacheHit": null,
                "output": 0.05,
                "videoGeneration": null
            },
            "description": "GLM-Z1-9B-0414 is a small but powerful model in the GLM series, with only 9 billion parameters. Despite its size, it delivers strong performance in math reasoning and general tasks, ranking among the best in its class of open-source models.\n\nTrained with the same techniques as larger models, it strikes an excellent balance between performance and efficiency—making it a great option for low-resource or lightweight deployment scenarios.",
            "extendedThinking": false,
            "id": "THUDM/GLM-Z1-9B-0414",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "THUDM/GLM-Z1-9B-0414",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 15,
                "inputCacheHit": null,
                "output": 15,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "tts-1",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["audio"],
                "output": ["audio"]
            },
            "name": "tts-1",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 15,
                "inputCacheHit": null,
                "output": 15,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "tts-1-1106",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["audio"],
                "output": ["audio"]
            },
            "name": "tts-1-1106",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 30,
                "inputCacheHit": null,
                "output": 30,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "tts-1-hd",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["audio"],
                "output": ["audio"]
            },
            "name": "tts-1-hd",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 30,
                "inputCacheHit": null,
                "output": 30,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "tts-1-hd-1106",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["audio"],
                "output": ["audio"]
            },
            "name": "tts-1-hd-1106",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 0,
                "output": 2,
                "videoGeneration": null
            },
            "description": "The super-resolution upscale interface of the Ideogram AI drawing model is designed to enlarge low-resolution images into high-resolution ones, redrawing details (with controllable similarity and detail proportions).\nUS $0.06/ IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.",
            "extendedThinking": false,
            "id": "UPSCALE",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "UPSCALE",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 0,
                "output": 2,
                "videoGeneration": null
            },
            "description": "Fast and high-quality — top image quality in just 11 seconds per piece, with almost no extra time for batch generation.\nFlexible ratios — supports ultra-wide and tall formats like 3:1, 2:1, offering diverse perspectives.\nUnique strengths — outstanding design capabilities in the V3 and V2 series, with powerful text rendering (Chinese support coming soon).\nPrecise local editing — fine-tuned mask control for area redrawing (edit) and easy background replacement (replace-background).",
            "extendedThinking": false,
            "id": "V3",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "V3",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 0,
                "output": 2,
                "videoGeneration": null
            },
            "description": "V_1 is a text-to-image model in the Ideogram series. It delivers strong text rendering capabilities, high photorealistic image quality, and precise prompt adherence. The model also introduces Magic Prompt, a new feature that automatically refines input prompts to generate more detailed and creative visuals.",
            "extendedThinking": false,
            "id": "V_1",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "V_1",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 0,
                "output": 2,
                "videoGeneration": null
            },
            "description": "The Ideogram AI drawing interface is now live. This model boasts powerful text-to-image capabilities, supporting endpoints are: /generate, /remix.\nThis model is the ultra-fast version of the original V_1, offering increased speed at the slight expense of quality.\nUS $0.02/ IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.",
            "extendedThinking": false,
            "id": "V_1_TURBO",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "V_1_TURBO",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 0,
                "output": 2,
                "videoGeneration": null
            },
            "description": "The Ideogram AI drawing interface is now live. This model boasts powerful text-to-image capabilities, supporting endpoints are: /generate, /remix, /edit.\nThis model is the stable V_2 version, highly recommended for editing.\nUS $0.08/ 1 IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.",
            "extendedThinking": false,
            "id": "V_2",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "V_2",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 0,
                "output": 2,
                "videoGeneration": null
            },
            "description": "The Ideogram AI drawing interface is now live. This model boasts powerful text-to-image capabilities, supporting endpoints are: /generate, /remix, /edit.\nThis model is the fast version of V_2, offering increased speed at the slight expense of quality.\nUS $0.05/ IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.",
            "extendedThinking": false,
            "id": "V_2_TURBO",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "V_2_TURBO",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 0,
                "output": 2,
                "videoGeneration": null
            },
            "description": "The Ideogram AI drawing interface is now live. This model boasts powerful text-to-image capabilities, supporting endpoints are: /generate, /remix.\nThis model is the fast version of V_2, faster and cheaper.\nUS $0.04/ IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.",
            "extendedThinking": false,
            "id": "V_2A",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "V_2A",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 2,
                "input": 2,
                "inputCacheHit": 0,
                "output": 2,
                "videoGeneration": null
            },
            "description": "The Ideogram AI drawing interface is now live. This model boasts powerful text-to-image capabilities, supporting endpoints are: /generate, /remix.\nThis model is the ultra-fast version of V_2, delivering the highest speed while slightly reducing quality.\nUS $0.025/ IMG.\nFor usage examples and pricing details, refer to the documentation at https://docs.aihubmix.com/cn/api/IdeogramAI.",
            "extendedThinking": false,
            "id": "V_2A_TURBO",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "V_2A_TURBO",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": 0,
                "output": 2,
                "videoGeneration": 2
            },
            "description": "Veo 2.0 is an advanced video generation model capable of producing high-quality videos based on text or image prompts. It excels in understanding real-world physics and human motion, resulting in fluid character movements and lifelike scenes. Veo 2.0 supports various visual styles and camera control options, including lens types, angles, and motion effects. Users can generate 8-second video clips at 720p resolution.",
            "extendedThinking": false,
            "id": "veo-2.0-generate-001",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["video"],
                "output": ["video"]
            },
            "name": "veo-2.0-generate-001",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": 0,
                "output": 2,
                "videoGeneration": 2
            },
            "description": "veo3 reverse access with a total cost of just $0.41 per video generation., OpenAI chat port compatible format.\nNote that this is a reverse interface, and charges are based on the number of requests. As long as a request is initiated, even if it returns a failure, you will be charged. If you cannot accept this, please do not use it.",
            "extendedThinking": false,
            "id": "veo3",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image", "audio", "video"],
                "output": ["video"]
            },
            "name": "veo3",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": 0,
                "output": 2,
                "videoGeneration": 2
            },
            "description": "Veo 3.0 Generate Preview is an advanced AI video generation model that supports text-to-video creation with synchronized audio, featuring excellent physical simulation and lip-sync capabilities. Users can generate vivid video clips from short story prompts. 🎟️ Limited-Time Deal: Save 10% Now.",
            "extendedThinking": false,
            "id": "veo-3.0-generate-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image", "video"],
                "output": ["video"]
            },
            "name": "veo-3.0-generate-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 200,
                "inputCacheHit": null,
                "output": 200,
                "videoGeneration": 200
            },
            "description": "veo3.1 reverse model, and other available model names that can be requested include: veo3.1-pro and veo3.1-components. The price is currently tentatively set to be calculated per token, approximately $0.05 per request.",
            "extendedThinking": false,
            "id": "veo3.1",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["video"]
            },
            "name": "veo3.1",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 0,
                "videoGeneration": 2
            },
            "description": "Veo 3.1 is Google's state-of-the-art model for generating high-fidelity, 8-second 720p or 1080p videos featuring stunning realism and natively generated audio.",
            "extendedThinking": false,
            "id": "veo-3.1-fast-generate-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image", "video"],
                "output": ["video"]
            },
            "name": "veo-3.1-fast-generate-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": 0,
                "output": 2,
                "videoGeneration": 2
            },
            "description": "Veo 3.1 is Google's state-of-the-art model for generating high-fidelity, 8-second 720p or 1080p videos featuring stunning realism and natively generated audio.",
            "extendedThinking": false,
            "id": "veo-3.1-generate-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image", "video"],
                "output": ["video"]
            },
            "name": "veo-3.1-generate-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 0,
                "videoGeneration": 2
            },
            "description": "The newly upgraded Tongyi Wanxiang 2.2 text-to-video offers higher video quality. It optimizes video generation stability and success rate, features stronger instruction-following capabilities, consistently maintains image text, portrait, and product consistency, and provides precise camera motion control.",
            "extendedThinking": false,
            "id": "wan2.2-i2v-plus",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["video"]
            },
            "name": "wan2.2-i2v-plus",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 0,
                "videoGeneration": 2
            },
            "description": "The newly upgraded Tongyi Wanxiang 2.2 text-to-video offers higher video quality. It can stably generate large-scale complex motions, supports cinematic-level visual performance and control, and features enhanced instruction-following capabilities to achieve realistic physical world reproduction.",
            "extendedThinking": false,
            "id": "wan2.2-t2v-plus",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["video"]
            },
            "name": "wan2.2-t2v-plus",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 0,
                "videoGeneration": 2
            },
            "description": "Tongyi Wanxiang 2.5 - Text-to-Video Preview features a newly upgraded technical architecture, supporting sound generation synchronized with visuals, 10-second long video generation, stronger instruction-following capabilities, and further improvements in motion ability and visual quality.",
            "extendedThinking": false,
            "id": "wan2.5-i2v-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["video"]
            },
            "name": "wan2.5-i2v-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 0,
                "videoGeneration": 2
            },
            "description": "Tongyi Wanxiang 2.5 - Text-to-Video Preview, newly upgraded model architecture, supports sound generation synchronized with visuals, supports 10-second long video generation, enhanced instruction compliance, improved motion capability, and further enhanced visual quality.",
            "extendedThinking": false,
            "id": "wan2.5-t2v-preview",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["video"]
            },
            "name": "wan2.5-t2v-preview",
            "openWeights": false,
            "preview": true,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 0,
                "videoGeneration": 2
            },
            "description": "Wan 2.6 - Text-to-Video generation features intelligent storyboard scheduling supporting multi-shot narration, higher quality sound generation, stable multi-person dialogue, more natural and realistic voice tones, and supports video generation up to 15 seconds in length.",
            "extendedThinking": false,
            "id": "wan2.6-i2v",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["video"]
            },
            "name": "wan2.6-i2v",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 0,
                "videoGeneration": 2
            },
            "description": "Wan 2.6 - Text-to-Video generation features intelligent storyboard scheduling supporting multi-shot narration, higher quality sound generation, stable multi-person dialogue, more natural and realistic voice tones, and supports video generation up to 15 seconds in length.",
            "extendedThinking": false,
            "id": "wan2.6-t2v",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["video"]
            },
            "name": "wan2.6-t2v",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": 3,
                "input": 3,
                "inputCacheHit": 0,
                "output": 3,
                "videoGeneration": null
            },
            "description": "gpt-image-1.5 Drawing Reverse Interface: perfectly replicates the raw image capabilities of the Web version, supporting text-to-image and image-to-text generation; each use costs $0.005 (approximately 0.04 RMB). Please note this interface is extremely unstable, and charges will be applied even if the generation fails. Avoid using it if you are concerned.",
            "extendedThinking": false,
            "id": "web-gpt-image-1.5",
            "imageGeneration": true,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "web-gpt-image-1.5",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": 2
            },
            "description": "This model is an unofficial reverse-engineered API of the OpenAI web version sora-2-hd, for entertainment purposes only. Charges apply regardless of generation success or failure, billed per use. Please avoid using it if you mind. It can be used via the chat interface, allowing intuitive image uploads: you can directly upload images through the chat interface as the basis for video generation.\n\nPrecise parameter control: by appending commands such as \"landscape/portrait,\" \"16:9/9:16,\" \"10 seconds/15 seconds,\" etc., at the end of the prompt, you can directly define the video's aspect ratio and duration.",
            "extendedThinking": false,
            "id": "web-sora-2",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["video"]
            },
            "name": "web-sora-2",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 2,
                "inputCacheHit": null,
                "output": 2,
                "videoGeneration": 2
            },
            "description": "This model is an unofficial reverse-engineered API of the OpenAI web version sora-2-hd, for entertainment purposes only. Charges apply regardless of generation success or failure, billed per use. Please avoid using it if you mind. It can be used via the chat interface, allowing intuitive image uploads: you can directly upload images through the chat interface as the basis for video generation.\n\nPrecise parameter control: by appending commands such as \"landscape/portrait,\" \"16:9/9:16,\" \"10 seconds/15 seconds,\" etc., at the end of the prompt, you can directly define the video's aspect ratio and duration.",
            "extendedThinking": false,
            "id": "web-sora-2-pro",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["video"]
            },
            "name": "web-sora-2-pro",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 100,
                "inputCacheHit": null,
                "output": 100,
                "videoGeneration": null
            },
            "description": "Ignore the displayed price on the page; the actual charge for this model request is consistent with the official, so you can use it with confidence.",
            "extendedThinking": false,
            "id": "whisper-1",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["audio"],
                "output": ["text"]
            },
            "name": "whisper-1",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 30.834,
                "inputCacheHit": null,
                "output": 30.834,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "whisper-large-v3",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["audio"],
                "output": ["text"]
            },
            "name": "whisper-large-v3",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 5.556,
                "inputCacheHit": null,
                "output": 5.556,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "whisper-large-v3-turbo",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["audio"],
                "output": ["text"]
            },
            "name": "whisper-large-v3-turbo",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix",
            "audioGeneration": true,
            "description": "Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation.",
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "WizardLM/WizardCoder-Python-34B-V1.0",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "WizardLM/WizardCoder-Python-34B-V1.0",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 4,
                "inputCacheHit": null,
                "output": 4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "yi-large-rag",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "yi-large-rag",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 1.8,
                "inputCacheHit": null,
                "output": 1.8,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "yi-large-turbo",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "yi-large-turbo",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "yi-lightning",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "yi-lightning",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.4,
                "inputCacheHit": null,
                "output": 0.4,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "yi-medium",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "yi-medium",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        },
        {
            "attachment": false,
            "cost": {
                "imageGeneration": null,
                "input": 0.000852,
                "inputCacheHit": null,
                "output": 0.000852,
                "videoGeneration": null
            },
            "extendedThinking": false,
            "id": "yi-vl-plus",
            "imageGeneration": false,
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "yi-vl-plus",
            "openWeights": false,
            "preview": false,
            "provider": "AIHubMix",
            "providerDoc": "https://docs.aihubmix.com",
            "providerEnv": ["AIHUBMIX_API_KEY"],
            "providerId": "ai-hub-mix",
            "providerNpm": "@aihubmix/ai-sdk-provider",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "aihubmix"
        }
    ]
}
