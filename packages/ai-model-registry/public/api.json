{
    "metadata": {
        "description": "AI Models API - Comprehensive database of AI model specifications, pricing, and features",
        "lastUpdated": "2026-01-10T23:24:47.758Z",
        "totalModels": 3051,
        "totalProviders": 33,
        "version": "0.0.0-development"
    },
    "models": [
        {
            "attachment": false,
            "cost": {
                "input": 0.00075,
                "inputCacheHit": null,
                "output": 0.00099
            },
            "extendedThinking": true,
            "id": "deepseek-r-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": 163840
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-r1",
            "openWeights": false,
            "provider": "Alibaba",
            "providerDoc": "https://help.aliyun.com/zh/model-studio/deepseek-api",
            "providerEnv": ["ALIBABA_API_KEY"],
            "providerId": "alibaba",
            "providerModelsDevId": "alibaba",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-01-20",
            "streamingSupported": true,
            "temperature": false,
            "toolCall": true,
            "vision": false,
            "icon": "alibaba"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0004,
                "inputCacheHit": null,
                "output": 0.00175
            },
            "extendedThinking": true,
            "id": "deepseek-r-1-0528",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-r1-0528",
            "openWeights": false,
            "provider": "Alibaba",
            "providerDoc": "https://help.aliyun.com/zh/model-studio/deepseek-api",
            "providerEnv": ["ALIBABA_API_KEY"],
            "providerId": "alibaba",
            "providerModelsDevId": "alibaba",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-05-28",
            "streamingSupported": true,
            "temperature": false,
            "toolCall": true,
            "vision": false,
            "icon": "alibaba"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.004,
                "inputCacheHit": null,
                "output": 0.016
            },
            "extendedThinking": true,
            "id": "deepseek-r-1-685b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-r1 685B",
            "openWeights": false,
            "provider": "Alibaba",
            "providerDoc": "https://help.aliyun.com/zh/model-studio/deepseek-api",
            "providerEnv": ["ALIBABA_API_KEY"],
            "providerId": "alibaba",
            "providerModelsDevId": "alibaba",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": false,
            "toolCall": true,
            "vision": false,
            "icon": "alibaba"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "deepseek-r-1-distill-qwen-1-5-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-r1-distill-qwen-1.5b",
            "openWeights": false,
            "provider": "Alibaba",
            "providerDoc": "https://help.aliyun.com/zh/model-studio/deepseek-api",
            "providerEnv": ["ALIBABA_API_KEY"],
            "providerId": "alibaba",
            "providerModelsDevId": "alibaba",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-01-31",
            "streamingSupported": true,
            "temperature": false,
            "toolCall": true,
            "vision": false,
            "icon": "alibaba"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0009,
                "inputCacheHit": null,
                "output": 0.0009
            },
            "extendedThinking": false,
            "id": "deepseek-v-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-v3",
            "openWeights": false,
            "provider": "Alibaba",
            "providerDoc": "https://help.aliyun.com/zh/model-studio/deepseek-api",
            "providerEnv": ["ALIBABA_API_KEY"],
            "providerId": "alibaba",
            "providerModelsDevId": "alibaba",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "alibaba"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00023,
                "inputCacheHit": null,
                "output": 0.0009
            },
            "extendedThinking": false,
            "id": "deepseek-v-3-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-v3.1",
            "openWeights": false,
            "provider": "Alibaba",
            "providerDoc": "https://help.aliyun.com/zh/model-studio/deepseek-api",
            "providerEnv": ["ALIBABA_API_KEY"],
            "providerId": "alibaba",
            "providerModelsDevId": "alibaba",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "alibaba"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00027,
                "inputCacheHit": null,
                "output": 0.0004
            },
            "extendedThinking": false,
            "id": "deepseek-v-3-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-v3.2",
            "openWeights": false,
            "provider": "Alibaba",
            "providerDoc": "https://help.aliyun.com/zh/model-studio/deepseek-api",
            "providerEnv": ["ALIBABA_API_KEY"],
            "providerId": "alibaba",
            "providerModelsDevId": "alibaba",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "alibaba"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00027,
                "inputCacheHit": null,
                "output": 0.0004
            },
            "extendedThinking": false,
            "id": "deepseek-v-3-2-exp",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-v3.2-exp",
            "openWeights": false,
            "provider": "Alibaba",
            "providerDoc": "https://help.aliyun.com/zh/model-studio/deepseek-api",
            "providerEnv": ["ALIBABA_API_KEY"],
            "providerId": "alibaba",
            "providerModelsDevId": "alibaba",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "alibaba"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1,
                "inputCacheHit": null,
                "output": 0
            },
            "extendedThinking": false,
            "id": "moonshot-kimi-k2-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 0,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Moonshot-Kimi-K2-Instruct",
            "openWeights": false,
            "provider": "Alibaba",
            "providerDoc": "https://help.aliyun.com/zh/model-studio/kimi-api",
            "providerEnv": ["ALIBABA_API_KEY"],
            "providerId": "alibaba",
            "providerModelsDevId": "alibaba",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "alibaba"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "ai21.jamba-1-5-large-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-09-23",
            "launchDate": "9/23/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Jamba 1.5 Large",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/ai21-labs",
            "reasoning": false,
            "regions": ["us-east-1"],
            "releaseDate": "2024-09-23",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "ai21.jamba-1-5-mini-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-09-23",
            "launchDate": "9/23/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Jamba 1.5 Mini",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/ai21-labs",
            "reasoning": false,
            "regions": ["us-east-1"],
            "releaseDate": "2024-09-23",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "ai21.jamba-instruct-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-06-25",
            "launchDate": "6/25/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Jamba-Instruct",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/ai21-labs",
            "reasoning": false,
            "regions": ["us-east-1"],
            "releaseDate": "2024-06-25",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "amazon.nova-canvas-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-12-04",
            "launchDate": "12/4/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text", "image"]
            },
            "name": "Nova Canvas",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/amazon",
            "reasoning": false,
            "regions": ["us-east-1"],
            "releaseDate": "2024-12-04",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "amazon.nova-lite-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-12-04",
            "launchDate": "12/4/202412/4/202412/4/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text", "image", "video"]
            },
            "name": "Nova Lite",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/amazon",
            "reasoning": false,
            "regions": ["us-east-1", "us-east-2*", "us-west-2*"],
            "releaseDate": "2024-12-04",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "amazon.nova-micro-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-12-04",
            "launchDate": "12/4/202412/4/202412/4/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nova Micro",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/amazon",
            "reasoning": false,
            "regions": ["us-east-1", "us-east-2*", "us-west-2*"],
            "releaseDate": "2024-12-04",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "amazon.nova-pro-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-12-04",
            "launchDate": "12/4/202412/4/202412/4/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text", "image", "video"]
            },
            "name": "Nova Pro",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/amazon",
            "reasoning": false,
            "regions": ["us-east-1", "us-east-2*", "us-west-2*"],
            "releaseDate": "2024-12-04",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "amazon.nova-reel-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-12-04",
            "launchDate": "12/4/202412/4/202412/4/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text", "image"]
            },
            "name": "Nova Reel",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/amazon",
            "reasoning": false,
            "regions": ["us-east-1"],
            "releaseDate": "2024-12-04",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "amazon.rerank-v1:0",
            "knowledge": null,
            "lastUpdated": null,
            "launchDate": "",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Rerank 1.0",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/amazon",
            "reasoning": false,
            "regions": ["us-west-2", "ap-northeast-1", "ca-central-1", "eu-central-1"],
            "releaseDate": null,
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "amazon.titan-embed-image-v1",
            "knowledge": null,
            "lastUpdated": "2023-11-29",
            "launchDate": "11/29/202311/29/20234/30/20243/27/20246/13/20246/27/20244/30/20246/13/20243/27/20246/13/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text", "image"]
            },
            "name": "Titan Multimodal Embeddings G1",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/amazon",
            "reasoning": false,
            "regions": [
                "us-east-1",
                "us-west-2",
                "ap-south-1",
                "ap-southeast-2",
                "ca-central-1",
                "eu-central-1",
                "eu-west-1 (Gated)",
                "eu-west-2",
                "eu-west-3",
                "sa-east-1"
            ],
            "releaseDate": "2023-11-29",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "amazon.titan-embed-text-v1",
            "knowledge": null,
            "lastUpdated": "2023-11-29",
            "launchDate": "11/29/202311/29/202311/29/202311/29/2023",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Titan Embeddings G1 - Text",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/amazon",
            "reasoning": false,
            "regions": ["us-east-1", "us-west-2", "ap-northeast-1", "eu-central-1"],
            "releaseDate": "2023-11-29",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "amazon.titan-embed-text-v2:0",
            "knowledge": null,
            "lastUpdated": "2024-04-30",
            "launchDate": "4/30/20244/30/202411/8/20248/13/202412/13/20249/30/202412/13/202410/10/20246/13/20246/27/202410/31/20246/13/202412/13/20246/13/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Titan Text Embeddings V2",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/amazon",
            "reasoning": false,
            "regions": [
                "us-east-1",
                "us-east-2",
                "us-west-2",
                "us-gov-east-1",
                "us-gov-west-1",
                "ap-northeast-1",
                "ap-northeast-2",
                "ap-south-1",
                "ap-southeast-1",
                "ap-southeast-2",
                "ca-central-1",
                "eu-central-1",
                "eu-central-2",
                "eu-west-2",
                "eu-west-3",
                "sa-east-1"
            ],
            "releaseDate": "2024-04-30",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "amazon.titan-image-generator-v1",
            "knowledge": null,
            "lastUpdated": "2023-12-01",
            "launchDate": "12/1/202312/1/20234/30/20244/30/20246/13/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Titan Image Generator G1",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/amazon",
            "reasoning": false,
            "regions": ["us-east-1", "us-west-2", "ap-south-1", "eu-west-1 (Gated)", "eu-west-2"],
            "releaseDate": "2023-12-01",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "amazon.titan-image-generator-v2:0",
            "knowledge": null,
            "lastUpdated": "2024-08-06",
            "launchDate": "8/6/20248/6/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text", "image"]
            },
            "name": "Titan Image Generator G1 v2",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/amazon",
            "reasoning": false,
            "regions": ["us-east-1", "us-west-2"],
            "releaseDate": "2024-08-06",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "amazon.titan-text-express-v1",
            "knowledge": null,
            "lastUpdated": "2023-11-29",
            "launchDate": "11/29/202311/29/202311/29/202311/29/20234/30/20243/27/20246/13/202411/29/20234/30/20246/13/20243/27/20246/13/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Titan Text G1 - Express",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/amazon",
            "reasoning": false,
            "regions": [
                "us-east-1",
                "us-west-2",
                "us-gov-west-1",
                "ap-northeast-1",
                "ap-south-1",
                "ap-southeast-2",
                "ca-central-1",
                "eu-central-1",
                "eu-west-1 (Gated)",
                "eu-west-2",
                "eu-west-3",
                "sa-east-1"
            ],
            "releaseDate": "2023-11-29",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "amazon.titan-text-lite-v1",
            "knowledge": null,
            "lastUpdated": "2023-11-29",
            "launchDate": "11/29/202311/29/20234/30/20243/27/20246/13/20246/27/20244/30/20246/13/20243/27/20246/13/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Titan Text G1 - Lite",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/amazon",
            "reasoning": false,
            "regions": [
                "us-east-1",
                "us-west-2",
                "ap-south-1",
                "ap-southeast-2",
                "ca-central-1",
                "eu-central-1",
                "eu-west-1 (Gated)",
                "eu-west-2",
                "eu-west-3",
                "sa-east-1"
            ],
            "releaseDate": "2023-11-29",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "amazon.titan-text-premier-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-05-07",
            "launchDate": "5/7/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Titan Text G1 - Premier",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/amazon",
            "reasoning": false,
            "regions": ["us-east-1"],
            "releaseDate": "2024-05-07",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "anthropic.claude-3-5-haiku-20241022-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-11-04",
            "launchDate": "11/4/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Claude 3.5 Haiku",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/anthropic",
            "reasoning": false,
            "regions": ["us-east-1*", "us-east-2*", "us-west-2"],
            "releaseDate": "2024-11-04",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "anthropic.claude-3-5-sonnet-20240620-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-06-20",
            "launchDate": "6/20/20247/30/20248/7/20248/5/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text", "image"]
            },
            "name": "Claude 3.5 Sonnet v1",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/anthropic",
            "reasoning": false,
            "regions": ["us-gov-east-1*", "us-gov-west-1", "ap-northeast-1", "ap-northeast-2", "ap-south-1*", "ap-southeast-1 (Gated)", "ap-southeast-2*"],
            "releaseDate": "2024-06-20",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "anthropic.claude-3-5-sonnet-20241022-v2:0",
            "knowledge": null,
            "lastUpdated": "2024-10-22",
            "launchDate": "10/22/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text", "image"]
            },
            "name": "Claude 3.5 Sonnet v2",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/anthropic",
            "reasoning": false,
            "regions": ["ap-northeast-1", "ap-northeast-2", "ap-northeast-3", "ap-south-1", "ap-south-2", "ap-southeast-1", "ap-southeast-2"],
            "releaseDate": "2024-10-22",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "anthropic.claude-3-7-sonnet-20250219-v1:0",
            "knowledge": null,
            "lastUpdated": "2025-02-24",
            "launchDate": "2/24/2025",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text", "image"]
            },
            "name": "Claude 3.7 Sonnet",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/anthropic",
            "reasoning": false,
            "releaseDate": "2025-02-24",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "anthropic.claude-3-haiku-20240307-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-03-14",
            "launchDate": "3/14/20243/14/20248/30/20247/30/20244/30/20248/7/20244/6/20246/13/20244/30/20245/9/20244/4/20246/13/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text", "image"]
            },
            "name": "Claude 3 Haiku",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/anthropic",
            "reasoning": false,
            "regions": [
                "us-east-1",
                "us-east-2*",
                "us-west-2",
                "us-gov-east-1*",
                "us-gov-west-1",
                "ap-northeast-1",
                "ap-northeast-2",
                "ap-south-1",
                "ap-southeast-1 (Gated)",
                "ap-southeast-2",
                "ca-central-1",
                "eu-central-1",
                "eu-central-2",
                "eu-west-1 (Gated)",
                "eu-west-2",
                "eu-west-3",
                "sa-east-1"
            ],
            "releaseDate": "2024-03-14",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "anthropic.claude-3-sonnet-20240229-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-03-04",
            "launchDate": "3/4/20243/4/2024--4/30/2024-4/6/20246/13/20245/29/20244/30/20245/9/20244/4/20246/13/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Claude 3 Sonnet",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/anthropic",
            "reasoning": false,
            "regions": [
                "us-east-1",
                "us-west-2",
                "ap-northeast-1*",
                "ap-northeast-2*",
                "ap-south-1",
                "ap-southeast-1 (Gated)*",
                "ap-southeast-2",
                "ca-central-1",
                "eu-central-1",
                "eu-west-1 (Gated)",
                "eu-west-2",
                "eu-west-3",
                "sa-east-1"
            ],
            "releaseDate": "2024-03-04",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "anthropic.claude-haiku-4-5-20251001-v1:0",
            "knowledge": null,
            "lastUpdated": "2025-10-01",
            "launchDate": "10/1/2025",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text", "image"]
            },
            "name": "Claude Haiku 4.5",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/anthropic",
            "reasoning": false,
            "regions": ["us-east-1*", "us-east-2*", "us-west-2*"],
            "releaseDate": "2025-10-01",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "anthropic.claude-instant-v1",
            "knowledge": null,
            "lastUpdated": "2023-11-29",
            "launchDate": "--11/29/202311/29/2023",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Claude Instant",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/anthropic",
            "reasoning": false,
            "regions": ["us-east-1", "us-west-2", "ap-northeast-1", "ap-southeast-1 (Gated)", "eu-central-1"],
            "releaseDate": "2023-11-29",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "anthropic.claude-opus-4-1-20250805-v1:0",
            "knowledge": null,
            "lastUpdated": "2025-07-31",
            "launchDate": "7/31/20257/31/20257/31/2025",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text", "image"]
            },
            "name": "Claude Opus 4.1",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/anthropic",
            "reasoning": false,
            "regions": ["us-east-1*", "us-east-2*", "us-west-2*"],
            "releaseDate": "2025-07-31",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "anthropic.claude-opus-4-20250514-v1:0",
            "knowledge": null,
            "lastUpdated": "2025-05-22",
            "launchDate": "5/22/20255/22/20255/22/2025",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text", "image"]
            },
            "name": "Claude Opus 4.0",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/anthropic",
            "reasoning": false,
            "regions": ["us-east-1*", "us-east-2*", "us-west-2*"],
            "releaseDate": "2025-05-22",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "anthropic.claude-sonnet-4-20250514-v1:0",
            "knowledge": null,
            "lastUpdated": "2025-05-22",
            "launchDate": "5/22/20255/22/20255/22/2025",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text", "image"]
            },
            "name": "Claude Sonnet 4.0",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/anthropic",
            "reasoning": false,
            "regions": ["us-east-1*", "us-east-2*", "us-west-2*"],
            "releaseDate": "2025-05-22",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "anthropic.claude-sonnet-4-5-20250929-v1:0",
            "knowledge": null,
            "lastUpdated": "2025-09-29",
            "launchDate": "9/29/2025",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text", "image"]
            },
            "name": "Claude Sonnet 4.5",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/anthropic",
            "reasoning": false,
            "regions": ["us-east-1*", "us-east-2*", "us-west-2*"],
            "releaseDate": "2025-09-29",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "anthropic.claude-v2",
            "knowledge": null,
            "lastUpdated": "2023-08-01",
            "launchDate": "8/1/2023-11/29/2024-",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Claude 2",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/anthropic",
            "reasoning": false,
            "regions": ["us-east-1", "us-west-2", "ap-southeast-1 (Gated)", "eu-central-1"],
            "releaseDate": "2023-08-01",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "anthropic.claude-v2:1",
            "knowledge": null,
            "lastUpdated": "2023-11-29",
            "launchDate": "11/29/202311/29/202312/21/2023-",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Claude 2.1",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/anthropic",
            "reasoning": false,
            "regions": ["us-east-1", "us-west-2", "ap-northeast-1", "eu-central-1"],
            "releaseDate": "2023-11-29",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "cohere.command-light-text-v14",
            "knowledge": null,
            "lastUpdated": "2023-11-13",
            "launchDate": "11/13/202311/13/2023",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Command Light",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/cohere",
            "reasoning": false,
            "regions": ["us-east-1", "us-west-2"],
            "releaseDate": "2023-11-13",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "cohere.command-r-plus-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-04-29",
            "launchDate": "4/29/20244/29/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Command R+",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/cohere",
            "reasoning": false,
            "regions": ["us-east-1", "us-west-2"],
            "releaseDate": "2024-04-29",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "cohere.command-r-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-04-29",
            "launchDate": "4/29/20244/29/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Command R",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/cohere",
            "reasoning": false,
            "regions": ["us-east-1", "us-west-2"],
            "releaseDate": "2024-04-29",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0005,
                "inputCacheHit": null,
                "output": 0.0015
            },
            "id": "cohere.command-text-v14",
            "knowledge": null,
            "lastUpdated": "2023-11-13",
            "launchDate": "11/13/202311/13/2023",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Command",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/cohere",
            "reasoning": false,
            "regions": ["us-east-1", "us-west-2"],
            "releaseDate": "2023-11-13",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "cohere.embed-english-v3",
            "knowledge": null,
            "lastUpdated": "2025-01-24",
            "launchDate": "1/24/2025",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cohere Embed English",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/cohere",
            "reasoning": false,
            "releaseDate": "2025-01-24",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "cohere.embed-multilingual-v3",
            "knowledge": null,
            "lastUpdated": "2025-01-24",
            "launchDate": "1/24/2025",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cohere Embed Multilingual",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/cohere",
            "reasoning": false,
            "releaseDate": "2025-01-24",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "cohere.rerank-v3-5:0",
            "knowledge": null,
            "lastUpdated": null,
            "launchDate": "",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Rerank 3.5",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/cohere",
            "reasoning": false,
            "regions": ["us-west-2", "ap-northeast-1", "ca-central-1", "eu-central-1"],
            "releaseDate": null,
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00075,
                "inputCacheHit": null,
                "output": 0.00099
            },
            "extendedThinking": false,
            "id": "deepseek.r1-v1:0",
            "knowledge": null,
            "lastUpdated": "2025-03-10",
            "launchDate": "3/10/2025",
            "limit": {
                "context": 163840,
                "output": 163840
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/deep-seek",
            "reasoning": false,
            "regions": ["us-east-1", "us-east-2", "us-west-2"],
            "releaseDate": "2025-03-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "luma.ray-v2:0",
            "knowledge": null,
            "lastUpdated": "2025-01-23",
            "launchDate": "1/23/2025",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Luma Ray v2",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/luma",
            "reasoning": false,
            "regions": ["us-west-2"],
            "releaseDate": "2025-01-23",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "id": "meta.llama3-1-405b-instruct-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-12-03",
            "launchDate": "12/3/20247/23/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.1 405B Instruct",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/meta",
            "reasoning": false,
            "regions": ["us-east-2*", "us-west-2"],
            "releaseDate": "2024-12-03",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "id": "meta.llama3-1-70b-instruct-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-10-26",
            "launchDate": "10/26/202410/26/20247/23/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.1 70B Instruct",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/meta",
            "reasoning": false,
            "regions": ["us-east-1*", "us-east-2*", "us-west-2"],
            "releaseDate": "2024-10-26",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "id": "meta.llama3-1-8b-instruct-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-10-26",
            "launchDate": "10/26/202410/26/20247/23/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.1 8B Instruct",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/meta",
            "reasoning": false,
            "regions": ["us-east-1*", "us-east-2*", "us-west-2"],
            "releaseDate": "2024-10-26",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "id": "meta.llama3-2-11b-instruct-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-09-25",
            "launchDate": "9/25/202410/26/20249/25/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text", "image"]
            },
            "name": "Llama 3.2 11B Instruct",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/meta",
            "reasoning": false,
            "regions": ["us-east-1*", "us-east-2*", "us-west-2*"],
            "releaseDate": "2024-09-25",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "id": "meta.llama3-2-1b-instruct-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-09-25",
            "launchDate": "9/25/202410/26/20249/25/20249/25/20249/25/20249/25/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.2 1B Instruct",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/meta",
            "reasoning": false,
            "regions": ["us-east-1*", "us-east-2*", "us-west-2*", "eu-central-1*", "eu-west-1 (Gated)*", "eu-west-3*"],
            "releaseDate": "2024-09-25",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "id": "meta.llama3-2-3b-instruct-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-09-25",
            "launchDate": "9/25/202410/26/20249/25/20249/25/20249/25/20249/25/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.2 3B Instruct",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/meta",
            "reasoning": false,
            "regions": ["us-east-1*", "us-east-2*", "us-west-2*", "eu-central-1*", "eu-west-1 (Gated)*", "eu-west-3*"],
            "releaseDate": "2024-09-25",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "id": "meta.llama3-2-90b-instruct-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-09-25",
            "launchDate": "9/25/202410/26/20249/25/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text", "image"]
            },
            "name": "Llama 3.2 90B Instruct",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/meta",
            "reasoning": false,
            "regions": ["us-east-1*", "us-east-2*", "us-west-2*"],
            "releaseDate": "2024-09-25",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "id": "meta.llama3-3-70b-instruct-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-12-19",
            "launchDate": "12/19/202412/19/202412/19/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.3 70B Instruct",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/meta",
            "reasoning": false,
            "regions": ["us-east-1*", "us-east-2", "us-west-2*"],
            "releaseDate": "2024-12-19",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "id": "meta.llama3-70b-instruct-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-04-23",
            "launchDate": "4/23/20244/23/20248/1/20244/30/20246/13/20246/13/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3 70B Instruct",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/meta",
            "reasoning": false,
            "regions": ["us-east-1", "us-west-2", "us-gov-west-1", "ap-south-1", "ca-central-1", "eu-west-2"],
            "releaseDate": "2024-04-23",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "id": "meta.llama3-8b-instruct-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-04-23",
            "launchDate": "4/23/20244/23/20248/1/20244/30/20246/13/20246/13/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3 8B Instruct",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/meta",
            "reasoning": false,
            "regions": ["us-east-1", "us-west-2", "us-gov-west-1", "ap-south-1", "ca-central-1", "eu-west-2"],
            "releaseDate": "2024-04-23",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "id": "meta.llama4-maverick-17b-instruct-v1:0",
            "knowledge": null,
            "lastUpdated": "2025-04-28",
            "launchDate": "4/28/2025",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text", "image"]
            },
            "name": "Llama 4 Maverick 17B Instruct",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/meta",
            "reasoning": false,
            "regions": ["us-east-1", "us-east-2", "us-west-2"],
            "releaseDate": "2025-04-28",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "id": "meta.llama4-scout-17b-instruct-v1:0",
            "knowledge": null,
            "lastUpdated": "2025-04-28",
            "launchDate": "4/28/2025",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text", "image"]
            },
            "name": "Llama 4 Scout 17B Instruct",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/meta",
            "reasoning": false,
            "regions": ["us-east-1", "us-east-2", "us-west-2"],
            "releaseDate": "2025-04-28",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "mistral.pixtral-large-2502-v1:0",
            "knowledge": null,
            "lastUpdated": "2025-04-08",
            "launchDate": "4/8/2025",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Pixtral Large (25.02)",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/miatral",
            "reasoning": false,
            "releaseDate": "2025-04-08",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "id": "mistral.mistral-7b-instruct-v0:2",
            "knowledge": null,
            "lastUpdated": "2024-03-09",
            "launchDate": "3/9/20243/1/20244/30/20243/29/20246/13/20244/30/20246/13/20243/29/20246/13/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral 7B Instruct",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/mistral-ai",
            "reasoning": false,
            "regions": ["us-east-1", "us-west-2", "ap-south-1", "ap-southeast-2", "ca-central-1", "eu-west-1 (Gated)", "eu-west-2", "eu-west-3", "sa-east-1"],
            "releaseDate": "2024-03-09",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "id": "mistral.mistral-large-2402-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-04-03",
            "launchDate": "4/3/20244/3/20244/30/20244/4/20246/13/20244/30/20246/13/20244/3/20246/13/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Large (24.02)",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/mistral-ai",
            "reasoning": false,
            "regions": ["us-east-1", "us-west-2", "ap-south-1", "ap-southeast-2", "ca-central-1", "eu-west-1 (Gated)", "eu-west-2", "eu-west-3", "sa-east-1"],
            "releaseDate": "2024-04-03",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral.mistral-large-2407-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-07-24",
            "launchDate": "7/24/2024",
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Large (24.07)",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/mistral-ai",
            "reasoning": false,
            "regions": ["us-west-2"],
            "releaseDate": "2024-07-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "id": "mistral.mistral-small-2402-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-05-24",
            "launchDate": "5/24/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Small (24.02)",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/mistral-ai",
            "reasoning": false,
            "regions": ["us-east-1"],
            "releaseDate": "2024-05-24",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "mistral.mixtral-8x7b-instruct-v0:1",
            "knowledge": null,
            "lastUpdated": "2024-03-09",
            "launchDate": "3/9/20243/1/20244/30/20243/29/20246/13/20244/30/20246/13/20243/29/20246/13/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mixtral 8x7B Instruct",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/mistral-ai",
            "reasoning": false,
            "regions": ["us-east-1", "us-west-2", "ap-south-1", "ap-southeast-2", "ca-central-1", "eu-west-1 (Gated)", "eu-west-2", "eu-west-3", "sa-east-1"],
            "releaseDate": "2024-03-09",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "stability.sd3-5-large-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-12-19",
            "launchDate": "12/19/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text", "image"]
            },
            "name": "Stable Diffusion 3.5 Large",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/stability-ai",
            "reasoning": false,
            "regions": ["us-west-2"],
            "releaseDate": "2024-12-19",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "stability.sd3-large-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-09-04",
            "launchDate": "9/4/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text", "image"]
            },
            "name": "SD3 Large 1.0",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/stability-ai",
            "reasoning": false,
            "regions": ["us-west-2"],
            "releaseDate": "2024-09-04",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "stability.stable-image-core-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-09-04",
            "launchDate": "9/4/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Stable Image Core 1.0",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/stability-ai",
            "reasoning": false,
            "regions": ["us-west-2"],
            "releaseDate": "2024-09-04",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "stability.stable-image-core-v1:1",
            "knowledge": null,
            "lastUpdated": "2024-12-19",
            "launchDate": "12/19/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Stable Image Core 1.1",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/stability-ai",
            "reasoning": false,
            "regions": ["us-west-2"],
            "releaseDate": "2024-12-19",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "stability.stable-image-ultra-v1:0",
            "knowledge": null,
            "lastUpdated": "2024-09-04",
            "launchDate": "9/4/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Stable Image Ultra 1.0",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/stability-ai",
            "reasoning": false,
            "regions": ["us-west-2"],
            "releaseDate": "2024-09-04",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "stability.stable-image-ultra-v1:1",
            "knowledge": null,
            "lastUpdated": "2024-12-19",
            "launchDate": "12/19/2024",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Stable Image Ultra 1.1",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/stability-ai",
            "reasoning": false,
            "regions": ["us-west-2"],
            "releaseDate": "2024-12-19",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "writer.palmyra-x4-v1:0",
            "knowledge": null,
            "lastUpdated": "2025-04-28",
            "launchDate": "4/28/2025",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Palmyra X4",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/writer",
            "reasoning": false,
            "regions": ["us-west-2"],
            "releaseDate": "2025-04-28",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "id": "writer.palmyra-x5-v1:0",
            "knowledge": null,
            "lastUpdated": "2025-04-28",
            "launchDate": "4/28/2025",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Palmyra X5",
            "openWeights": true,
            "provider": "Amazon Bedrock",
            "providerId": "amazon-bedrock/writer",
            "reasoning": false,
            "regions": ["us-west-2"],
            "releaseDate": "2025-04-28",
            "streamingSupported": null,
            "temperature": true,
            "toolCall": true,
            "icon": "bedrock"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.25,
                "inputCacheHit": null,
                "output": 1.25
            },
            "extendedThinking": false,
            "id": "claude-haiku-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 4000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Claude Haiku 3",
            "openWeights": false,
            "provider": "Anthropic",
            "providerDoc": "https://platform.claude.com/docs/en/about-claude/models/overview",
            "providerEnv": ["ANTHROPIC_API_KEY"],
            "providerId": "anthropic",
            "providerModelsDevId": "anthropic",
            "providerNpm": "@ai-sdk/anthropic",
            "reasoning": false,
            "releaseDate": "2024-03-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "anthropic"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.6,
                "inputCacheHit": null,
                "output": 0.08
            },
            "extendedThinking": false,
            "id": "claude-haiku-3-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 0,
                "output": 1
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Claude Haiku 3.5",
            "openWeights": false,
            "provider": "Anthropic",
            "providerDoc": "https://docs.anthropic.com/en/docs/about-claude/models",
            "providerEnv": ["ANTHROPIC_API_KEY"],
            "providerId": "anthropic",
            "providerModelsDevId": "anthropic",
            "providerNpm": "@ai-sdk/anthropic",
            "reasoning": false,
            "releaseDate": "2024-03-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "anthropic"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1,
                "inputCacheHit": null,
                "output": 5
            },
            "extendedThinking": true,
            "id": "claude-haiku-4-5",
            "knowledge": "2025",
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Claude Haiku 4.5",
            "openWeights": false,
            "provider": "Anthropic",
            "providerDoc": "https://platform.claude.com/docs/en/about-claude/models/overview",
            "providerEnv": ["ANTHROPIC_API_KEY"],
            "providerId": "anthropic",
            "providerModelsDevId": "anthropic",
            "providerNpm": "@ai-sdk/anthropic",
            "reasoning": true,
            "releaseDate": "2025-10-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "anthropic"
        },
        {
            "attachment": false,
            "cost": {
                "input": 30,
                "inputCacheHit": null,
                "output": 1.5
            },
            "extendedThinking": true,
            "id": "claude-opus-3-(deprecated)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 15,
                "output": 18
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Claude Opus 3 (deprecated)",
            "openWeights": false,
            "provider": "Anthropic",
            "providerDoc": "https://docs.anthropic.com/en/docs/about-claude/models",
            "providerEnv": ["ANTHROPIC_API_KEY"],
            "providerId": "anthropic",
            "providerModelsDevId": "anthropic",
            "providerNpm": "@ai-sdk/anthropic",
            "reasoning": true,
            "releaseDate": "2024-02-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "anthropic"
        },
        {
            "attachment": false,
            "cost": {
                "input": 15,
                "inputCacheHit": null,
                "output": 75
            },
            "extendedThinking": true,
            "id": "claude-opus-4",
            "knowledge": "2025",
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 32000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Claude Opus 4",
            "openWeights": false,
            "provider": "Anthropic",
            "providerDoc": "https://platform.claude.com/docs/en/about-claude/models/overview",
            "providerEnv": ["ANTHROPIC_API_KEY"],
            "providerId": "anthropic",
            "providerModelsDevId": "anthropic",
            "providerNpm": "@ai-sdk/anthropic",
            "reasoning": true,
            "releaseDate": "2025-05-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "anthropic"
        },
        {
            "attachment": false,
            "cost": {
                "input": 15,
                "inputCacheHit": null,
                "output": 75
            },
            "extendedThinking": true,
            "id": "claude-opus-4-1",
            "knowledge": "2025",
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 32000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Claude Opus 4.1",
            "openWeights": false,
            "provider": "Anthropic",
            "providerDoc": "https://platform.claude.com/docs/en/about-claude/models/overview",
            "providerEnv": ["ANTHROPIC_API_KEY"],
            "providerId": "anthropic",
            "providerModelsDevId": "anthropic",
            "providerNpm": "@ai-sdk/anthropic",
            "reasoning": true,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "anthropic"
        },
        {
            "attachment": false,
            "cost": {
                "input": 5,
                "inputCacheHit": null,
                "output": 25
            },
            "extendedThinking": true,
            "id": "claude-opus-4-5",
            "knowledge": "2025",
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Claude Opus 4.5",
            "openWeights": false,
            "provider": "Anthropic",
            "providerDoc": "https://platform.claude.com/docs/en/about-claude/models/overview",
            "providerEnv": ["ANTHROPIC_API_KEY"],
            "providerId": "anthropic",
            "providerModelsDevId": "anthropic",
            "providerNpm": "@ai-sdk/anthropic",
            "reasoning": true,
            "releaseDate": "2025-11-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "anthropic"
        },
        {
            "attachment": false,
            "cost": {
                "input": 6,
                "inputCacheHit": null,
                "output": 0.3
            },
            "extendedThinking": true,
            "id": "claude-sonnet-3-5-(deprecated)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 3,
                "output": 3
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Claude Sonnet 3.5 (deprecated)",
            "openWeights": false,
            "provider": "Anthropic",
            "providerDoc": "https://docs.anthropic.com/en/docs/about-claude/models",
            "providerEnv": ["ANTHROPIC_API_KEY"],
            "providerId": "anthropic",
            "providerModelsDevId": "anthropic",
            "providerNpm": "@ai-sdk/anthropic",
            "reasoning": true,
            "releaseDate": "2024-03-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "anthropic"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3,
                "inputCacheHit": null,
                "output": 15
            },
            "extendedThinking": true,
            "id": "claude-sonnet-3-7",
            "knowledge": "2024",
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Claude Sonnet 3.7",
            "openWeights": false,
            "provider": "Anthropic",
            "providerDoc": "https://platform.claude.com/docs/en/about-claude/models/overview",
            "providerEnv": ["ANTHROPIC_API_KEY"],
            "providerId": "anthropic",
            "providerModelsDevId": "anthropic",
            "providerNpm": "@ai-sdk/anthropic",
            "reasoning": true,
            "releaseDate": "2025-02-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "anthropic"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3,
                "inputCacheHit": null,
                "output": 15
            },
            "extendedThinking": true,
            "id": "claude-sonnet-4",
            "knowledge": "2025",
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Claude Sonnet 4",
            "openWeights": false,
            "provider": "Anthropic",
            "providerDoc": "https://platform.claude.com/docs/en/about-claude/models/overview",
            "providerEnv": ["ANTHROPIC_API_KEY"],
            "providerId": "anthropic",
            "providerModelsDevId": "anthropic",
            "providerNpm": "@ai-sdk/anthropic",
            "reasoning": true,
            "releaseDate": "2025-05-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "anthropic"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3,
                "inputCacheHit": null,
                "output": 15
            },
            "extendedThinking": true,
            "id": "claude-sonnet-4-5",
            "knowledge": "2025",
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Claude Sonnet 4.5",
            "openWeights": false,
            "provider": "Anthropic",
            "providerDoc": "https://platform.claude.com/docs/en/about-claude/models/overview",
            "providerEnv": ["ANTHROPIC_API_KEY"],
            "providerId": "anthropic",
            "providerModelsDevId": "anthropic",
            "providerNpm": "@ai-sdk/anthropic",
            "reasoning": true,
            "releaseDate": "2025-09-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "anthropic"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0015,
                "inputCacheHit": null,
                "output": 0.002
            },
            "extendedThinking": false,
            "id": "gpt-35-turbo-(0125)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-35-turbo (0125)",
            "openWeights": false,
            "provider": "Azure OpenAI",
            "providerDoc": "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
            "providerEnv": ["AZURE_OPENAI_API_KEY", "AZURE_OPENAI_ENDPOINT"],
            "providerId": "azure-open-ai",
            "providerModelsDevId": "azure-openai",
            "providerNpm": "@ai-sdk/azure-openai",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "azure"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0015,
                "inputCacheHit": null,
                "output": 0.002
            },
            "extendedThinking": false,
            "id": "gpt-35-turbo-(1106)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-35-turbo (1106)",
            "openWeights": false,
            "provider": "Azure OpenAI",
            "providerDoc": "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
            "providerEnv": ["AZURE_OPENAI_API_KEY", "AZURE_OPENAI_ENDPOINT"],
            "providerId": "azure-open-ai",
            "providerModelsDevId": "azure-openai",
            "providerNpm": "@ai-sdk/azure-openai",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "azure"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "gpt-4-(turbo-2024-04-09)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-4 (turbo-2024-04-09)",
            "openWeights": false,
            "provider": "Azure OpenAI",
            "providerDoc": "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
            "providerEnv": ["AZURE_OPENAI_API_KEY", "AZURE_OPENAI_ENDPOINT"],
            "providerId": "azure-open-ai",
            "providerModelsDevId": "azure-openai",
            "providerNpm": "@ai-sdk/azure-openai",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "azure"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "description": "Lifecycle: Generally Available | Deprecation: 2025-11-20 | Retirement: 2026-06-03 | Replacement: gpt-5.1",
            "extendedThinking": false,
            "id": "gpt-4-o-(2024-05-13)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-4o (2024-05-13)",
            "openWeights": false,
            "provider": "Azure OpenAI",
            "providerDoc": "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
            "providerEnv": ["AZURE_OPENAI_API_KEY", "AZURE_OPENAI_ENDPOINT"],
            "providerId": "azure-open-ai",
            "providerModelsDevId": "azure-openai",
            "providerNpm": "@ai-sdk/azure-openai",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "azure"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "description": "Lifecycle: Generally Available | Deprecation: 2025-11-20 | Retirement: 2026-06-03 | Replacement: gpt-5.1",
            "extendedThinking": false,
            "id": "gpt-4-o-(2024-08-06)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-4o (2024-08-06)",
            "openWeights": false,
            "provider": "Azure OpenAI",
            "providerDoc": "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
            "providerEnv": ["AZURE_OPENAI_API_KEY", "AZURE_OPENAI_ENDPOINT"],
            "providerId": "azure-open-ai",
            "providerModelsDevId": "azure-openai",
            "providerNpm": "@ai-sdk/azure-openai",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "azure"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "description": "Lifecycle: Generally Available | Deprecation: 2025-11-20 | Retirement: 2026-06-03 | Replacement: gpt-5.1",
            "extendedThinking": false,
            "id": "gpt-4-o-(2024-11-20)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-4o (2024-11-20)",
            "openWeights": false,
            "provider": "Azure OpenAI",
            "providerDoc": "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
            "providerEnv": ["AZURE_OPENAI_API_KEY", "AZURE_OPENAI_ENDPOINT"],
            "providerId": "azure-open-ai",
            "providerModelsDevId": "azure-openai",
            "providerNpm": "@ai-sdk/azure-openai",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "azure"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "description": "Lifecycle: Generally Available | Deprecation: 2025-11-20 | Retirement: 2026-06-03 | Replacement: gpt-5.1",
            "extendedThinking": false,
            "id": "gpt-4-o-mini-(2024-07-18)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gpt-4o-mini (2024-07-18)",
            "openWeights": false,
            "provider": "Azure OpenAI",
            "providerDoc": "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
            "providerEnv": ["AZURE_OPENAI_API_KEY", "AZURE_OPENAI_ENDPOINT"],
            "providerId": "azure-open-ai",
            "providerModelsDevId": "azure-openai",
            "providerNpm": "@ai-sdk/azure-openai",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "azure"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.015,
                "inputCacheHit": null,
                "output": 0.06
            },
            "description": "Lifecycle: Generally Available | Deprecation: 2025-12-17 | Retirement: 2026-06-18 | Replacement: o3",
            "extendedThinking": false,
            "id": "o-1-mini-(2024-09-12)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "o1-mini (2024-09-12)",
            "openWeights": false,
            "provider": "Azure OpenAI",
            "providerDoc": "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
            "providerEnv": ["AZURE_OPENAI_API_KEY", "AZURE_OPENAI_ENDPOINT"],
            "providerId": "azure-open-ai",
            "providerModelsDevId": "azure-openai",
            "providerNpm": "@ai-sdk/azure-openai",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "azure"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.015,
                "inputCacheHit": null,
                "output": 0.06
            },
            "description": "Lifecycle: Generally Available | Deprecation: 2025-12-17 | Retirement: 2026-06-18 | Replacement: o3",
            "extendedThinking": false,
            "id": "o-1-preview-(2024-09-12)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "o1-preview (2024-09-12)",
            "openWeights": false,
            "provider": "Azure OpenAI",
            "providerDoc": "https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",
            "providerEnv": ["AZURE_OPENAI_API_KEY", "AZURE_OPENAI_ENDPOINT"],
            "providerId": "azure-open-ai",
            "providerModelsDevId": "azure-openai",
            "providerNpm": "@ai-sdk/azure-openai",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "azure"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0001,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": true,
            "id": "FP16",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen-3-32b",
            "openWeights": false,
            "provider": "cerebras",
            "providerDoc": "https://inference-docs.cerebras.ai/models/overview",
            "providerEnv": ["CEREBRAS_API_KEY"],
            "providerId": "cerebras",
            "providerNpm": "@ai-sdk/cerebras",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "cerebras"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "FP16/FP8 (weights only)1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 202752,
                "output": 65535
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "zai-glm-4.7",
            "openWeights": false,
            "provider": "cerebras",
            "providerDoc": "https://inference-docs.cerebras.ai/models/overview",
            "providerEnv": ["CEREBRAS_API_KEY"],
            "providerId": "cerebras",
            "providerNpm": "@ai-sdk/cerebras",
            "reasoning": true,
            "releaseDate": "2025-12-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "cerebras"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.35,
                "inputCacheHit": null,
                "output": 0.75
            },
            "extendedThinking": true,
            "id": "gpt-oss-120b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI GPT OSS",
            "openWeights": false,
            "provider": "cerebras",
            "providerDoc": "https://inference-docs.cerebras.ai/models/overview",
            "providerEnv": ["CEREBRAS_API_KEY"],
            "providerId": "cerebras",
            "providerNpm": "@ai-sdk/cerebras",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "cerebras",
            "audioGeneration": false,
            "description": "OpenAIs open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases  gpt-oss-120b is for production, general purpose, high reasoning use-cases.",
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": true,
            "id": "llama3.1-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.1 8B",
            "openWeights": false,
            "provider": "cerebras",
            "providerDoc": "https://inference-docs.cerebras.ai/models/overview",
            "providerEnv": ["CEREBRAS_API_KEY"],
            "providerId": "cerebras",
            "providerNpm": "@ai-sdk/cerebras",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "cerebras"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.85,
                "inputCacheHit": null,
                "output": 1.2
            },
            "extendedThinking": true,
            "id": "llama-3.3-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.3 70B",
            "openWeights": false,
            "provider": "cerebras",
            "providerDoc": "https://inference-docs.cerebras.ai/models/overview",
            "providerEnv": ["CEREBRAS_API_KEY"],
            "providerId": "cerebras",
            "providerNpm": "@ai-sdk/cerebras",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "cerebras"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0002,
                "inputCacheHit": null,
                "output": 0.0006
            },
            "extendedThinking": false,
            "id": "llama-4-maverick-17b-128e-instruct",
            "knowledge": null,
            "lastUpdated": "2025-04-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama-4-Maverick-17B-128E-Instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00011,
                "inputCacheHit": null,
                "output": 0.00034
            },
            "extendedThinking": false,
            "id": "llama-4-scout-17b-16e-instruct",
            "knowledge": null,
            "lastUpdated": "2025-04-10",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama-4-Scout-17B-16E-Instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope",
            "audioGeneration": false,
            "description": "Meta's Llama 4 Scout is a 17 billion parameter model with 16 experts that is natively multimodal. These models leverage a mixture-of-experts architecture to offer industry-leading performance in text and image understanding.",
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-235b-a22b-instruct-2507",
            "knowledge": null,
            "lastUpdated": "2025-09-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-235B-A22B-Instruct-2507",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00011,
                "inputCacheHit": null,
                "output": 0.0006
            },
            "extendedThinking": true,
            "id": "qwen-3-235b-a22b-thinking-2507",
            "knowledge": null,
            "lastUpdated": "2025-08-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-235B-A22B-Thinking-2507",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-07-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00029,
                "inputCacheHit": null,
                "output": 0.00059
            },
            "extendedThinking": false,
            "id": "qwen-3-32b",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-32B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope",
            "preview": true
        },
        {
            "attachment": false,
            "cost": {
                "input": 2,
                "inputCacheHit": null,
                "output": 2
            },
            "extendedThinking": true,
            "id": "qwen-3-coder-480b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen 3 480B Coder",
            "openWeights": false,
            "provider": "cerebras",
            "providerDoc": "https://inference-docs.cerebras.ai/models/overview",
            "providerEnv": ["CEREBRAS_API_KEY"],
            "providerId": "cerebras",
            "providerNpm": "@ai-sdk/cerebras",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "cerebras"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2.25,
                "inputCacheHit": null,
                "output": 2.75
            },
            "extendedThinking": true,
            "id": "zai-glm-4.6",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Z.ai GLM 4.6",
            "openWeights": false,
            "provider": "cerebras",
            "providerDoc": "https://inference-docs.cerebras.ai/models/overview",
            "providerEnv": ["CEREBRAS_API_KEY"],
            "providerId": "cerebras",
            "providerNpm": "@ai-sdk/cerebras",
            "reasoning": true,
            "releaseDate": "2025-09-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "cerebras"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2.25,
                "inputCacheHit": null,
                "output": 2.75
            },
            "extendedThinking": true,
            "id": "zai-glm-4.7",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Z.ai GLM 4.7 1",
            "openWeights": false,
            "provider": "cerebras",
            "providerDoc": "https://inference-docs.cerebras.ai/models/overview",
            "providerEnv": ["CEREBRAS_API_KEY"],
            "providerId": "cerebras",
            "providerNpm": "@ai-sdk/cerebras",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "cerebras"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000015,
                "inputCacheHit": null,
                "output": 0.000015
            },
            "extendedThinking": false,
            "id": "agentica-org/DeepCoder-14B-Preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 384000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepCoder-14B-Preview",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "all-hands/openhands-lm-32b-v0.1-ep3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "openhands-lm-32b-v0.1-ep3",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00003,
                "inputCacheHit": null,
                "output": 0.00011
            },
            "extendedThinking": false,
            "id": "ArliAI/QwQ-32B-ArliAI-RpR-v1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "QwQ-32B-ArliAI-RpR-v1",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00005,
                "inputCacheHit": null,
                "output": 0.00022
            },
            "extendedThinking": false,
            "id": "chutesai/Devstral-Small-2505",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 524288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Devstral-Small-2505",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0,
                "inputCacheHit": null,
                "output": 0
            },
            "extendedThinking": false,
            "id": "chutesai/Llama-4-Maverick-17B-128E-Instruct-FP8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 512000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama-4-Maverick-17B-128E-Instruct-FP8",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00014,
                "inputCacheHit": null,
                "output": 0.00042
            },
            "extendedThinking": false,
            "id": "chutesai/Mistral-Small-3.1-24B-Instruct-2503",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 524288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral-Small-3.1-24B-Instruct-2503",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00014,
                "inputCacheHit": null,
                "output": 0.00042
            },
            "extendedThinking": false,
            "id": "chutesai/Mistral-Small-3.2-24B-Instruct-2506",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 524288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral-Small-3.2-24B-Instruct-2506",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00004,
                "inputCacheHit": null,
                "output": 0.00017
            },
            "extendedThinking": false,
            "id": "cognitivecomputations/Dolphin3.0-Mistral-24B",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Dolphin3.0-Mistral-24B",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "cognitivecomputations/Dolphin3.0-R1-Mistral-24B",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Dolphin3.0-R1-Mistral-24B",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00075,
                "inputCacheHit": null,
                "output": 0.00099
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-R1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 655360,
                "output": 163840
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0004,
                "inputCacheHit": null,
                "output": 0.00175
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-R1-0528",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 655360,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-0528",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes",
            "providerModelsDevId": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00003,
                "inputCacheHit": null,
                "output": 0.00011
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 524288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-0528-Qwen3-8B",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-R1-0528-TEE",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 655360,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-0528-TEE",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00075,
                "inputCacheHit": null,
                "output": 0.00099
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 524288,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-Distill-Llama-70B",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes",
            "providerModelsDevId": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-R1-TEE",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 655360,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-TEE",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0009,
                "inputCacheHit": null,
                "output": 0.0009
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-V3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 655360,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes",
            "providerModelsDevId": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-V3-0324",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 655360,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3-0324",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes",
            "providerModelsDevId": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-V3-0324-TEE",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 655360,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3-0324-TEE",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-V3.1-TEE",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 655360,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.1-TEE",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-V3.1-Terminus-TEE",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 655360,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.1-Terminus-TEE",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-V3.2-Speciale-TEE",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 655360,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.2-Speciale-TEE",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-V3.2-TEE",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 655360,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.2-TEE",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-V3-Base",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 655360,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3-Base",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "internlm/Intern-S1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Intern-S1",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "microsoft/MAI-DS-R1-FP8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 655360,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MAI-DS-R1-FP8",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "MiniMaxAI/MiniMax-M2.1-TEE",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 786432,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniMax-M2.1-TEE",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "miromind-ai/MiroThinker-v1.5-235B",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiroThinker-v1.5-235B",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mistralai/Devstral-2-123B-Instruct-2512",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Devstral-2-123B-Instruct-2512",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mistralai/Devstral-2-123B-Instruct-2512-TEE",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Devstral-2-123B-Instruct-2512-TEE",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00029,
                "inputCacheHit": null,
                "output": 0.00115
            },
            "extendedThinking": false,
            "id": "moonshotai/Kimi-Dev-72B",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 524288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kimi-Dev-72B",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.001,
                "inputCacheHit": null,
                "output": 0.003
            },
            "extendedThinking": false,
            "id": "moonshotai/Kimi-K2-Instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 300000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kimi-K2-Instruct",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes",
            "providerModelsDevId": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "moonshotai/Kimi-K2-Instruct-0905",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kimi-K2-Instruct-0905",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes",
            "providerModelsDevId": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "moonshotai/Kimi-K2-Thinking-TEE",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kimi-K2-Thinking-TEE",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "moonshotai/Kimi-VL-A3B-Thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 524288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kimi-VL-A3B-Thinking",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00003,
                "inputCacheHit": null,
                "output": 0.00011
            },
            "extendedThinking": false,
            "id": "NousResearch/DeepHermes-3-Llama-3-8B-Preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 524288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepHermes-3-Llama-3-8B-Preview",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00015,
                "inputCacheHit": null,
                "output": 0.00059
            },
            "extendedThinking": false,
            "id": "NousResearch/DeepHermes-3-Mistral-24B-Preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepHermes-3-Mistral-24B-Preview",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "NousResearch/Hermes-4-14B",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Hermes-4-14B",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "NousResearch/Hermes-4.3-36B",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2097152,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Hermes-4.3-36B",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "NousResearch/Hermes-4-405B-FP8-TEE",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 524288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Hermes-4-405B-FP8-TEE",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00011,
                "inputCacheHit": null,
                "output": 0.00038
            },
            "extendedThinking": false,
            "id": "NousResearch/Hermes-4-70B",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 524288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Hermes-4-70B",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "nvidia/Llama-3_3-Nemotron-Super-49B-v1_5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 524288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama-3_3-Nemotron-Super-49B-v1_5",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "OpenGVLab/InternVL3-78B-TEE",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "InternVL3-78B-TEE",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai/gpt-oss-120b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI: gpt-oss-120b",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai/gpt-oss-120b-TEE",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 524288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-oss-120b-TEE",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai/gpt-oss-20b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI: gpt-oss-20b",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0012,
                "inputCacheHit": null,
                "output": 0.0012
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen2.5-72B-Instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-72B-Instruct",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0008,
                "inputCacheHit": null,
                "output": 0.0008
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen2.5-Coder-32B-Instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder-32B-Instruct",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-11-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00005,
                "inputCacheHit": null,
                "output": 0.00022
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen2.5-VL-32B-Instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-VL-32B-Instruct",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00008,
                "inputCacheHit": null,
                "output": 0.00033
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen2.5-VL-72B-Instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-VL-72B-Instruct",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen2.5-VL-72B-Instruct-TEE",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-VL-72B-Instruct-TEE",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00005,
                "inputCacheHit": null,
                "output": 0.00022
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen3-14B",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-14B",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes",
            "providerModelsDevId": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00018,
                "inputCacheHit": null,
                "output": 0.00054
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen3-235B-A22B",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-235B-A22B",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen3-235B-A22B-Instruct-2507",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-235B-A22B-Instruct-2507",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes",
            "providerModelsDevId": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen3-235B-A22B-Instruct-2507-TEE",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-235B-A22B-Instruct-2507-TEE",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00011,
                "inputCacheHit": null,
                "output": 0.0006
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen3-235B-A22B-Thinking-2507",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-235B-A22B-Thinking-2507",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes",
            "providerModelsDevId": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00006,
                "inputCacheHit": null,
                "output": 0.00022
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen3-30B-A3B",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-30B-A3B",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes",
            "providerModelsDevId": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00008,
                "inputCacheHit": null,
                "output": 0.00033
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen3-30B-A3B-Instruct-2507",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-30B-A3B-Instruct-2507",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00029,
                "inputCacheHit": null,
                "output": 0.00059
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen3-32B",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-32B",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes",
            "providerModelsDevId": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00003,
                "inputCacheHit": null,
                "output": 0.00011
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen3-8B",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-8B",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00006,
                "inputCacheHit": null,
                "output": 0.00025
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen3-Coder-30B-A3B-Instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Coder-30B-A3B-Instruct",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Coder-480B-A35B-Instruct-FP8",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8-TEE",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Coder-480B-A35B-Instruct-FP8-TEE",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen3Guard-Gen-0.6B",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3Guard-Gen-0.6B",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0001,
                "inputCacheHit": null,
                "output": 0.0008
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen3-Next-80B-A3B-Instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Next-80B-A3B-Instruct",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes",
            "providerModelsDevId": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0012
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen3-VL-235B-A22B-Instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-235B-A22B-Instruct",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "rednote-hilab/dots.ocr",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 524288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "dots.ocr",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "Salesforce/xgen-small-9B-instruct-r",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "xgen-small-9B-instruct-r",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "shisa-ai/shisa-v2-llama3.3-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Shisa AI: Shisa V2 Llama 3.3 70B ",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "stepfun-ai/step3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": 65536
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["text"]
            },
            "name": "StepFun: Step3",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00003,
                "inputCacheHit": null,
                "output": 0.00003
            },
            "extendedThinking": false,
            "id": "tencent/Hunyuan-A13B-Instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Hunyuan-A13B-Instruct",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "Tesslate/UIGEN-X-32B-0727",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "UIGEN-X-32B-0727",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "TheDrummer/Cydonia-24B-v2.1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cydonia-24B-v2.1",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "TheDrummer/Gemmasutra-Pro-27B-v1.1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemmasutra-Pro-27B-v1.1",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00008,
                "inputCacheHit": null,
                "output": 0.00033
            },
            "extendedThinking": false,
            "id": "TheDrummer/Skyfall-36B-v2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Skyfall-36B-v2",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "TheDrummer/Tunguska-39B-v1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 524288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Tunguska-39B-v1",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0012
            },
            "extendedThinking": false,
            "id": "tngtech/DeepSeek-R1T-Chimera",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 655360,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1T-Chimera",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "tngtech/DeepSeek-TNG-R1T2-Chimera",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 655360,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-TNG-R1T2-Chimera",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "tngtech/TNG-R1T-Chimera-TEE",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 655360,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "TNG-R1T-Chimera-TEE",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "tplr/TEMPLAR-I",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "TEMPLAR-I",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00008,
                "inputCacheHit": null,
                "output": 0.00008
            },
            "extendedThinking": false,
            "id": "unsloth/gemma-2-9b-it",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemma-2-9b-it",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00003,
                "inputCacheHit": null,
                "output": 0.0001
            },
            "extendedThinking": false,
            "id": "unsloth/gemma-3-12b-it",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4194304,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemma-3-12b-it",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00009,
                "inputCacheHit": null,
                "output": 0.00016
            },
            "extendedThinking": false,
            "id": "unsloth/gemma-3-27b-it",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4194304,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemma-3-27b-it",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000170301,
                "inputCacheHit": null,
                "output": 0.0000681536
            },
            "extendedThinking": false,
            "id": "unsloth/gemma-3-4b-it",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 524288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemma-3-4b-it",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00002,
                "inputCacheHit": null,
                "output": 0.00002
            },
            "extendedThinking": false,
            "id": "unsloth/Llama-3.2-1B-Instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama-3.2-1B-Instruct",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00003,
                "inputCacheHit": null,
                "output": 0.00005
            },
            "extendedThinking": false,
            "id": "unsloth/Llama-3.2-3B-Instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama-3.2-3B-Instruct",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "unsloth/Mistral-Nemo-Instruct-2407",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 524288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral-Nemo-Instruct-2407",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00014,
                "inputCacheHit": null,
                "output": 0.00042
            },
            "extendedThinking": false,
            "id": "unsloth/Mistral-Small-24B-Instruct-2501",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral-Small-24B-Instruct-2501",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "XiaomiMiMo/MiMo-V2-Flash",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiMo-V2-Flash",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "zai-org/GLM-4-32B-0414",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4-32B-0414",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00013,
                "inputCacheHit": null,
                "output": 0.00085
            },
            "extendedThinking": false,
            "id": "zai-org/GLM-4.5-Air",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 524288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.5-Air",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes",
            "providerModelsDevId": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "zai-org/GLM-4.5-FP8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 393216,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.5-FP8",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "zai-org/GLM-4.5-TEE",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 524288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.5-TEE",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "zai-org/GLM-4.5V-FP8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.5V-FP8",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "zai-org/GLM-4.6-TEE",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 811008,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.6-TEE",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "zai-org/GLM-4.6V",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 524288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.6V",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "zai-org/GLM-4.7-TEE",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 811008,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.7-TEE",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "zai-org/GLM-Z1-32B-0414",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-Z1-32B-0414",
            "openWeights": false,
            "provider": "chutes",
            "providerDoc": "https://llm.chutes.ai/v1/models",
            "providerEnv": ["CHUTES_API_KEY"],
            "providerId": "chutes",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "chutes"
        },
        {
            "attachment": false,
            "audioGeneration": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Aura is a context-aware text-to-speech (TTS) model that applies natural pacing, expressiveness, and fillers based on the context of the provided text. The quality of your text input directly impacts the naturalness of the audio output.",
            "id": "aura-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["audio"],
                "output": ["text"]
            },
            "name": "aura-1",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": true,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Aura-2 is a context-aware text-to-speech (TTS) model that applies natural pacing, expressiveness, and fillers based on the context of the provided text. The quality of your text input directly impacts the naturalness of the audio output.",
            "id": "aura-2-en",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["audio"],
                "output": ["text"]
            },
            "name": "aura-2-en",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": true,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Aura-2 is a context-aware text-to-speech (TTS) model that applies natural pacing, expressiveness, and fillers based on the context of the provided text. The quality of your text input directly impacts the naturalness of the audio output.",
            "id": "aura-2-es",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["audio"],
                "output": ["text"]
            },
            "name": "aura-2-es",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": true,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "BART is a transformer encoder-encoder (seq2seq) model with a bidirectional (BERT-like) encoder and an autoregressive (GPT-like) decoder. You can use this model for text summarization.",
            "id": "bart-large-cnn",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "bart-large-cnn",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "BAAI general embedding (Base) model that transforms any given text into a 768-dimensional vector",
            "id": "bge-base-en-v1.5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "bge-base-en-v1.5",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "BAAI general embedding (Large) model that transforms any given text into a 1024-dimensional vector",
            "id": "bge-large-en-v1.5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "bge-large-en-v1.5",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Multi-Functionality, Multi-Linguality, and Multi-Granularity embeddings model.",
            "id": "bge-m3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 60000000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "bge-m3",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bge-reranker-base",
            "knowledge": null,
            "lastUpdated": "2024-09-13",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "bge-reranker-base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope",
            "audioGeneration": false,
            "description": "Different from embedding model, reranker uses question and document as input and directly output similarity instead of embedding. You can get a relevance score by inputting query and passage to the reranker. And the score can be mapped to a float value in [0,1] by sigmoid function.",
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "BAAI general embedding (Small) model that transforms any given text into a 384-dimensional vector",
            "id": "bge-small-en-v1.5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "bge-small-en-v1.5",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Deepseek Coder is composed of a series of code language models, each trained from scratch on 2T tokens, with a composition of 87% code and 13% natural language in both English and Chinese.",
            "id": "deepseek-coder-6.7b-base-awq",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-coder-6.7b-base-awq",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Deepseek Coder is composed of a series of code language models, each trained from scratch on 2T tokens, with a composition of 87% code and 13% natural language in both English and Chinese.",
            "id": "deepseek-coder-6.7b-instruct-awq",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-coder-6.7b-instruct-awq",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "DeepSeekMath-Instruct 7B is a mathematically instructed tuning model derived from DeepSeekMath-Base 7B. DeepSeekMath is initialized with DeepSeek-Coder-v1.5 7B and continues pre-training on math-related tokens sourced from Common Crawl, together with natural language and code data for 500B tokens.",
            "id": "deepseek-math-7b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-math-7b-instruct",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "description": "DeepSeek-R1-Distill-Qwen-32B is a model distilled from DeepSeek-R1 based on Qwen2.5. It outperforms OpenAI-o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.",
            "extendedThinking": false,
            "id": "deepseek-r1-distill-qwen-32b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 80000000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-r1-distill-qwen-32b",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": "2025-01-29",
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "DEtection TRansformer (DETR) model trained end-to-end on COCO 2017 object detection (118k annotated images).",
            "id": "detr-resnet-50",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "detr-resnet-50",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": true,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "DiscoLM German 7b is a Mistral-based large language model with a focus on German-language applications. AWQ is an efficient, accurate and blazing-fast low-bit weight quantization method, currently supporting 4-bit quantization.",
            "id": "discolm-german-7b-v1-awq",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "discolm-german-7b-v1-awq",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Distilled BERT model that was finetuned on SST-2 for sentiment classification",
            "id": "distilbert-sst-2-int8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "distilbert-sst-2-int8",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Stable Diffusion model that has been fine-tuned to be better at photorealism without sacrificing range.",
            "id": "dreamshaper-8-lcm",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "dreamshaper-8-lcm",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": true,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "EmbeddingGemma is a 300M parameter, state-of-the-art for its size, open embedding model from Google, built from Gemma 3 (with T5Gemma initialization) and the same research and technology used to create Gemini models. EmbeddingGemma produces vector representations of text, making it well-suited for search and retrieval tasks, including classification, clustering, and semantic similarity search. This model was trained with data in 100+ spoken languages.",
            "id": "embeddinggemma-300m",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "embeddinggemma-300m",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Falcon-7B-Instruct is a 7B parameters causal decoder-only model built by TII based on Falcon-7B and finetuned on a mixture of chat/instruct datasets.",
            "id": "falcon-7b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "falcon-7b-instruct",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": true,
            "cost": {
                "input": 0,
                "inputCacheHit": null,
                "output": 0
            },
            "description": "Flux is the first conversational speech recognition model built specifically for voice agents.",
            "id": "flux",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["audio"],
                "output": ["text"]
            },
            "name": "flux",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-schnell",
            "knowledge": null,
            "lastUpdated": "2024-09-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX.1-schnell",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-08-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope",
            "audioGeneration": false,
            "description": "FLUX.1 [schnell] is a 12 billion parameter rectified flow transformer capable of generating images from text descriptions.",
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-2-dev",
            "knowledge": null,
            "lastUpdated": "2025-12-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image"]
            },
            "name": "flux2-dev",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope",
            "audioGeneration": false,
            "description": "FLUX.2 [dev] is an image model from Black Forest Labs where you can generate highly realistic and detailed images, with multi-reference support.",
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "This is a Gemma-2B base model that Cloudflare dedicates for inference with LoRA adapters. Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.",
            "id": "gemma-2b-it-lora",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemma-2b-it-lora",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.00003,
                "inputCacheHit": null,
                "output": 0.0001
            },
            "description": "Gemma 3 models are well-suited for a variety of text generation and image understanding tasks, including question answering, summarization, and reasoning. Gemma 3 models are multimodal, handling text and image input and generating text output, with a large, 128K context window, multilingual support in over 140 languages, and is available in more sizes than previous versions.",
            "id": "gemma-3-12b-it",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 80000000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gemma-3-12b-it",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": true,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.00007,
                "inputCacheHit": null,
                "output": 0.00007
            },
            "description": "Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models. They are text-to-text, decoder-only large language models, available in English, with open weights, pre-trained variants, and instruction-tuned variants.",
            "id": "gemma-7b-it",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemma-7b-it",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.00007,
                "inputCacheHit": null,
                "output": 0.00007
            },
            "description": "This is a Gemma-7B base model that Cloudflare dedicates for inference with LoRA adapters. Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.",
            "id": "gemma-7b-it-lora",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 3500000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemma-7b-it-lora",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "SEA-LION stands for Southeast Asian Languages In One Network, which is a collection of Large Language Models (LLMs) which have been pretrained and instruct-tuned for the Southeast Asia (SEA) region.",
            "id": "gemma-sea-lion-v4-27b-it",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemma-sea-lion-v4-27b-it",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.0001,
                "inputCacheHit": null,
                "output": 0.0001
            },
            "description": "OpenAIs open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases  gpt-oss-20b is for lower latency, and local or specialized use-cases.",
            "id": "gpt-oss-20b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-oss-20b",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.000017,
                "inputCacheHit": null,
                "output": 0.00011
            },
            "description": "Granite 4.0 instruct models deliver strong performance across benchmarks, achieving industry-leading results in key agentic tasks like instruction following and function calling. These efficiencies make the models well-suited for a wide range of use cases like retrieval-augmented generation (RAG), multi-agent workflows, and edge deployments.",
            "id": "granite-4.0-h-micro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131000000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "granite-4.0-h-micro",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "hermes-2-pro-mistral-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Hermes 2 Pro Mistral 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks",
            "audioGeneration": false,
            "description": "Hermes 2 Pro on Mistral 7B is the new flagship 7B Hermes! Hermes 2 Pro is an upgraded, retrained version of Nous Hermes 2, consisting of an updated and cleaned version of the OpenHermes 2.5 Dataset, as well as a newly introduced Function Calling and JSON Mode dataset developed in-house.",
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "IndicTrans2 is the first open-source transformer-based multilingual NMT model that supports high-quality translations across all the 22 scheduled Indic languages",
            "id": "indictrans2-en-indic-1B",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "indictrans2-en-indic-1B",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "description": "Llama 2 13B Chat AWQ is an efficient, accurate and blazing-fast low-bit weight quantized Llama 2 variant.",
            "id": "llama-2-13b-chat-awq",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-2-13b-chat-awq",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "description": "Full precision (fp16) generative text model with 7 billion parameters from Meta",
            "id": "llama-2-7b-chat-fp16",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-2-7b-chat-fp16",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "description": "This is a Llama2 base model that Cloudflare dedicated for inference with LoRA adapters. Llama 2 is a collection of pretrained and fine-tuned generative text models ranging in scale from 7 billion to 70 billion parameters. This is the repository for the 7B fine-tuned model, optimized for dialogue use cases and converted for the Hugging Face Transformers format.",
            "id": "llama-2-7b-chat-hf-lora",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-2-7b-chat-hf-lora",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "description": "Quantized (int8) generative text model with 7 billion parameters from Meta",
            "id": "llama-2-7b-chat-int8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-2-7b-chat-int8",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.00045,
                "inputCacheHit": null,
                "output": 0.00045
            },
            "description": "The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models. The Llama 3.1 instruction tuned text only models are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks.",
            "id": "llama-3.1-70b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 24000000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "llama-3.1-70b-instruct",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": true,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.0001,
                "inputCacheHit": null,
                "output": 0.0001
            },
            "description": "The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models. The Llama 3.1 instruction tuned text only models are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks.",
            "id": "llama-3.1-8b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 7968000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3.1-8b-instruct",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "description": "Quantized (int4) generative text model with 8 billion parameters from Meta.",
            "id": "llama-3.1-8b-instruct-awq",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3.1-8b-instruct-awq",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "description": "[Fast version] The Meta Llama 3.1 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction tuned generative models. The Llama 3.1 instruction tuned text only models are optimized for multilingual dialogue use cases and outperform many of the available open source and closed chat models on common industry benchmarks.",
            "id": "llama-3.1-8b-instruct-fast",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "llama-3.1-8b-instruct-fast",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": true,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "description": "Llama 3.1 8B quantized to FP8 precision",
            "id": "llama-3.1-8b-instruct-fp8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32000000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3.1-8b-instruct-fp8",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.00006,
                "inputCacheHit": null,
                "output": 0.00006
            },
            "description": "The Llama 3.2-Vision instruction-tuned models are optimized for visual recognition, image reasoning, captioning, and answering general questions about an image.",
            "id": "llama-3.2-11b-vision-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "llama-3.2-11b-vision-instruct",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": true,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.00002,
                "inputCacheHit": null,
                "output": 0.00002
            },
            "description": "The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks.",
            "id": "llama-3.2-1b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 60000000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3.2-1b-instruct",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.00003,
                "inputCacheHit": null,
                "output": 0.00005
            },
            "description": "The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks.",
            "id": "llama-3.2-3b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3.2-3b-instruct",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0,
                "inputCacheHit": null,
                "output": 0
            },
            "description": "Llama 3.3 70B quantized to fp8 precision, optimized to be faster.",
            "id": "llama-3.3-70b-instruct-fp8-fast",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 24000000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3.3-70b-instruct-fp8-fast",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-3-8b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3 8B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks",
            "audioGeneration": false,
            "description": "Generation over generation, Meta Llama 3 demonstrates state-of-the-art performance on a wide range of industry benchmarks and offers new capabilities, including improved reasoning.",
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "description": "Quantized (int4) generative text model with 8 billion parameters from Meta.",
            "id": "llama-3-8b-instruct-awq",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3-8b-instruct-awq",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-guard-3-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama Guard 3 8B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": "2025-02-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks",
            "audioGeneration": false,
            "description": "Llama Guard 3 is a Llama-3.1-8B pretrained model, fine-tuned for content safety classification. Similar to previous versions, it can be used to classify content in both LLM inputs (prompt classification) and in LLM responses (response classification). It acts as an LLM  it generates text in its output that indicates whether a given prompt or response is safe or unsafe, and if unsafe, it also lists the content categories violated.",
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "description": "Llama Guard is a model for classifying the safety of LLM prompts and responses, using a taxonomy of safety risks.",
            "id": "llamaguard-7b-awq",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llamaguard-7b-awq",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "LLaVA is an open-source chatbot trained by fine-tuning LLaMA/Vicuna on GPT-generated multimodal instruction-following data. It is an auto-regressive language model, based on the transformer architecture.",
            "id": "llava-1.5-7b-hf",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "llava-1.5-7b-hf",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": true,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Lucid Origin from Leonardo.AI is their most adaptable and prompt-responsive model to date. Whether you're generating images with sharp graphic design, stunning full-HD renders, or highly specific creative direction, it adheres closely to your prompts, renders text with accuracy, and supports a wide array of visual styles and aesthetics  from stylized concept art to crisp product mockups.",
            "id": "lucid-origin",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "lucid-origin",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": true,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation",
            "id": "m2m100-1.2b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "m2m100-1.2b",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "MeloTTS is a high-quality multi-lingual text-to-speech library by MyShell.ai.",
            "id": "melotts",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["audio"],
                "output": ["text"]
            },
            "name": "melotts",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama-3-8b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-06-23",
            "limit": {
                "context": 8192,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta-Llama-3-8B-Instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-04-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope",
            "audioGeneration": false,
            "description": "Generation over generation, Meta Llama 3 demonstrates state-of-the-art performance on a wide range of industry benchmarks and offers new capabilities, including improved reasoning.",
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.00014,
                "inputCacheHit": null,
                "output": 0.00042
            },
            "description": "Instruct fine-tuned version of the Mistral-7b generative text model with 7 billion parameters",
            "id": "mistral-7b-instruct-v0.1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2824000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mistral-7b-instruct-v0.1",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.00014,
                "inputCacheHit": null,
                "output": 0.00042
            },
            "description": "Mistral 7B Instruct v0.1 AWQ is an efficient, accurate and blazing-fast low-bit weight quantized Mistral variant.",
            "id": "mistral-7b-instruct-v0.1-awq",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mistral-7b-instruct-v0.1-awq",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.00014,
                "inputCacheHit": null,
                "output": 0.00042
            },
            "description": "The Mistral-7B-Instruct-v0.2 Large Language Model (LLM) is an instruct fine-tuned version of the Mistral-7B-v0.2. Mistral-7B-v0.2 has the following changes compared to Mistral-7B-v0.1: 32k context window (vs 8k context in v0.1), rope-theta = 1e6, and no Sliding-Window Attention.",
            "id": "mistral-7b-instruct-v0.2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 3072000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mistral-7b-instruct-v0.2",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.00014,
                "inputCacheHit": null,
                "output": 0.00042
            },
            "description": "The Mistral-7B-Instruct-v0.2 Large Language Model (LLM) is an instruct fine-tuned version of the Mistral-7B-v0.2.",
            "id": "mistral-7b-instruct-v0.2-lora",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 15000000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mistral-7b-instruct-v0.2-lora",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.00014,
                "inputCacheHit": null,
                "output": 0.00042
            },
            "description": "Building upon Mistral Small 3 (2501), Mistral Small 3.1 (2503) adds state-of-the-art vision understanding and enhances long context capabilities up to 128k tokens without compromising text performance. With 24 billion parameters, this model achieves top-tier capabilities in both text and vision tasks.",
            "id": "mistral-small-3.1-24b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "mistral-small-3.1-24b-instruct",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": true,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "This model is a fine-tuned 7B parameter LLM on the Intel Gaudi 2 processor from the mistralai/Mistral-7B-v0.1 on the open source dataset Open-Orca/SlimOrca.",
            "id": "neural-chat-7b-v3-1-awq",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "neural-chat-7b-v3-1-awq",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": true,
            "cost": {
                "input": 5.2e-9,
                "inputCacheHit": null,
                "output": 9.2e-9
            },
            "description": "Transcribe audio using Deepgrams speech-to-text model",
            "id": "nova-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["audio"],
                "output": ["text"]
            },
            "name": "nova-3",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "OpenChat is an innovative library of open-source language models, fine-tuned with C-RLFT - a strategy inspired by offline reinforcement learning.",
            "id": "openchat-3.5-0106",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "openchat-3.5-0106",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "description": "OpenHermes 2.5 Mistral 7B is a state of the art Mistral Fine-tune, a continuation of OpenHermes 2 model, which trained on additional code datasets.",
            "id": "openhermes-2.5-mistral-7b-awq",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "openhermes-2.5-mistral-7b-awq",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.0001,
                "inputCacheHit": null,
                "output": 0.0001
            },
            "description": "Phi-2 is a Transformer-based model with a next-word prediction objective, trained on 1.4T tokens from multiple passes on a mixture of Synthetic and Web datasets for NLP and coding.",
            "id": "phi-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2048000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "phi-2",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Phoenix 1.0 is a model by Leonardo.Ai that generates images with exceptional prompt adherence and coherent text.",
            "id": "phoenix-1.0",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "phoenix-1.0",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": true,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "PLaMo-Embedding-1B is a Japanese text embedding model developed by Preferred Networks, Inc.\n\nIt can convert Japanese text input into numerical vectors and can be used for a wide range of applications, including information retrieval, text classification, and clustering.",
            "id": "plamo-embedding-1b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "plamo-embedding-1b",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.0001,
                "inputCacheHit": null,
                "output": 0.0001
            },
            "description": "Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud.",
            "id": "qwen1.5-0.5b-chat",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32000000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen1.5-0.5b-chat",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud. AWQ is an efficient, accurate and blazing-fast low-bit weight quantization method, currently supporting 4-bit quantization.",
            "id": "qwen1.5-14b-chat-awq",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 7500000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen1.5-14b-chat-awq",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.0001,
                "inputCacheHit": null,
                "output": 0.0001
            },
            "description": "Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud.",
            "id": "qwen1.5-1.8b-chat",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32000000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen1.5-1.8b-chat",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Qwen1.5 is the improved version of Qwen, the large language model series developed by Alibaba Cloud. AWQ is an efficient, accurate and blazing-fast low-bit weight quantization method, currently supporting 4-bit quantization.",
            "id": "qwen1.5-7b-chat-awq",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 20000000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen1.5-7b-chat-awq",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.0008,
                "inputCacheHit": null,
                "output": 0.0008
            },
            "description": "Qwen2.5-Coder is the latest series of Code-Specific Qwen large language models (formerly known as CodeQwen). As of now, Qwen2.5-Coder has covered six mainstream model sizes, 0.5, 1.5, 3, 7, 14, 32 billion parameters, to meet the needs of different developers. Qwen2.5-Coder brings the following improvements upon CodeQwen1.5:",
            "extendedThinking": false,
            "id": "qwen2.5-coder-32b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768000,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen2.5-coder-32b-instruct",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": "2024-11-11",
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. Built upon extensive training, Qwen3 delivers groundbreaking advancements in reasoning, instruction-following, agent capabilities, and multilingual support.",
            "id": "qwen3-30b-a3b-fp8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen3-30b-a3b-fp8",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "The Qwen3 Embedding model series is the latest proprietary model of the Qwen family, specifically designed for text embedding and ranking tasks.",
            "id": "qwen3-embedding-0.6b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["embedding"]
            },
            "name": "qwen3-embedding-0.6b",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwq-32b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "QWQ 32B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks",
            "audioGeneration": false,
            "description": "QwQ is the reasoning model of the Qwen series. Compared with conventional instruction-tuned models, QwQ, which is capable of thinking and reasoning, can achieve significantly enhanced performance in downstream tasks, especially hard problems. QwQ-32B is the medium-sized reasoning model, which is capable of achieving competitive performance against state-of-the-art reasoning models, e.g., DeepSeek-R1, o1-mini.",
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "50 layers deep image classification CNN trained on more than 1M images from ImageNet",
            "id": "resnet-50",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "resnet-50",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": true,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "An open source, community-driven, native audio turn detection model in 2nd version",
            "id": "smart-turn-v2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["audio"]
            },
            "name": "smart-turn-v2",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "This model is intended to be used by non-technical users to understand data inside their SQL databases.",
            "id": "sqlcoder-7b-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 10000000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "sqlcoder-7b-2",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images. Img2img generate a new image from an input image with Stable Diffusion.",
            "id": "stable-diffusion-v1-5-img2img",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "stable-diffusion-v1-5-img2img",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": true,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Stable Diffusion Inpainting is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input, with the extra capability of inpainting the pictures by using a mask.",
            "id": "stable-diffusion-v1-5-inpainting",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "stable-diffusion-v1-5-inpainting",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": true,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Diffusion-based text-to-image generative model by Stability AI. Generates and modify images based on text prompts.",
            "id": "stable-diffusion-xl-base-1.0",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "stable-diffusion-xl-base-1.0",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": true,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "SDXL-Lightning is a lightning-fast text-to-image generation model. It can generate high-quality 1024px images in a few steps.",
            "id": "stable-diffusion-xl-lightning",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "stable-diffusion-xl-lightning",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": true,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "We introduce Starling-LM-7B-beta, an open large language model (LLM) trained by Reinforcement Learning from AI Feedback (RLAIF). Starling-LM-7B-beta is trained from Openchat-3.5-0106 with our new reward model Nexusflow/Starling-RM-34B and policy optimization method Fine-Tuning Language Models from Human Preferences (PPO).",
            "id": "starling-lm-7b-beta",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "starling-lm-7b-beta",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "description": "The TinyLlama project aims to pretrain a 1.1B Llama model on 3 trillion tokens. This is the chat model finetuned on top of TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T.",
            "id": "tinyllama-1.1b-chat-v1.0",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2048000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "tinyllama-1.1b-chat-v1.0",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "UForm-Gen is a small generative vision-language model primarily designed for Image Captioning and Visual Question Answering. The model was pre-trained on the internal image captioning dataset and fine-tuned on public instructions datasets: SVIT, LVIS, VQAs datasets.",
            "id": "uform-gen2-qwen-500m",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "uform-gen2-qwen-500m",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": true,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Cybertron 7B v2 is a 7B MistralAI based model, best on it's series. It was trained with SFT, DPO and UNA (Unified Neural Alignment) on multiple datasets.",
            "id": "una-cybertron-7b-v2-bf16",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 15000000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "una-cybertron-7b-v2-bf16",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "whisper",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "audio"],
                "output": ["text", "audio"]
            },
            "name": "Whisper",
            "openWeights": false,
            "preview": false,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq",
            "audioGeneration": true,
            "description": "Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multitasking model that can perform multilingual speech recognition, speech translation, and language identification.",
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true
        },
        {
            "attachment": false,
            "audioGeneration": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation.",
            "id": "whisper-large-v3-turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["audio"],
                "output": ["text"]
            },
            "name": "whisper-large-v3-turbo",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalize to many datasets and domains without the need for fine-tuning. This is the English-only version of the Whisper Tiny model which was trained on the task of speech recognition.",
            "id": "whisper-tiny-en",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["audio"],
                "output": ["text"]
            },
            "name": "whisper-tiny-en",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "audioGeneration": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Zephyr 7B Beta AWQ is an efficient, accurate and blazing-fast low-bit weight quantized Zephyr model variant.",
            "id": "zephyr-7b-beta-awq",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "zephyr-7b-beta-awq",
            "openWeights": false,
            "provider": "Cloudflare",
            "providerDoc": "https://developers.cloudflare.com/workers-ai/models",
            "providerEnv": ["CLOUDFLARE_API_TOKEN"],
            "providerId": "cloudflare",
            "providerNpm": "@ai-sdk/cloudflare",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "structuredOutputs": true,
            "supportsStructuredOutput": true,
            "supportsTools": true,
            "temperature": true,
            "toolCall": true,
            "version": null,
            "vision": false,
            "icon": "cloudflare"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000009,
                "inputCacheHit": null,
                "output": 0.000019
            },
            "extendedThinking": false,
            "id": "allenai/olmOCR-2-7B-1025",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "olmOCR-2-7B-1025",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00003,
                "inputCacheHit": null,
                "output": 0.00018
            },
            "extendedThinking": false,
            "id": "allenai/olmOCR-7B-0725-FP8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "olmOCR-7B-0725-FP8",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00165,
                "inputCacheHit": null,
                "output": 0.00825
            },
            "extendedThinking": false,
            "id": "anthropic/claude-4-opus",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "claude-4-opus",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00033,
                "inputCacheHit": null,
                "output": 0.00165
            },
            "extendedThinking": false,
            "id": "anthropic/claude-4-sonnet",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "claude-4-sonnet",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": null,
                "output": 0.00001
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-OCR",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-OCR",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0001,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-R1-0528-Turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-0528-Turbo",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0001,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-V3-0324-Turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3-0324-Turbo",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000021,
                "inputCacheHit": null,
                "output": 0.000079
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-V3.1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.1",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000021,
                "inputCacheHit": null,
                "output": 0.000079
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-V3.1-Terminus",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.1-Terminus",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000026,
                "inputCacheHit": null,
                "output": 0.000039
            },
            "extendedThinking": false,
            "id": "deepseek-ai/DeepSeek-V3.2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.2",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-2.5-flash",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["file", "image", "text", "audio", "video"],
                "output": ["text"]
            },
            "name": "Google: Gemini 2.5 Flash",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-06-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-2.5-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image", "file", "audio", "video"],
                "output": ["text"]
            },
            "name": "Google: Gemini 2.5 Pro",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-06-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemma-3-12b-it",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Google: Gemma 3 12B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemma-3-27b-it",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 96000,
                "output": 96000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Google: Gemma 3 27B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemma-3-4b-it",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 96000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Google: Gemma 3 4B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000023,
                "inputCacheHit": null,
                "output": 0.00004
            },
            "extendedThinking": false,
            "id": "meta-llama/Llama-3.3-70B-Instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama-3.3-70B-Instruct",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00001,
                "inputCacheHit": null,
                "output": 0.000032
            },
            "extendedThinking": false,
            "id": "meta-llama/Llama-3.3-70B-Instruct-Turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama-3.3-70B-Instruct-Turbo",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000015,
                "inputCacheHit": null,
                "output": 0.00006
            },
            "extendedThinking": false,
            "id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama-4-Maverick-17B-128E-Instruct-FP8",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00005,
                "inputCacheHit": null,
                "output": 0.00005
            },
            "extendedThinking": false,
            "id": "meta-llama/Llama-4-Maverick-17B-128E-Instruct-Turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama-4-Maverick-17B-128E-Instruct-Turbo",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000008,
                "inputCacheHit": null,
                "output": 0.00003
            },
            "extendedThinking": false,
            "id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 327680,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama-4-Scout-17B-16E-Instruct",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000018,
                "inputCacheHit": null,
                "output": 0.000018
            },
            "extendedThinking": false,
            "id": "meta-llama/Llama-Guard-4-12B",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama-Guard-4-12B",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "microsoft/phi-4",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Microsoft: Phi 4",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-01-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000254,
                "inputCacheHit": null,
                "output": 0.000102
            },
            "extendedThinking": false,
            "id": "MiniMaxAI/MiniMax-M2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniMax-M2",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000007,
                "inputCacheHit": null,
                "output": 0.000028
            },
            "extendedThinking": false,
            "id": "mistralai/Devstral-Small-2507",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Devstral-Small-2507",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000075,
                "inputCacheHit": null,
                "output": 0.00002
            },
            "extendedThinking": false,
            "id": "mistralai/Mistral-Small-3.2-24B-Instruct-2506",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral-Small-3.2-24B-Instruct-2506",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000047,
                "inputCacheHit": null,
                "output": 0.0002
            },
            "extendedThinking": false,
            "id": "moonshotai/Kimi-K2-Thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kimi-K2-Thinking",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000006,
                "inputCacheHit": null,
                "output": 0.000024
            },
            "extendedThinking": false,
            "id": "nvidia/Nemotron-3-Nano-30B-A3B",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nemotron-3-Nano-30B-A3B",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000014,
                "inputCacheHit": null,
                "output": 0.00008
            },
            "extendedThinking": false,
            "id": "PaddlePaddle/PaddleOCR-VL-0.9B",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "PaddleOCR-VL-0.9B",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000075,
                "inputCacheHit": null,
                "output": 0.000015
            },
            "extendedThinking": false,
            "id": "Qwen/QwQ-32B",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "QwQ-32B",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00004,
                "inputCacheHit": null,
                "output": 0.00016
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Coder-480B-A35B-Instruct",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000028,
                "inputCacheHit": null,
                "output": 0.00012
            },
            "extendedThinking": false,
            "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct-Turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Coder-480B-A35B-Instruct-Turbo",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000055,
                "inputCacheHit": null,
                "output": 0.0002
            },
            "extendedThinking": false,
            "id": "zai-org/GLM-4.5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.5",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00005,
                "inputCacheHit": null,
                "output": 0.00017
            },
            "extendedThinking": false,
            "id": "zai-org/GLM-4.5V",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.5V",
            "openWeights": false,
            "provider": "Deep Infra",
            "providerDoc": "https://deepinfra.com/docs",
            "providerEnv": [],
            "providerId": "deep-infra",
            "providerModelsDevId": "deepinfra",
            "providerNpm": "@deepinfra/sdk",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "deepinfra"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0004,
                "inputCacheHit": null,
                "output": 0.00175
            },
            "extendedThinking": false,
            "id": "deep-seek-r1-0528",
            "knowledge": null,
            "lastUpdated": "2025-05-29",
            "limit": {
                "context": 163840,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-0528",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-v3-0324",
            "knowledge": null,
            "lastUpdated": "2025-03-25",
            "limit": {
                "context": null,
                "output": 8000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3-0324",
            "openWeights": false,
            "provider": "DeepSeek",
            "providerDoc": "https://api-docs.deepseek.com/quick_start/pricing",
            "providerEnv": ["DEEPSEEK_API_KEY"],
            "providerId": "deep-seek",
            "providerModelsDevId": "deepseek",
            "providerNpm": "@ai-sdk/deepseek",
            "reasoning": false,
            "releaseDate": "2024-03-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "deepseek"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/chronos-hermes-13b-v2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Chronos Hermes 13B v2",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/code-llama-13b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 13B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/code-llama-13b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 13B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/code-llama-13b-python",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 13B Python",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/code-llama-34b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 34B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/code-llama-34b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 34B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/code-llama-34b-python",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 34B Python",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/code-llama-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 70B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/code-llama-70b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 70B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/code-llama-70b-python",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 70B Python",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/code-llama-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/code-llama-7b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 7B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/code-llama-7b-python",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 7B Python",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/code-qwen-1p5-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "CodeQwen 1.5 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/codegemma-2b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "CodeGemma 2B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/codegemma-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "CodeGemma 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/cogito-v1-preview-llama-3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cogito v1 Preview Llama 3B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/cogito-v1-preview-llama-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cogito v1 Preview Llama 70B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/cogito-v1-preview-llama-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cogito v1 Preview Llama 8B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/cogito-v1-preview-qwen-14b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cogito v1 Preview Qwen 14B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/cogito-v1-preview-qwen-32b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cogito v1 Preview Qwen 32B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.2,
                "inputCacheHit": null,
                "output": 1.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/dbrx-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DBRX Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-coder-1b-base",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek Coder 1.3B Base",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-coder-33b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek Coder 33B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-coder-7b-base",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek Coder 7B Base",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-coder-7b-base-v1p5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek Coder 7B Base v1.5",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-coder-7b-instruct-v1p5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek Coder 7B Instruct v1.5",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.2,
                "inputCacheHit": null,
                "output": 1.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-coder-v2-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek Coder V2 Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.5,
                "inputCacheHit": null,
                "output": 0.5
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-coder-v2-lite-base",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek Coder V2 Lite Base",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.5,
                "inputCacheHit": null,
                "output": 0.5
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-coder-v2-lite-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek Coder V2 Lite Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.2,
                "inputCacheHit": null,
                "output": 1.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-prover-v2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek Prover V2",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.35,
                "inputCacheHit": null,
                "output": 5.4
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-r1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek R1 (Fast)",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.35,
                "inputCacheHit": null,
                "output": 5.4
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-r1-0528",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Deepseek R1 05/28",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": "2025-05-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-r1-0528-distill-qwen3-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek R1 0528 Distill Qwen3 8B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.55,
                "inputCacheHit": null,
                "output": 2.19
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-r1-basic",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek R1 (Basic)",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-r1-distill-llama-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek R1 Distill Llama 70B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": "2025-01-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-r1-distill-llama-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 32000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek R1 Distill Llama 8B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": "2025-02-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-r1-distill-qwen-14b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek R1 Distill Qwen 14B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": "2025-01-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-r1-distill-qwen-1p5b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek R1 Distill Qwen 1.5B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": "2025-01-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-r1-distill-qwen-32b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek R1 Distill Qwen 32B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": "2025-01-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-r1-distill-qwen-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek R1 Distill Qwen 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.5,
                "inputCacheHit": null,
                "output": 0.5
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-v2-lite-chat",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek V2 Lite Chat",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.2,
                "inputCacheHit": null,
                "output": 1.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-v2p5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek V2.5",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-v3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek V3",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-v3-0324",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Deepseek V3 03-24",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.56,
                "inputCacheHit": null,
                "output": 1.68
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-v3p1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek V3.1",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.56,
                "inputCacheHit": null,
                "output": 1.68
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/deepseek-v3p2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Deepseek v3.2",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/devstral-small-2505",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Devstral-Small-2505",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/devstral-small-2-24b-instruct-2512",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Devstral Small 2 24B Instruct 2512",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/dolphin-2-9-2-qwen2-72b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Dolphin 2.9.2 Qwen2 72B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.5,
                "inputCacheHit": null,
                "output": 0.5
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/dolphin-2p6-mixtral-8x7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Dolphin 2.6 Mixtral 8x7b",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/ernie-4p5-21b-a3b-pt",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ERNIE-4.5-21B-A3B-PT",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/ernie-4p5-300b-a47b-pt",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ERNIE-4.5-300B-A47B-PT",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/fare-20b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FARE-20B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.5,
                "inputCacheHit": null,
                "output": 0.5
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/firefunction-v1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FireFunction V1",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/firefunction-v2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FireFunction V2",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/firellava-13b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "FireLLaVA 13B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/firesearch-ocr-v6",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Firesearch OCR V6",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0,
                "inputCacheHit": null,
                "output": 0
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/fireworks-asr-large",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Streaming ASR v1",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0,
                "inputCacheHit": null,
                "output": 0
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/fireworks-asr-v2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Streaming ASR v2",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.001,
                "inputCacheHit": null,
                "output": 0.001
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/flux-1-dev-controlnet-union",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FLUX.1 [dev] ControlNet",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0005,
                "inputCacheHit": null,
                "output": 0.0005
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/flux-1-dev-fp8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "FLUX.1 [dev] FP8",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/flux-1-schnell",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FLUX.1 [schnell]",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00035,
                "inputCacheHit": null,
                "output": 0.00035
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/flux-1-schnell-fp8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "FLUX.1 [schnell] FP8",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.08,
                "inputCacheHit": null,
                "output": 0.08
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/flux-kontext-max",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "FLUX.1 Kontext Max",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.04,
                "inputCacheHit": null,
                "output": 0.04
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/flux-kontext-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "FLUX.1 Kontext Pro",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/gemma2-9b-it",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemma 2 9B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/gemma-2b-it",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemma 2B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/gemma-3-12b-it",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemma 3 12B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/gemma-3-27b-it",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemma 3 27B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/gemma-3-4b-it",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemma 3 4B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/gemma-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemma 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/gemma-7b-it",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemma 7B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.55,
                "inputCacheHit": null,
                "output": 2.19
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/glm-4p5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.5",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.22,
                "inputCacheHit": null,
                "output": 0.88
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/glm-4p5-air",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.5-Air",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.2,
                "inputCacheHit": null,
                "output": 1.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/glm-4p5v",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "GLM-4.5V",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.55,
                "inputCacheHit": null,
                "output": 2.19
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/glm-4p6",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 202752,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.6",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.6,
                "inputCacheHit": null,
                "output": 2.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/glm-4p7",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 202752,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.7",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.15,
                "inputCacheHit": null,
                "output": 0.6
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/gpt-oss-120b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI gpt-oss-120b",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.07,
                "inputCacheHit": null,
                "output": 0.3
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/gpt-oss-20b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI gpt-oss-20b",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.2,
                "inputCacheHit": null,
                "output": 1.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/gpt-oss-safeguard-120b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI gpt-oss-safeguard-120b",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.5,
                "inputCacheHit": null,
                "output": 0.5
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/gpt-oss-safeguard-20b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI gpt-oss-safeguard-20b",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": "2025-10-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/hermes-2-pro-mistral-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Hermes 2 Pro Mistral 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/internvl3-38b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "InternVL3 38B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/internvl3-78b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "InternVL3 78B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/internvl3-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "InternVL3 8B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00013,
                "inputCacheHit": null,
                "output": 0.00013
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/japanese-stable-diffusion-xl",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Japanese Stable Diffusion XL",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/kat-coder",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "KAT Coder",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/kat-dev-32b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "KAT Dev 32B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/kat-dev-72b-exp",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "KAT Dev 72B Exp",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.6,
                "inputCacheHit": null,
                "output": 2.5
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/kimi-k2-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kimi K2 Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.6,
                "inputCacheHit": null,
                "output": 2.5
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/kimi-k2-instruct-0905",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kimi K2 Instruct 0905",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.6,
                "inputCacheHit": null,
                "output": 2.5
            },
            "extendedThinking": true,
            "id": "accounts/fireworks/models/kimi-k2-thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kimi K2 Thinking",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.22,
                "inputCacheHit": null,
                "output": 0.88
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama4-maverick-instruct-basic",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Llama 4 Maverick Instruct (Basic)",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.15,
                "inputCacheHit": null,
                "output": 0.6
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama4-scout-instruct-basic",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Llama 4 Scout Instruct (Basic)",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-guard-2-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama Guard v2 8B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-guard-3-1b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama Guard v3 1B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-guard-3-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama Guard 3 8B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": "2025-02-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v2-13b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 2 13B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v2-13b-chat",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 2 13B Chat",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v2-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 2 70B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v2-70b-chat",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2048,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 2 70B Chat",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v2-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 2 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v2-7b-chat",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 2 7B Chat",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v3-70b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3 70B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v3-70b-instruct-hf",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3 70B Instruct (HF version)",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v3-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3 8B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v3-8b-instruct-hf",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3 8B Instruct (HF version)",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3,
                "inputCacheHit": null,
                "output": 3
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v3p1-405b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.1 405B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v3p1-405b-instruct-long",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.1 405B Instruct Long",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v3p1-70b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.1 70B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v3p1-70b-instruct-1b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.1 70B Instruct 1B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v3p1-8b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.1 8B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v3p1-nemotron-70b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.1 Nemotron 70B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v3p2-11b-vision-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Llama 3.2 11B Vision Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v3p2-1b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.2 1B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v3p2-1b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.2 1B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v3p2-3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.2 3B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v3p2-3b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.2 3B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v3p2-90b-vision-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Llama 3.2 90B Vision Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llama-v3p3-70b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.3 70B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llamaguard-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama Guard 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/llava-yi-34b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "LLaVA V1.6 Yi 34B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/minimax-m1-80k",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniMax-M1-80k",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.3,
                "inputCacheHit": null,
                "output": 1.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/minimax-m2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 196608,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniMax-M2",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.3,
                "inputCacheHit": null,
                "output": 1.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/minimax-m2p1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 204800,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniMax-M2.1",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/ministral-3-14b-instruct-2512",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Ministral 3 14B Instruct 2512",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/ministral-3-3b-instruct-2512",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Ministral 3 3B Instruct 2512",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/ministral-3-8b-instruct-2512",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Ministral 3 8B Instruct 2512",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/mistral-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/mistral-7b-instruct-4k",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistal 7B Instruct V0.1",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/mistral-7b-instruct-v0p2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral 7B Instruct v0.2",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/mistral-7b-instruct-v3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral 7B Instruct v0.3",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/mistral-7b-v0p2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral 7B v0.2",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.2,
                "inputCacheHit": null,
                "output": 1.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/mistral-large-3-fp8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Mistral Large 3 675B Instruct 2512",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/mistral-nemo-base-2407",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Nemo Base 2407",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/mistral-nemo-instruct-2407",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Nemo Instruct 2407",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/mistral-small-24b-instruct-2501",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Small 24B Instruct 2501",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.2,
                "inputCacheHit": null,
                "output": 1.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/mixtral-8x22b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mixtral Moe 8x22B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.2,
                "inputCacheHit": null,
                "output": 1.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/mixtral-8x22b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mixtral MoE 8x22B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.5,
                "inputCacheHit": null,
                "output": 0.5
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/mixtral-8x7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mixtral 8x7B v0.1",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.5,
                "inputCacheHit": null,
                "output": 0.5
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/mixtral-8x7b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mixtral MoE 8x7B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.5,
                "inputCacheHit": null,
                "output": 0.5
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/mixtral-8x7b-instruct-hf",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mixtral MoE 8x7B Instruct (HF version)",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/mythomax-l2-13b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MythoMax L2 13B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/nemotron-nano-3-30b-a3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "NVIDIA Nemotron Nano 3 30B A3B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/nemotron-nano-v2-12b-vl",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "NVIDIA Nemotron Nano 2 VL",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/nous-capybara-7b-v1p9",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nous Capybara 7B V1.9",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.5,
                "inputCacheHit": null,
                "output": 0.5
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/nous-hermes-2-mixtral-8x7b-dpo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nouse Hermes 2 Mixtral 8x7B DPO",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/nous-hermes-2-yi-34b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nous Hermes 2 Yi 34B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/nous-hermes-llama2-13b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nous Hermes Llama2 13B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/nous-hermes-llama2-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nous Hermes Llama2 70B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/nous-hermes-llama2-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nous Hermes Llama2 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/nvidia-nemotron-nano-12b-v2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "NVIDIA Nemotron Nano 12B v2",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/nvidia-nemotron-nano-9b-v2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "NVIDIA Nemotron Nano 9B v2",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": "2025-09-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/openchat-3p5-0106-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenChat 3.5 0106",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/openhermes-2-mistral-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenHermes 2 Mistral 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/openhermes-2p5-mistral-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenHermes 2.5 Mistral 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/openorca-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral 7B OpenOrca",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/phi-2-3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2048,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Phi-2 3B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/phi-3-mini-128k-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Phi-3 Mini 128k Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/phi-3-vision-128k-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32064,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Phi-3.5 Vision Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/phind-code-llama-34b-python-v1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Phind CodeLlama 34B Python v1",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/phind-code-llama-34b-v1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Phind CodeLlama 34B v1",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/phind-code-llama-34b-v2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Phind CodeLlama 34B v2",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00013,
                "inputCacheHit": null,
                "output": 0.00013
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/playground-v2-1024px-aesthetic",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Playground v2 1024",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00013,
                "inputCacheHit": null,
                "output": 0.00013
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/playground-v2-5-1024px-aesthetic",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Playground v2.5 1024",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/pythia-12b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2048,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Pythia 12B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen1p5-72b-chat",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen1.5 72B Chat",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2-72b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2 72B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": "2024-06-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2-7b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2 7B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-0p5b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5 0.5B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-14b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5 14B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-1p5b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5 1.5B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-32b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5 32B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-32b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5 32B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-72b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5 72B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-72b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5 72B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": "2024-09-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-7b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5 7B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-coder-0p5b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 0.5B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-coder-0p5b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 0.5B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-coder-14b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 14B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-coder-14b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 14B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-coder-1p5b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 1.5B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-coder-1p5b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 1.5B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-coder-32b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 32B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-coder-32b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 32B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": "2024-11-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-coder-32b-instruct-128k",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 32B Instruct 128K",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-coder-32b-instruct-32k-rope",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 32B Instruct 32K RoPE",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-coder-32b-instruct-64k",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 32B Instruct 64k",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-coder-3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 3B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-coder-3b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 3B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-coder-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-coder-7b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 7B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-math-72b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Math 72B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-vl-32b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2.5-VL 32B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-vl-3b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2.5-VL 3B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-vl-72b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2.5-VL 72B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2p5-vl-7b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2.5-VL 7B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2-vl-2b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2-VL 2B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2-vl-72b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2-VL 72B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen2-vl-7b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2-VL 7B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-0p6b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 0.6B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-14b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 14B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-1p7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 1.7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-1p7b-fp8-draft",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 1.7B fp8 model used for drafting",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-1p7b-fp8-draft-131072",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 1.7B fp8 model used for drafting for 131072 context",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-1p7b-fp8-draft-40960",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 1.7B fp8 model used for drafting for 40960 context length",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.22,
                "inputCacheHit": null,
                "output": 0.88
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-235b-a22b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 235B A22B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.22,
                "inputCacheHit": null,
                "output": 0.88
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-235b-a22b-instruct-2507",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 235B A22B Instruct 2507",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.15,
                "inputCacheHit": null,
                "output": 0.6
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-30b-a3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 30B-A3B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.5,
                "inputCacheHit": null,
                "output": 0.5
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-30b-a3b-instruct-2507",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 30B A3B Instruct 2507",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": true,
            "id": "accounts/fireworks/models/qwen3-30b-a3b-thinking-2507",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 30B A3B Thinking 2507",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-32b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 32B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-4b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 4B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-4b-instruct-2507",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen 3 4B Instruct 2507",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 8B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.15,
                "inputCacheHit": null,
                "output": 0.6
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-coder-30b-a3b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 Coder 30B A3B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.45,
                "inputCacheHit": null,
                "output": 1.8
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-coder-480b-a35b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 Coder 480B A35B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.2,
                "inputCacheHit": null,
                "output": 1.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-coder-480b-instruct-bf16",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 Coder 480B Instruct BF16",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0,
                "inputCacheHit": null,
                "output": 0
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-embedding-0p6b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 Embedding 0.6B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0,
                "inputCacheHit": null,
                "output": 0
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-embedding-4b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 Embedding 4B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0,
                "inputCacheHit": null,
                "output": 0
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-embedding-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 Embedding 8B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-next-80b-a3b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 Next 80B A3B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": true,
            "id": "accounts/fireworks/models/qwen3-next-80b-a3b-thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 Next 80B A3B Thinking",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.5,
                "inputCacheHit": null,
                "output": 0.5
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-omni-30b-a3b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3 Omni 30B A3B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0,
                "inputCacheHit": null,
                "output": 0
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-reranker-0p6b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 Reranker 0.6B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0,
                "inputCacheHit": null,
                "output": 0
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-reranker-4b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 Reranker 4B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0,
                "inputCacheHit": null,
                "output": 0
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-reranker-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 Reranker 8B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.22,
                "inputCacheHit": null,
                "output": 0.88
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-vl-235b-a22b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3 VL 235B A22B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.22,
                "inputCacheHit": null,
                "output": 0.88
            },
            "extendedThinking": true,
            "id": "accounts/fireworks/models/qwen3-vl-235b-a22b-thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3 VL 235B A22B Thinking",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.15,
                "inputCacheHit": null,
                "output": 0.6
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-vl-30b-a3b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3 VL 30B A3B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.15,
                "inputCacheHit": null,
                "output": 0.6
            },
            "extendedThinking": true,
            "id": "accounts/fireworks/models/qwen3-vl-30b-a3b-thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3 VL 30B A3B Thinking",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-vl-32b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3 VL 32B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen3-vl-8b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-8B-Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen-qwq-32b-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen QWQ 32B Preview",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": "2024-11-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen-v2p5-14b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5 14B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwen-v2p5-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/qwq-32b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "QWQ 32B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/rolm-ocr",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Rolm OCR",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/seed-oss-36b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 524288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Seed OSS 36B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/snorkel-mistral-7b-pairrm-dpo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Snorkel Mistral PairRM DPO",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00013,
                "inputCacheHit": null,
                "output": 0.00013
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/SSD-1B",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Segmind Stable Diffusion 1B (SSD-1B)",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00013,
                "inputCacheHit": null,
                "output": 0.00013
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/stable-diffusion-xl-1024-v1-0",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Stable Diffusion XL",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/stablecode-3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Stable Code 3B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/starcoder-16b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "StarCoder 16B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/starcoder2-15b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "StarCoder2 15B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.1,
                "inputCacheHit": null,
                "output": 0.1
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/starcoder2-3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "StarCoder2 3B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/starcoder2-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "StarCoder2 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/starcoder-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "StarCoder 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/toppy-m-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Toppy M 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0,
                "inputCacheHit": null,
                "output": 0
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/whisper-v3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Whisper V3 Large",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0,
                "inputCacheHit": null,
                "output": 0
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/whisper-v3-turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Whisper V3 Turbo",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.9,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/yi-34b-200k-capybara",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nouse Capybara 34B V1.9",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.2,
                "inputCacheHit": null,
                "output": 0.2
            },
            "extendedThinking": false,
            "id": "accounts/fireworks/models/zephyr-7b-beta",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Zephyr 7B Beta",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "chronos-hermes-13b-v-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Chronos Hermes 13B v2",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "code-gemma-2b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "CodeGemma 2B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "code-gemma-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "CodeGemma 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "code-llama-13b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 13B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "code-llama-13b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 13B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "code-llama-13b-python",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 13B Python",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "code-llama-34b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 34B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "code-llama-34b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 34B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "code-llama-34b-python",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 34B Python",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "code-llama-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 70B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "code-llama-70b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 70B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "code-llama-70b-python",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 70B Python",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "code-llama-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "code-llama-7b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 7B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "code-llama-7b-python",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Code Llama 7B Python",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "code-qwen-1-5-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "CodeQwen 1.5 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "cogito-v-1-preview-llama-3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cogito v1 Preview Llama 3B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "cogito-v-1-preview-llama-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cogito v1 Preview Llama 70B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "cogito-v-1-preview-llama-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cogito v1 Preview Llama 8B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cogito-v-1-preview-qwen-14b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cogito v1 Preview Qwen 14B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cogito-v-1-preview-qwen-32b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cogito v1 Preview Qwen 32B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "dbrx-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DBRX Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-coder-1-3b-base",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek Coder 1.3B Base",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-coder-33b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek Coder 33B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-coder-7b-base",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek Coder 7B Base",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-coder-7b-base-v-1-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek Coder 7B Base v1.5",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-coder-7b-instruct-v-1-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek Coder 7B Instruct v1.5",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-coder-v2-instruct",
            "knowledge": null,
            "lastUpdated": "2024-08-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-Coder-V2-Instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-06-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-coder-v2-lite-base",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek Coder V2 Lite Base",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-coder-v2-lite-instruct",
            "knowledge": null,
            "lastUpdated": "2024-12-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-Coder-V2-Lite-Instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-06-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-prover-v2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek Prover V2",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.55,
                "inputCacheHit": null,
                "output": 2.19
            },
            "extendedThinking": false,
            "id": "deep-seek-r1-(basic)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek R1 (Basic)",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3,
                "inputCacheHit": null,
                "output": 8
            },
            "extendedThinking": false,
            "id": "deep-seek-r1-(fast)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek R1 (Fast)",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-r1-0528-distill-qwen-3-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek R1 0528 Distill Qwen3 8B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00075,
                "inputCacheHit": null,
                "output": 0.00099
            },
            "extendedThinking": false,
            "id": "deep-seek-r1-distill-llama-70b",
            "knowledge": null,
            "lastUpdated": "2025-02-24",
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-Distill-Llama-70B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00004,
                "inputCacheHit": null,
                "output": 0.00004
            },
            "extendedThinking": false,
            "id": "deep-seek-r1-distill-llama-8b",
            "knowledge": null,
            "lastUpdated": "2025-02-24",
            "limit": {
                "context": 32000,
                "output": 32000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-Distill-Llama-8B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00015,
                "inputCacheHit": null,
                "output": 0.00015
            },
            "extendedThinking": false,
            "id": "deep-seek-r1-distill-qwen-14b",
            "knowledge": null,
            "lastUpdated": "2025-02-24",
            "limit": {
                "context": 32768,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-Distill-Qwen-14B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-r1-distill-qwen-1-5b",
            "knowledge": null,
            "lastUpdated": "2025-03-07",
            "limit": {
                "context": 131072,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-Distill-Qwen-1.5B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "deep-seek-r1-distill-qwen-32b",
            "knowledge": null,
            "lastUpdated": "2025-02-24",
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-Distill-Qwen-32B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-r1-distill-qwen-7b",
            "knowledge": null,
            "lastUpdated": "2025-02-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-Distill-Qwen-7B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-v2-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek V2.5",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-v2-lite-chat",
            "knowledge": null,
            "lastUpdated": "2024-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V2-Lite-Chat",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-05-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0009,
                "inputCacheHit": null,
                "output": 0.0009
            },
            "extendedThinking": false,
            "id": "deep-seek-v3",
            "knowledge": null,
            "lastUpdated": "2025-02-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-12-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3,
                "inputCacheHit": null,
                "output": 8
            },
            "extendedThinking": false,
            "id": "deepseek-r1-05-28",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Deepseek R1 05/28",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": "2025-05-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek-v3-03-24",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Deepseek V3 03-24",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00005,
                "inputCacheHit": null,
                "output": 0.00022
            },
            "extendedThinking": false,
            "id": "devstral-small-2505",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Devstral-Small-2505",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "dobby-mini-unhinged-plus-llama-3-1-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Dobby Mini Unhinged Plus Llama 3.1 8B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "dobby-unhinged-llama-3-3-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Dobby-Unhinged-Llama-3.3-70B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "dolphin-2-6-mixtral-8-x-7-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Dolphin 2.6 Mixtral 8x7b",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "dolphin-2-9-2-qwen-2-72b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Dolphin 2.9.2 Qwen2 72B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ernie-4-5-21b-a3b-pt",
            "knowledge": null,
            "lastUpdated": "2025-09-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ERNIE-4.5-21B-A3B-PT",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ernie-4-5-300b-a47b-pt",
            "knowledge": null,
            "lastUpdated": "2025-08-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ERNIE-4.5-300B-A47B-PT",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "fire-function-v1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FireFunction V1",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "fire-function-v2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FireFunction V2",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "fire-l-la-va-13b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "FireLLaVA 13B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "firesearch-ocr-v6",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Firesearch OCR V6",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-[dev]",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FLUX.1 [dev]",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-[dev]-control-net",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FLUX.1 [dev] ControlNet",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-[dev]-fp8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FLUX.1 [dev] FP8",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-[schnell]",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FLUX.1 [schnell]",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-[schnell]-fp8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FLUX.1 [schnell] FP8",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-kontext-max",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FLUX.1 Kontext Max",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-kontext-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FLUX.1 Kontext Pro",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemma-2-9b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemma 2 9B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemma-2b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemma 2B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemma-3-27b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemma 3 27B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemma-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemma 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemma-7b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemma 7B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0015
            },
            "extendedThinking": false,
            "id": "glm-4-5",
            "knowledge": null,
            "lastUpdated": "2025-08-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.5",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00013,
                "inputCacheHit": null,
                "output": 0.00085
            },
            "extendedThinking": false,
            "id": "glm-4-5-air",
            "knowledge": null,
            "lastUpdated": "2025-08-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.5-Air",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "intern-vl-3-38b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "InternVL3 38B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00007,
                "inputCacheHit": null,
                "output": 0.00026
            },
            "extendedThinking": false,
            "id": "intern-vl-3-78b",
            "knowledge": null,
            "lastUpdated": "2025-05-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "InternVL3-78B",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "intern-vl-3-8b",
            "knowledge": null,
            "lastUpdated": "2025-09-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "InternVL3-8B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "japanese-stable-diffusion-xl",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Japanese Stable Diffusion XL",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.001,
                "inputCacheHit": null,
                "output": 0.003
            },
            "extendedThinking": false,
            "id": "kimi-k2-instruct",
            "knowledge": null,
            "lastUpdated": "2025-11-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kimi-K2-Instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "l-la-va-v1-6-yi-34b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "LLaVA V1.6 Yi 34B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-2-13b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 2 13B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-2-13b-chat",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 2 13B Chat",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-2-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 2 70B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-2-70b-chat",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2048,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 2 70B Chat",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-2-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 2 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-2-7b-chat",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 2 7B Chat",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-3-1-405b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.1 405B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-3-1-405b-instruct-long",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.1 405B Instruct Long",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-3-1-70b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.1 70B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-3-1-70b-instruct-1b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.1 70B Instruct 1B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-3-1-8b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.1 8B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-3-1-nemotron-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.1 Nemotron 70B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-3-2-11b-vision-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Llama 3.2 11B Vision Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00002,
                "inputCacheHit": null,
                "output": 0.00002
            },
            "extendedThinking": false,
            "id": "llama-3-2-1b",
            "knowledge": null,
            "lastUpdated": "2024-10-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama-3.2-1B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00002,
                "inputCacheHit": null,
                "output": 0.00002
            },
            "extendedThinking": false,
            "id": "llama-3-2-1b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama-3.2-1B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00003,
                "inputCacheHit": null,
                "output": 0.00005
            },
            "extendedThinking": false,
            "id": "llama-3-2-3b",
            "knowledge": null,
            "lastUpdated": "2024-10-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama-3.2-3B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00003,
                "inputCacheHit": null,
                "output": 0.00005
            },
            "extendedThinking": false,
            "id": "llama-3-2-3b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama-3.2-3B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-3-2-90b-vision-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Llama 3.2 90B Vision Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00045,
                "inputCacheHit": null,
                "output": 0.00045
            },
            "extendedThinking": false,
            "id": "llama-3-3-70b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama-3.3-70B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-12-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-3-70b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3 70B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-3-70b-instruct-(hf-version)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3 70B Instruct (HF version)",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-3-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3 8B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-3-8b-instruct-(hf-version)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3 8B Instruct (HF version)",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.22,
                "inputCacheHit": null,
                "output": 0.88
            },
            "extendedThinking": false,
            "id": "llama-4-maverick-instruct-(basic)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Llama 4 Maverick Instruct (Basic)",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.15,
                "inputCacheHit": null,
                "output": 0.6
            },
            "extendedThinking": false,
            "id": "llama-4-scout-instruct-(basic)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Llama 4 Scout Instruct (Basic)",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-guard-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama Guard 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-guard-v-2-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama Guard v2 8B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-guard-v-3-1b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama Guard v3 1B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mini-max-m1-80-k",
            "knowledge": null,
            "lastUpdated": "2025-07-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniMax-M1-80k",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mistal-7b-instruct-v0-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistal 7B Instruct V0.1",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-7b-instruct-v-0-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral 7B Instruct v0.2",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00014,
                "inputCacheHit": null,
                "output": 0.00042
            },
            "extendedThinking": false,
            "id": "mistral-7b-instruct-v-0-3",
            "knowledge": null,
            "lastUpdated": "2024-09-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral-7B-Instruct-v0.3",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-06-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-7b-open-orca",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral 7B OpenOrca",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-7b-v-0-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral 7B v0.2",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-nemo-base-2407",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Nemo Base 2407",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-nemo-instruct-2407",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Nemo Instruct 2407",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-small-24b-instruct-2501",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Small 24B Instruct 2501",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mixtral-8-x-7-b-v-0-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mixtral 8x7B v0.1",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mixtral-mo-e-8-x-22-b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mixtral MoE 8x22B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mixtral-mo-e-8-x-7-b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mixtral MoE 8x7B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mixtral-mo-e-8-x-7-b-instruct-(hf-version)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mixtral MoE 8x7B Instruct (HF version)",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mixtral-moe-8-x-22-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mixtral Moe 8x22B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mytho-max-l2-13b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MythoMax L2 13B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nous-capybara-7b-v1-9",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nous Capybara 7B V1.9",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nous-hermes-2-yi-34b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nous Hermes 2 Yi 34B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "nous-hermes-llama-2-13b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nous Hermes Llama2 13B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "nous-hermes-llama-2-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nous Hermes Llama2 70B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "nous-hermes-llama-2-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nous Hermes Llama2 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nouse-capybara-34b-v1-9",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 199680,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nouse Capybara 34B V1.9",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nouse-hermes-2-mixtral-8-x-7-b-dpo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nouse Hermes 2 Mixtral 8x7B DPO",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "open-chat-3-5-0106",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenChat 3.5 0106",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "open-hermes-2-5-mistral-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenHermes 2.5 Mistral 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "open-hermes-2-mistral-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenHermes 2 Mistral 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "phi-2-3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2048,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Phi-2 3B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "phi-3-5-vision-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 31744,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Phi-3.5 Vision Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "phi-3-mini-128-k-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Phi-3 Mini 128k Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "phind-code-llama-34b-python-v-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Phind CodeLlama 34B Python v1",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "phind-code-llama-34b-v-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Phind CodeLlama 34B v1",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "phind-code-llama-34b-v-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Phind CodeLlama 34B v2",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "playground-v-2-1024",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Playground v2 1024",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "playground-v-2-5-1024",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Playground v2.5 1024",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "pythia-12b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2048,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Pythia 12B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-1-5-72b-chat",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen1.5 72B Chat",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-0-5b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-0.5B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-14b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5 14B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-14b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-03-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-14B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-1-5b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-1.5B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-32b",
            "knowledge": null,
            "lastUpdated": "2024-09-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-32B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-32b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-03-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-32B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-72b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5 72B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0012,
                "inputCacheHit": null,
                "output": 0.0012
            },
            "extendedThinking": false,
            "id": "qwen-2-5-72b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-03-07",
            "limit": {
                "context": 32768,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-72B-Instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "qwen-2-5-7b",
            "knowledge": null,
            "lastUpdated": "2024-09-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-7B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "qwen-2-5-7b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-03-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-7B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-coder-0-5b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 0.5B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-coder-0-5b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 0.5B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-coder-14b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 14B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-coder-14b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-03-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder-14B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-11-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-coder-1-5b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 1.5B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-coder-1-5b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder-1.5B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-coder-32b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 32B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0008,
                "inputCacheHit": null,
                "output": 0.0008
            },
            "extendedThinking": false,
            "id": "qwen-2-5-coder-32b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-03-07",
            "limit": {
                "context": 32768,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder-32B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-11-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-coder-32b-instruct-128k",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 32B Instruct 128K",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-coder-32b-instruct-32k-ro-pe",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 32B Instruct 32K RoPE",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-coder-32b-instruct-64-k",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 32B Instruct 64k",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-coder-3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 3B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-coder-3b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 3B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-coder-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00003,
                "inputCacheHit": null,
                "output": 0.00009
            },
            "extendedThinking": false,
            "id": "qwen-2-5-coder-7b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-03-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Coder-7B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-math-72b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Math 72B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00005,
                "inputCacheHit": null,
                "output": 0.00022
            },
            "extendedThinking": false,
            "id": "qwen-2-5-vl-32b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-04-14",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2.5-VL-32B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-03-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-vl-3b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-04-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2.5-VL-3B-Instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00008,
                "inputCacheHit": null,
                "output": 0.00033
            },
            "extendedThinking": false,
            "id": "qwen-2-5-vl-72b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-06-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2.5-VL-72B-Instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-vl-7b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-04-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2.5-VL-7B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-72b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2 72B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": "2024-06-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-7b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2-7B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-06-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-vl-2b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2-VL-2B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-08-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-vl-72b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2-VL 72B Instruct",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-vl-7b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-03-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2-VL-7B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-08-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-0-6b",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-0.6B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00005,
                "inputCacheHit": null,
                "output": 0.00022
            },
            "extendedThinking": false,
            "id": "qwen-3-14b",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-14B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-1-7b",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-1.7B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-1-7b-fp-8-model-used-for-drafting",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 1.7B fp8 model used for drafting",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-1-7b-fp-8-model-used-for-drafting-for-131072-context",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 1.7B fp8 model used for drafting for 131072 context",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-1-7b-fp-8-model-used-for-drafting-for-40960-context-length",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 1.7B fp8 model used for drafting for 40960 context length",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00018,
                "inputCacheHit": null,
                "output": 0.00054
            },
            "extendedThinking": false,
            "id": "qwen-3-235b-a22b",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-235B-A22B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00006,
                "inputCacheHit": null,
                "output": 0.00022
            },
            "extendedThinking": false,
            "id": "qwen-3-30b-a3b",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-30B-A3B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00008,
                "inputCacheHit": null,
                "output": 0.00033
            },
            "extendedThinking": false,
            "id": "qwen-3-30b-a3b-instruct-2507",
            "knowledge": null,
            "lastUpdated": "2025-09-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-30B-A3B-Instruct-2507",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00008,
                "inputCacheHit": null,
                "output": 0.00029
            },
            "extendedThinking": true,
            "id": "qwen-3-30b-a3b-thinking-2507",
            "knowledge": null,
            "lastUpdated": "2025-08-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-30B-A3B-Thinking-2507",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-07-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0,
                "inputCacheHit": null,
                "output": 0
            },
            "extendedThinking": false,
            "id": "qwen-3-4b",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-4B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00003,
                "inputCacheHit": null,
                "output": 0.00011
            },
            "extendedThinking": false,
            "id": "qwen-3-8b",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-8B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00006,
                "inputCacheHit": null,
                "output": 0.00025
            },
            "extendedThinking": false,
            "id": "qwen-3-coder-30b-a3b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-12-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Coder-30B-A3B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-coder-480b-a35b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-08-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Coder-480B-A35B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-qwq-32b-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen QWQ 32B Preview",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": "2024-11-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "rolm-ocr",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Rolm OCR",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "segmind-stable-diffusion-1b-(ssd-1b)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Segmind Stable Diffusion 1B (SSD-1B)",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "snorkel-mistral-pair-rm-dpo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Snorkel Mistral PairRM DPO",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "stable-code-3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Stable Code 3B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "stable-diffusion-xl",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Stable Diffusion XL",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "star-coder-16b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "StarCoder 16B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "star-coder-2-15b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "StarCoder2 15B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "star-coder-2-3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "StarCoder2 3B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "star-coder-2-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "StarCoder2 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "star-coder-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "StarCoder 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "streaming-asr",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Streaming ASR",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "toppy-m-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Toppy M 7B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "whisper-v3-large",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Whisper V3 Large",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "whisper-v3-turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Whisper V3 Turbo",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "yi-34b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Yi 34B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "yi-34b-chat",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Yi 34B Chat",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "yi-6b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Yi 6B",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.003,
                "inputCacheHit": null,
                "output": 0.003
            },
            "extendedThinking": false,
            "id": "yi-large",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Yi-Large",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "zephyr-7b-beta",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Zephyr 7B Beta",
            "openWeights": false,
            "provider": "Fireworks AI",
            "providerDoc": "https://readme.fireworks.ai/",
            "providerEnv": ["FIREWORKS_API_KEY"],
            "providerId": "fireworks-ai",
            "providerModelsDevId": "fireworks-ai",
            "providerNpm": "@ai-sdk/fireworks",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "fireworks"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "claude-sonnet-3-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Claude Sonnet 3.5",
            "openWeights": false,
            "provider": "GitHub Copilot",
            "providerDoc": "https://docs.github.com/en/copilot/reference/ai-models/supported-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-copilot",
            "providerModelsDevId": "github-copilot",
            "providerNpm": "@ai-sdk/github-copilot",
            "reasoning": false,
            "releaseDate": "2024-03-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "githubcopilot"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "claude-sonnet-3-7-thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Claude Sonnet 3.7 Thinking",
            "openWeights": false,
            "provider": "GitHub Copilot",
            "providerDoc": "https://docs.github.com/en/copilot/reference/ai-models/supported-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-copilot",
            "providerModelsDevId": "github-copilot",
            "providerNpm": "@ai-sdk/github-copilot",
            "reasoning": true,
            "releaseDate": "2024-11-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "githubcopilot"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-2-0-flash",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemini 2.0 Flash",
            "openWeights": false,
            "provider": "GitHub Copilot",
            "providerDoc": "https://docs.github.com/en/copilot/reference/ai-models/supported-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-copilot",
            "providerModelsDevId": "github-copilot",
            "providerNpm": "@ai-sdk/github-copilot",
            "reasoning": false,
            "releaseDate": "2024-05-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "githubcopilot"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-2-5-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemini 2.5 Pro",
            "openWeights": false,
            "provider": "GitHub Copilot",
            "providerDoc": "https://docs.github.com/en/copilot/reference/ai-models/supported-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-copilot",
            "providerModelsDevId": "github-copilot",
            "providerNpm": "@ai-sdk/github-copilot",
            "reasoning": false,
            "releaseDate": "2024-12-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "githubcopilot"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-3-flash",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemini 3 Flash",
            "openWeights": false,
            "provider": "GitHub Copilot",
            "providerDoc": "https://docs.github.com/en/copilot/reference/ai-models/supported-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-copilot",
            "providerModelsDevId": "github-copilot",
            "providerNpm": "@ai-sdk/github-copilot",
            "reasoning": false,
            "releaseDate": "2024-02-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "githubcopilot"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-3-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemini 3 Pro",
            "openWeights": false,
            "provider": "GitHub Copilot",
            "providerDoc": "https://docs.github.com/en/copilot/reference/ai-models/supported-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-copilot",
            "providerModelsDevId": "github-copilot",
            "providerNpm": "@ai-sdk/github-copilot",
            "reasoning": false,
            "releaseDate": "2024-02-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "githubcopilot"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "gpt-4-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GPT-4.1",
            "openWeights": false,
            "provider": "GitHub Copilot",
            "providerDoc": "https://docs.github.com/en/copilot/reference/ai-models/supported-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-copilot",
            "providerModelsDevId": "github-copilot",
            "providerNpm": "@ai-sdk/github-copilot",
            "reasoning": false,
            "releaseDate": "2024-12-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "githubcopilot"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "gpt-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GPT-5",
            "openWeights": false,
            "provider": "GitHub Copilot",
            "providerDoc": "https://docs.github.com/en/copilot/reference/ai-models/supported-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-copilot",
            "providerModelsDevId": "github-copilot",
            "providerNpm": "@ai-sdk/github-copilot",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "githubcopilot"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "gpt-5-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GPT-5.1",
            "openWeights": false,
            "provider": "GitHub Copilot",
            "providerDoc": "https://docs.github.com/en/copilot/reference/ai-models/supported-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-copilot",
            "providerModelsDevId": "github-copilot",
            "providerNpm": "@ai-sdk/github-copilot",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "githubcopilot"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "gpt-5-1-codex",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GPT-5.1-Codex",
            "openWeights": false,
            "provider": "GitHub Copilot",
            "providerDoc": "https://docs.github.com/en/copilot/reference/ai-models/supported-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-copilot",
            "providerModelsDevId": "github-copilot",
            "providerNpm": "@ai-sdk/github-copilot",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "githubcopilot"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "gpt-5-1-codex-max",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GPT-5.1-Codex-Max",
            "openWeights": false,
            "provider": "GitHub Copilot",
            "providerDoc": "https://docs.github.com/en/copilot/reference/ai-models/supported-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-copilot",
            "providerModelsDevId": "github-copilot",
            "providerNpm": "@ai-sdk/github-copilot",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "githubcopilot"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "gpt-5-1-codex-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GPT-5.1-Codex-Mini",
            "openWeights": false,
            "provider": "GitHub Copilot",
            "providerDoc": "https://docs.github.com/en/copilot/reference/ai-models/supported-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-copilot",
            "providerModelsDevId": "github-copilot",
            "providerNpm": "@ai-sdk/github-copilot",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "githubcopilot"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "gpt-5-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GPT-5.2",
            "openWeights": false,
            "provider": "GitHub Copilot",
            "providerDoc": "https://docs.github.com/en/copilot/reference/ai-models/supported-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-copilot",
            "providerModelsDevId": "github-copilot",
            "providerNpm": "@ai-sdk/github-copilot",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "githubcopilot"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "gpt-5-codex",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GPT-5-Codex",
            "openWeights": false,
            "provider": "GitHub Copilot",
            "providerDoc": "https://docs.github.com/en/copilot/reference/ai-models/supported-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-copilot",
            "providerModelsDevId": "github-copilot",
            "providerNpm": "@ai-sdk/github-copilot",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "githubcopilot"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "gpt-5-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GPT-5 mini",
            "openWeights": false,
            "provider": "GitHub Copilot",
            "providerDoc": "https://docs.github.com/en/copilot/reference/ai-models/supported-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-copilot",
            "providerModelsDevId": "github-copilot",
            "providerNpm": "@ai-sdk/github-copilot",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "githubcopilot"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "grok-code-fast-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Grok Code Fast 1",
            "openWeights": false,
            "provider": "GitHub Copilot",
            "providerDoc": "https://docs.github.com/en/copilot/reference/ai-models/supported-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-copilot",
            "providerModelsDevId": "github-copilot",
            "providerNpm": "@ai-sdk/github-copilot",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "githubcopilot"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.002,
                "inputCacheHit": null,
                "output": 0.008
            },
            "extendedThinking": false,
            "id": "o-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "o3",
            "openWeights": false,
            "provider": "GitHub Copilot",
            "providerDoc": "https://docs.github.com/en/copilot/reference/ai-models/supported-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-copilot",
            "providerModelsDevId": "github-copilot",
            "providerNpm": "@ai-sdk/github-copilot",
            "reasoning": false,
            "releaseDate": "2024-02-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "githubcopilot"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0011,
                "inputCacheHit": null,
                "output": 0.0044
            },
            "extendedThinking": false,
            "id": "o-4-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "o4-mini",
            "openWeights": false,
            "provider": "GitHub Copilot",
            "providerDoc": "https://docs.github.com/en/copilot/reference/ai-models/supported-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-copilot",
            "providerModelsDevId": "github-copilot",
            "providerNpm": "@ai-sdk/github-copilot",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "githubcopilot"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "raptor-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Raptor mini",
            "openWeights": false,
            "provider": "GitHub Copilot",
            "providerDoc": "https://docs.github.com/en/copilot/reference/ai-models/supported-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-copilot",
            "providerModelsDevId": "github-copilot",
            "providerNpm": "@ai-sdk/github-copilot",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "githubcopilot"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "about-github-models",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "about-github-models",
            "openWeights": false,
            "provider": "GitHub Models",
            "providerDoc": "https://docs.github.com/en/github-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-models",
            "providerModelsDevId": "github-models",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "github"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ask-copilot-open",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "askCopilotOpen",
            "openWeights": false,
            "provider": "GitHub Models",
            "providerDoc": "https://docs.github.com/en/github-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-models",
            "providerModelsDevId": "github-models",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "github"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ask-copilot-select",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "askCopilotSelect",
            "openWeights": false,
            "provider": "GitHub Models",
            "providerDoc": "https://docs.github.com/en/github-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-models",
            "providerModelsDevId": "github-models",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "github"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "github-models",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "github-models",
            "openWeights": false,
            "provider": "GitHub Models",
            "providerDoc": "https://docs.github.com/en/github-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-models",
            "providerModelsDevId": "github-models",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "github"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "optimizing-your-ai-powered-app-with-github-models",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "optimizing-your-ai-powered-app-with-github-models",
            "openWeights": false,
            "provider": "GitHub Models",
            "providerDoc": "https://docs.github.com/en/github-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-models",
            "providerModelsDevId": "github-models",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "github"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "prototyping-with-ai-models",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "prototyping-with-ai-models",
            "openWeights": false,
            "provider": "GitHub Models",
            "providerDoc": "https://docs.github.com/en/github-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-models",
            "providerModelsDevId": "github-models",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "github"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "use-github-models",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "use-github-models",
            "openWeights": false,
            "provider": "GitHub Models",
            "providerDoc": "https://docs.github.com/en/github-models",
            "providerEnv": ["GITHUB_TOKEN"],
            "providerId": "git-hub-models",
            "providerModelsDevId": "github-models",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "github"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-1-5-flash",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemini 1.5 Flash",
            "openWeights": false,
            "provider": "Google",
            "providerDoc": "https://ai.google.dev/models",
            "providerEnv": ["GOOGLE_API_KEY"],
            "providerId": "google",
            "providerModelsDevId": "google",
            "providerNpm": "@ai-sdk/google",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-1-5-flash-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemini 1.5 Flash-8B",
            "openWeights": false,
            "provider": "Google",
            "providerDoc": "https://ai.google.dev/models",
            "providerEnv": ["GOOGLE_API_KEY"],
            "providerId": "google",
            "providerModelsDevId": "google",
            "providerNpm": "@ai-sdk/google",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-1-5-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemini 1.5 Pro",
            "openWeights": false,
            "provider": "Google",
            "providerDoc": "https://ai.google.dev/models",
            "providerEnv": ["GOOGLE_API_KEY"],
            "providerId": "google",
            "providerModelsDevId": "google",
            "providerNpm": "@ai-sdk/google",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-2-0-flash-lite",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemini 2.0 Flash-Lite",
            "openWeights": false,
            "provider": "Google",
            "providerDoc": "https://ai.google.dev/models",
            "providerEnv": ["GOOGLE_API_KEY"],
            "providerId": "google",
            "providerModelsDevId": "google",
            "providerNpm": "@ai-sdk/google",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-2-0-flash-preview-image-generation",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemini 2.0 Flash Preview Image Generation",
            "openWeights": false,
            "provider": "Google",
            "providerDoc": "https://ai.google.dev/models",
            "providerEnv": ["GOOGLE_API_KEY"],
            "providerId": "google",
            "providerModelsDevId": "google",
            "providerNpm": "@ai-sdk/google",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-2-5-flash",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemini 2.5 Flash",
            "openWeights": false,
            "provider": "Google",
            "providerDoc": "https://ai.google.dev/models",
            "providerEnv": ["GOOGLE_API_KEY"],
            "providerId": "google",
            "providerModelsDevId": "google",
            "providerNpm": "@ai-sdk/google",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-2-5-flash-lite",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemini 2.5 Flash-Lite",
            "openWeights": false,
            "provider": "Google",
            "providerDoc": "https://ai.google.dev/models",
            "providerEnv": ["GOOGLE_API_KEY"],
            "providerId": "google",
            "providerModelsDevId": "google",
            "providerNpm": "@ai-sdk/google",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-2-5-flash-native-audio",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemini 2.5 Flash Native Audio",
            "openWeights": false,
            "provider": "Google",
            "providerDoc": "https://ai.google.dev/models",
            "providerEnv": ["GOOGLE_API_KEY"],
            "providerId": "google",
            "providerModelsDevId": "google",
            "providerNpm": "@ai-sdk/google",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-2-5-flash-preview-tts",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemini 2.5 Flash Preview TTS",
            "openWeights": false,
            "provider": "Google",
            "providerDoc": "https://ai.google.dev/models",
            "providerEnv": ["GOOGLE_API_KEY"],
            "providerId": "google",
            "providerModelsDevId": "google",
            "providerNpm": "@ai-sdk/google",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-2-5-pro-preview-tts",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemini 2.5 Pro Preview TTS",
            "openWeights": false,
            "provider": "Google",
            "providerDoc": "https://ai.google.dev/models",
            "providerEnv": ["GOOGLE_API_KEY"],
            "providerId": "google",
            "providerModelsDevId": "google",
            "providerNpm": "@ai-sdk/google",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-api-card-width",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "--gemini-api-card-width",
            "openWeights": false,
            "provider": "Google",
            "providerDoc": "https://ai.google.dev/models",
            "providerEnv": ["GOOGLE_API_KEY"],
            "providerId": "google",
            "providerModelsDevId": "google",
            "providerNpm": "@ai-sdk/google",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-api-elevation-1-dp",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "--gemini-api-elevation-1dp",
            "openWeights": false,
            "provider": "Google",
            "providerDoc": "https://ai.google.dev/models",
            "providerEnv": ["GOOGLE_API_KEY"],
            "providerId": "google",
            "providerModelsDevId": "google",
            "providerNpm": "@ai-sdk/google",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-api-elevation-3-dp",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "--gemini-api-elevation-3dp",
            "openWeights": false,
            "provider": "Google",
            "providerDoc": "https://ai.google.dev/models",
            "providerEnv": ["GOOGLE_API_KEY"],
            "providerId": "google",
            "providerModelsDevId": "google",
            "providerNpm": "@ai-sdk/google",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-api-model-font",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "--gemini-api-model-font",
            "openWeights": false,
            "provider": "Google",
            "providerDoc": "https://ai.google.dev/models",
            "providerEnv": ["GOOGLE_API_KEY"],
            "providerId": "google",
            "providerModelsDevId": "google",
            "providerNpm": "@ai-sdk/google",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-api-table-font-color",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "--gemini-api-table-font-color",
            "openWeights": false,
            "provider": "Google",
            "providerDoc": "https://ai.google.dev/models",
            "providerEnv": ["GOOGLE_API_KEY"],
            "providerId": "google",
            "providerModelsDevId": "google",
            "providerNpm": "@ai-sdk/google",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "code-gemma",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "CodeGemma",
            "openWeights": true,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "embeddings-for-text",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Embeddings for Text",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-2-5-flash-image",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemini 2.5 Flash Image",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-2-5-flash-with-gemini-live-api",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemini 2.5 Flash with Gemini Live API",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-3-pro-image",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Gemini 3 Pro Image",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00007,
                "inputCacheHit": null,
                "output": 0.00007
            },
            "extendedThinking": false,
            "id": "gemma",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemma",
            "openWeights": true,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemma-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemma 2",
            "openWeights": true,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemma-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemma 3",
            "openWeights": true,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemma-3-n",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemma 3n",
            "openWeights": true,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "imagen-3-for-editing-and-customization",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image", "video"]
            },
            "name": "Imagen 3 for Editing and Customization",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "imagen-3-for-fast-generation",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image", "video"]
            },
            "name": "Imagen 3 for Fast Generation",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "imagen-3-for-generation",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image", "video"]
            },
            "name": "Imagen 3 for Generation",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "imagen-3-for-generation-001",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image", "video"]
            },
            "name": "Imagen 3 for Generation 001",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "imagen-3-for-generation-002",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image", "video"]
            },
            "name": "Imagen 3 for Generation 002",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "imagen-4-for-fast-generation",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image", "video"]
            },
            "name": "Imagen 4 for Fast Generation",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "imagen-4-for-generation",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image", "video"]
            },
            "name": "Imagen 4 for Generation",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "imagen-4-for-ultra-generation",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image", "video"]
            },
            "name": "Imagen 4 for Ultra Generation",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "imagen-for-captioning-&-vqa",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image", "video"]
            },
            "name": "Imagen for Captioning & VQA",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "imagen-product-recontext-on-vertex-ai",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image", "video"]
            },
            "name": "Imagen product recontext on Vertex AI",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "med-gemma",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MedGemma",
            "openWeights": true,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "multimodal-embeddings",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Multimodal Embeddings",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "pali-gemma",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "PaliGemma",
            "openWeights": true,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "shield-gemma-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ShieldGemma 2",
            "openWeights": true,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "t-5-gemma",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "T5Gemma",
            "openWeights": true,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "tx-gemma",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "TxGemma",
            "openWeights": true,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "veo-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image", "video"]
            },
            "name": "Veo 2",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "veo-2-experimental",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image", "video"]
            },
            "name": "Veo 2 Experimental",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "veo-2-generate",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image", "video"]
            },
            "name": "Veo 2 Generate",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "veo-2-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image", "video"]
            },
            "name": "Veo 2 Preview",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "veo-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image", "video"]
            },
            "name": "Veo 3",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "veo-3-1-fast",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image", "video"]
            },
            "name": "Veo 3.1 Fast",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "veo-3-1-fast-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image", "video"]
            },
            "name": "Veo 3.1 Fast preview",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "veo-3-1-generate",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image", "video"]
            },
            "name": "Veo 3.1 Generate",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "veo-3-1-generate-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image", "video"]
            },
            "name": "Veo 3.1 Generate preview",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "veo-3-fast",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image", "video"]
            },
            "name": "Veo 3 Fast",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "veo-3-fast-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image", "video"]
            },
            "name": "Veo 3 Fast preview",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "veo-3-generate",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image", "video"]
            },
            "name": "Veo 3 Generate",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "veo-3-generate-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image", "video"]
            },
            "name": "Veo 3 Generate preview",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "veo-3-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image", "video"]
            },
            "name": "Veo 3 preview",
            "openWeights": false,
            "provider": "Google Vertex",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/models",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-vertex",
            "providerModelsDevId": "google-vertex",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "vertexai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "jamba-1-5-large",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 0,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Jamba 1.5 Large",
            "openWeights": false,
            "provider": "Google Partner",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/ai21/jamba-1-5-large",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-partner/google-vertex-ai21-labs",
            "providerModelsDevId": "google-vertex-partner",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "jamba-1-5-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 0,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Jamba 1.5 Mini",
            "openWeights": false,
            "provider": "Google Partner",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/ai21/jamba-1-5-mini",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-partner/google-vertex-ai21-labs",
            "providerModelsDevId": "google-vertex-partner",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "claude-3-5-haiku",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Claude 3.5 Haiku",
            "openWeights": false,
            "provider": "Google Partner",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/haiku-3-5",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-partner/google-vertex-claude",
            "providerModelsDevId": "google-vertex-partner",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "claude-3-5-sonnet",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Claude 3.5 Sonnet",
            "openWeights": false,
            "provider": "Google Partner",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/sonnet-3-5",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-partner/google-vertex-claude",
            "providerModelsDevId": "google-vertex-partner",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "claude-3-5-sonnet-v-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Claude 3.5 Sonnet v2",
            "openWeights": false,
            "provider": "Google Partner",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/sonnet-3-5-v2",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-partner/google-vertex-claude",
            "providerModelsDevId": "google-vertex-partner",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "claude-3-7-sonnet",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Claude 3.7 Sonnet",
            "openWeights": false,
            "provider": "Google Partner",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/sonnet-3-7",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-partner/google-vertex-claude",
            "providerModelsDevId": "google-vertex-partner",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "claude-3-haiku",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Claude 3 Haiku",
            "openWeights": false,
            "provider": "Google Partner",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/haiku-3",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-partner/google-vertex-claude",
            "providerModelsDevId": "google-vertex-partner",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "safety-classifiers",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Safety classifiers",
            "openWeights": false,
            "provider": "Google Partner",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/safety",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-partner/google-vertex-claude",
            "providerModelsDevId": "google-vertex-partner",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "web-search",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Web search",
            "openWeights": false,
            "provider": "Google Partner",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/claude/web-search",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-partner/google-vertex-claude",
            "providerModelsDevId": "google-vertex-partner",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.3,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "codestral-(25-01)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 0,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Codestral (25.01)",
            "openWeights": false,
            "provider": "Google Partner",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/mistral/codestral-2501",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-partner/google-vertex-mistral-ai",
            "providerModelsDevId": "google-vertex-partner",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.3,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "codestral-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 0,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Codestral 2",
            "openWeights": false,
            "provider": "Google Partner",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/mistral/codestral-2",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-partner/google-vertex-mistral-ai",
            "providerModelsDevId": "google-vertex-partner",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-large-(24-11)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Large (24.11)",
            "openWeights": false,
            "provider": "Google Partner",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/mistral/mistral-large",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-partner/google-vertex-mistral-ai",
            "providerModelsDevId": "google-vertex-partner",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": true,
            "releaseDate": "2024-11-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-medium-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 0,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Medium 3",
            "openWeights": false,
            "provider": "Google Partner",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/mistral/mistral-medium-3",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-partner/google-vertex-mistral-ai",
            "providerModelsDevId": "google-vertex-partner",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-ocr-(25-05)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Mistral OCR (25.05)",
            "openWeights": false,
            "provider": "Google Partner",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/mistral/mistral-ocr",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-partner/google-vertex-mistral-ai",
            "providerModelsDevId": "google-vertex-partner",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-small-3-1-(25-03)",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 0,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Small 3.1 (25.03)",
            "openWeights": false,
            "provider": "Google Partner",
            "providerDoc": "https://cloud.google.com/vertex-ai/generative-ai/docs/partner-models/mistral/mistral-small-3-1",
            "providerEnv": ["GOOGLE_VERTEX_PROJECT", "GOOGLE_VERTEX_LOCATION", "GOOGLE_APPLICATION_CREDENTIALS"],
            "providerId": "google-partner/google-vertex-mistral-ai",
            "providerModelsDevId": "google-vertex-partner",
            "providerNpm": "@ai-sdk/google-vertex",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "google"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "canopy",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4000,
                "output": 50000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Canopy",
            "openWeights": false,
            "preview": true,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "compound",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Compound",
            "openWeights": false,
            "preview": false,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "compound-beta",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "compound-beta",
            "openWeights": false,
            "preview": true,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "compound-beta-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "compound-beta-mini",
            "openWeights": false,
            "preview": true,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00075,
                "inputCacheHit": null,
                "output": 0.00099
            },
            "extendedThinking": false,
            "id": "deepseek-r-1-distill-llama-70-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-r1-distill-llama-70b",
            "openWeights": false,
            "preview": false,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": "2025-01-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.075,
                "inputCacheHit": null,
                "output": 0.3
            },
            "extendedThinking": false,
            "id": "gpt",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GPT",
            "openWeights": false,
            "preview": false,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1,
                "inputCacheHit": null,
                "output": 3
            },
            "extendedThinking": false,
            "id": "kimi",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kimi",
            "openWeights": false,
            "preview": true,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.03
            },
            "extendedThinking": false,
            "id": "llama",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 512,
                "output": 512
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama",
            "openWeights": false,
            "preview": true,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00005,
                "inputCacheHit": null,
                "output": 0.00008
            },
            "extendedThinking": false,
            "id": "llama-3-1-8-b-instant",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3.1-8b-instant",
            "openWeights": false,
            "preview": false,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00059,
                "inputCacheHit": null,
                "output": 0.00079
            },
            "extendedThinking": false,
            "id": "llama-3-3-70-b-versatile",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-3.3-70b-versatile",
            "openWeights": false,
            "preview": false,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0002,
                "inputCacheHit": null,
                "output": 0.0006
            },
            "extendedThinking": false,
            "id": "meta-llama-llama-4-maverick-17-b-128-e-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "meta-llama/llama-4-maverick-17b-128e-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00011,
                "inputCacheHit": null,
                "output": 0.00034
            },
            "extendedThinking": false,
            "id": "meta-llama-llama-4-scout-17-b-16-e-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "meta-llama/llama-4-scout-17b-16e-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0002,
                "inputCacheHit": null,
                "output": 0.0002
            },
            "extendedThinking": false,
            "id": "meta-llama-llama-guard-4-12-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "meta-llama/llama-guard-4-12b",
            "openWeights": false,
            "preview": false,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama-llama-prompt-guard-2-22-m",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "meta-llama/llama-prompt-guard-2-22m",
            "openWeights": false,
            "preview": false,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama-llama-prompt-guard-2-86-m",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "meta-llama/llama-prompt-guard-2-86m",
            "openWeights": false,
            "preview": false,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.001,
                "inputCacheHit": null,
                "output": 0.003
            },
            "extendedThinking": false,
            "id": "moonshotai-kimi-k-2-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "moonshotai/kimi-k2-instruct",
            "openWeights": false,
            "preview": false,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00015,
                "inputCacheHit": null,
                "output": 0.00075
            },
            "extendedThinking": false,
            "id": "openai-gpt-oss-120-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "openai/gpt-oss-120b",
            "openWeights": false,
            "preview": false,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq",
            "description": "Efficient Mixture-of-Experts model designed for high-reasoning, agentic and general-purpose use cases"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0001,
                "inputCacheHit": null,
                "output": 0.0005
            },
            "extendedThinking": false,
            "id": "openai-gpt-oss-20-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "openai/gpt-oss-20b",
            "openWeights": false,
            "preview": false,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq",
            "description": "Lower latency Mixture-of-Experts model trained on OpenAIs Harmony response format with reasoning capabilities"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "playai-tts",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "playai-tts",
            "openWeights": false,
            "preview": false,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "playai-tts-arabic",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "playai-tts-arabic",
            "openWeights": false,
            "preview": false,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.04,
                "inputCacheHit": null,
                "output": 0.04
            },
            "extendedThinking": false,
            "id": "prompt",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 512,
                "output": 512
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Prompt",
            "openWeights": false,
            "preview": true,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00029,
                "inputCacheHit": null,
                "output": 0.00059
            },
            "extendedThinking": false,
            "id": "qwen-qwen-3-32-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen/qwen3-32b",
            "openWeights": false,
            "preview": false,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.075,
                "inputCacheHit": null,
                "output": 0.3
            },
            "extendedThinking": false,
            "id": "safety",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Safety",
            "openWeights": false,
            "preview": true,
            "provider": "Groq",
            "providerDoc": "https://console.groq.com/docs/models",
            "providerEnv": ["GROQ_API_KEY"],
            "providerId": "groq",
            "providerModelsDevId": "groq",
            "providerNpm": "@ai-sdk/groq",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "groq"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "whisper-large-v-3",
            "knowledge": null,
            "lastUpdated": "2025-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "whisper-large-v3",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope",
            "preview": false
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "whisper-large-v-3-turbo",
            "knowledge": null,
            "lastUpdated": "2025-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "whisper-large-v3-turbo",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope",
            "preview": false
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "amazon-chronos-t-5-small",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "amazon/chronos-t5-small",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "babelscape-rebel-large",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Babelscape/rebel-large",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "context-labs-meta-llama-llama-3-2-3b-instruct-fp16",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "context-labs/meta-llama-Llama-3.2-3B-Instruct-FP16",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "distilbert-distilgpt-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "distilbert/distilgpt2",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "dphn-dolphin-2-9-1-yi-1-5-34-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "dphn/dolphin-2.9.1-yi-1.5-34b",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "facebook-bart-large-cnn",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "facebook/bart-large-cnn",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "facebook-opt-125-m",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "facebook/opt-125m",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gensyn-qwen-2-5-0-5b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gensyn/Qwen2.5-0.5B-Instruct",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google-gemma-3-1-b-it",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "google/gemma-3-1b-it",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google-t-5-gemma-b-b-prefixlm",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "google/t5gemma-b-b-prefixlm",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google-t-5-t-5-small",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "google-t5/t5-small",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2.2e-7,
                "inputCacheHit": null,
                "output": 2.2e-7
            },
            "description": "Efficient conversational model optimized for responsive multilingual chatbot interactions",
            "extendedThinking": false,
            "id": "meta-llama-llama-3-1-8b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta Llama 3.1 8B",
            "openWeights": false,
            "provider": "Weights & Biases",
            "providerDoc": "https://docs.wandb.ai/guides/inference/models/",
            "providerEnv": ["WANDB_API_KEY"],
            "providerId": "weights-biases",
            "providerModelsDevId": "weights-biases",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "weights & biases"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00002,
                "inputCacheHit": null,
                "output": 0.00002
            },
            "extendedThinking": false,
            "id": "meta-llama-llama-3-2-1b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "meta-llama/Llama-3.2-1B-Instruct",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai-community-gpt-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "openai-community/gpt2",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai-community-gpt-2-large",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "openai-community/gpt2-large",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": 6e-8,
                "inputCacheHit": null,
                "output": 2.4e-7
            },
            "description": "Dense multilingual instruction-tuned model with tool-use and structured output support",
            "extendedThinking": false,
            "id": "qwen-qwen-2-5-14b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5 14B Instruct",
            "openWeights": false,
            "provider": "Weights & Biases",
            "providerDoc": "https://docs.wandb.ai/guides/inference/models/",
            "providerEnv": ["WANDB_API_KEY"],
            "providerId": "weights-biases",
            "providerModelsDevId": "weights-biases",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "weights & biases"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-qwen-2-5-1-5b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen2.5-1.5B-Instruct",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-qwen-2-5-32b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen2.5-32B-Instruct",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-qwen-2-5-3b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen2.5-3B-Instruct",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "qwen-qwen-2-5-7b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen2.5-7B-Instruct",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": "2024-10-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-qwen-2-5-coder-0-5b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen2.5-Coder-0.5B-Instruct",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-qwen-2-5-vl-3b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen2.5-VL-3B-Instruct",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-qwen-2-5-vl-7b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen2.5-VL-7B-Instruct",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": "2024-08-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-qwen-3-0-6b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen3-0.6B",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-qwen-3-1-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen3-1.7B",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0,
                "inputCacheHit": null,
                "output": 0
            },
            "extendedThinking": false,
            "id": "qwen-qwen-3-4b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen3-4B",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-qwen-3-4b-base",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen3-4B-Base",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-qwen-3-4b-instruct-2507",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen3-4B-Instruct-2507",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000035,
                "inputCacheHit": null,
                "output": 0.000138
            },
            "extendedThinking": false,
            "id": "qwen-qwen-3-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 20000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen3-8B",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-qwen-3-embedding-0-6b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen3-Embedding-0.6B",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0001,
                "inputCacheHit": null,
                "output": 0.0008
            },
            "extendedThinking": false,
            "id": "qwen-qwen-3-next-80b-a3b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen/Qwen3-Next-80B-A3B-Instruct",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": "2025-09-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "unslothai-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "unslothai/1",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "vikhyatk-moondream-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vikhyatk/moondream2",
            "openWeights": true,
            "provider": "Hugging Face",
            "providerDoc": "https://huggingface.co/docs",
            "providerEnv": ["HUGGINGFACE_API_KEY"],
            "providerId": "hugging-face",
            "providerModelsDevId": "huggingface",
            "providerNpm": "@ai-sdk/huggingface",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "huggingface"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.25,
                "inputCacheHit": 0.25,
                "output": 1
            },
            "extendedThinking": false,
            "id": "mercury",
            "knowledge": "2023-10",
            "lastUpdated": "2025-07-31",
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mercury",
            "openWeights": false,
            "provider": "inception",
            "providerDoc": "https://platform.inceptionlabs.ai/docs",
            "providerEnv": ["INCEPTION_API_KEY"],
            "providerId": "inception",
            "providerModelsDevId": "inception",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "inception"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.25,
                "inputCacheHit": 0.25,
                "output": 1
            },
            "extendedThinking": false,
            "id": "mercury-coder",
            "knowledge": "2023-10",
            "lastUpdated": "2025-07-31",
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mercury Coder",
            "openWeights": false,
            "provider": "inception",
            "providerDoc": "https://platform.inceptionlabs.ai/docs",
            "providerEnv": ["INCEPTION_API_KEY"],
            "providerId": "inception",
            "providerModelsDevId": "inception",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "inception"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.002,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "2-vision",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "2-Vision",
            "openWeights": false,
            "provider": "Inference",
            "providerDoc": "https://inference.net/models",
            "providerEnv": ["INFERENCE_API_KEY"],
            "providerId": "inference",
            "providerModelsDevId": "inference",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "inference"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "3-gemma",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "3Gemma",
            "openWeights": false,
            "provider": "Inference",
            "providerDoc": "https://inference.net/models",
            "providerEnv": ["INFERENCE_API_KEY"],
            "providerId": "inference",
            "providerModelsDevId": "inference",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "inference"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "id-meta-fp-16-llama",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "IDMetaFP16Llama",
            "openWeights": false,
            "provider": "Inference",
            "providerDoc": "https://inference.net/models",
            "providerEnv": ["INFERENCE_API_KEY"],
            "providerId": "inference",
            "providerModelsDevId": "inference",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "inference"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "id-meta-fp-8-fp-16-llama",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "IDMetaFP8FP16Llama",
            "openWeights": false,
            "provider": "Inference",
            "providerDoc": "https://inference.net/models",
            "providerEnv": ["INFERENCE_API_KEY"],
            "providerId": "inference",
            "providerModelsDevId": "inference",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "inference"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "id-meta-fp-8-llama",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "IDMetaFP8Llama",
            "openWeights": false,
            "provider": "Inference",
            "providerDoc": "https://inference.net/models",
            "providerEnv": ["INFERENCE_API_KEY"],
            "providerId": "inference",
            "providerModelsDevId": "inference",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "inference"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "id-mistral-fp-8-mistral",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "IDMistralFP8Mistral",
            "openWeights": false,
            "provider": "Inference",
            "providerDoc": "https://inference.net/models",
            "providerEnv": ["INFERENCE_API_KEY"],
            "providerId": "inference",
            "providerModelsDevId": "inference",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "inference"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "instruct-llama",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "InstructLlama",
            "openWeights": false,
            "provider": "Inference",
            "providerDoc": "https://inference.net/models",
            "providerEnv": ["INFERENCE_API_KEY"],
            "providerId": "inference",
            "providerModelsDevId": "inference",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "inference"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "instruct-mistral-ne-mo-12b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "InstructMistral-NeMo-12B-Instruct",
            "openWeights": false,
            "provider": "Inference",
            "providerDoc": "https://inference.net/models",
            "providerEnv": ["INFERENCE_API_KEY"],
            "providerId": "inference",
            "providerModelsDevId": "inference",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "inference"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0,
                "inputCacheHit": null,
                "output": 0
            },
            "extendedThinking": false,
            "id": "llama-4-maverick-17b-128e-instruct-fp8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cerebras-Llama-4-Maverick-17B-128E-Instruct (Preview)",
            "openWeights": true,
            "provider": "Meta",
            "providerDoc": "https://llama.meta.com/llama/",
            "providerEnv": ["META_API_KEY"],
            "providerId": "meta/cerebras",
            "providerModelsDevId": "meta",
            "providerNpm": "@ai-sdk/meta",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "meta"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0,
                "inputCacheHit": null,
                "output": 0
            },
            "extendedThinking": false,
            "id": "llama-4-scout-17b-16e-instruct-fp8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cerebras-Llama-4-Scout-17B-16E-Instruct (Preview)",
            "openWeights": true,
            "provider": "Meta",
            "providerDoc": "https://llama.meta.com/llama/",
            "providerEnv": ["META_API_KEY"],
            "providerId": "meta/cerebras",
            "providerModelsDevId": "meta",
            "providerNpm": "@ai-sdk/meta",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "meta"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00045,
                "inputCacheHit": null,
                "output": 0.00045
            },
            "extendedThinking": false,
            "id": "llama-3_3-70b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama-3.3-70B-Instruct",
            "openWeights": true,
            "provider": "Meta",
            "providerDoc": "https://llama.meta.com/llama/",
            "providerEnv": ["META_API_KEY"],
            "providerId": "meta",
            "providerModelsDevId": "meta",
            "providerNpm": "@ai-sdk/meta",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "meta"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0,
                "inputCacheHit": null,
                "output": 0
            },
            "extendedThinking": false,
            "id": "llama-3_3-8b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama-3.3-8B-Instruct",
            "openWeights": true,
            "provider": "Meta",
            "providerDoc": "https://llama.meta.com/llama/",
            "providerEnv": ["META_API_KEY"],
            "providerId": "meta",
            "providerModelsDevId": "meta",
            "providerNpm": "@ai-sdk/meta",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "meta"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.3,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "codestral-2405",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Codestral 2405",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.3,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "codestral-2501",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Codestral 2501",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.3,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "codestral-2508",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Codestral 2508",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.3,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "codestral-embed",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Codestral Embed",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.3,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "codestral-mamba",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Codestral Mamba",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.3,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "codestral-mamba-7b-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 0,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Codestral Mamba 7B ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.3,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "codestral-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 24,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Codestral ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "devstral-medium",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Devstral Medium",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "devstral-small-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Devstral Small 1",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "devstral-small-1-0-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 25,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Devstral Small 1.0 ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "devstral-small-1-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Devstral Small 1.1",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "magistral-medium-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Magistral Medium 1",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "magistral-medium-1-0-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 25,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Magistral Medium 1.0 ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "magistral-medium-1-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Magistral Medium 1.1",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "magistral-medium-1-1-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 25,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Magistral Medium 1.1 ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "magistral-small-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Magistral Small 1",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "magistral-small-1-0-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 25,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Magistral Small 1.0 ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "magistral-small-1-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Magistral Small 1.1",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "magistral-small-1-1-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 25,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Magistral Small 1.1 ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mathstral-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mathstral 7B",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mathstral-7b-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 0,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mathstral 7B ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ministral-3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Ministral 3B",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ministral-3b-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 24,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Ministral 3B ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ministral-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Ministral 8B",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ministral-8b-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 24,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Ministral 8B ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-7b-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 0,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral 7B ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-embed",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Embed",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-large-1-0-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 24,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Mistral Large 1.0 ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-large-2402",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2402,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Mistral Large 2402",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-large-2407",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Mistral Large 2407",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": "2024-11-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-large-2-0-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 24,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Mistral Large 2.0 ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-large-2-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Mistral Large 2.1",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-medium-1-0-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 23,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Medium 1.0 ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-medium-2312",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2312,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Medium 2312",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-medium-3-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Medium 3.1",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-moderation",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Moderation",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-nemo-12b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Nemo 12B",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-next-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Next ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-ocr-2503",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2503,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral OCR 2503",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-ocr-2505",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral OCR 2505",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-saba-2502",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2502,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Saba 2502",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-saba-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 25,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Saba ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": "2025-02-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-small-1-0-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 24,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Small 1.0 ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-small-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Small 2",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-small-2402",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2402,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Small 2402",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-small-2-0-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 24,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Small 2.0 ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-small-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Small 3",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-small-3-0-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 25,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Small 3.0 ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-small-3-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Small 3.1",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-small-3-1-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 25,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Small 3.1 ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral-small-3-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Small 3.2",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mixtral-8-x-22-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mixtral 8x22B",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mixtral-8-x-22-b-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 0,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mixtral 8x22B ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mixtral-8-x-7-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mixtral 8x7B",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mixtral-8-x-7-b-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 0,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mixtral 8x7B ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ocr-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 25,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OCR ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "pixtral-12b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Pixtral 12B",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "pixtral-12b-",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 24,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Pixtral 12B ",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "pixtral-large",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Pixtral Large",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "voxtral-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Voxtral Mini",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "voxtral-mini-transcribe",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Voxtral Mini Transcribe",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "voxtral-small",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Voxtral Small",
            "openWeights": false,
            "provider": "Mistral",
            "providerDoc": "https://docs.mistral.ai/getting-started/models/",
            "providerEnv": ["MISTRAL_API_KEY"],
            "providerId": "mistral",
            "providerModelsDevId": "mistral",
            "providerNpm": "@ai-sdk/mistral",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "mistral"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "14-ckpt-sd-xl",
            "knowledge": null,
            "lastUpdated": "2025-03-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "14_ckpt_SD_XL",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "42-ckpt-sd-xl",
            "knowledge": null,
            "lastUpdated": "2025-03-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "42_ckpt_SD_XL",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "46-ckpt-sd-xl",
            "knowledge": null,
            "lastUpdated": "2025-03-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "46_ckpt_SD_XL",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "47-ckpt-sd-xl",
            "knowledge": null,
            "lastUpdated": "2025-04-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "47_ckpt_SD_XL",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "489-ckpt-flux-1",
            "knowledge": null,
            "lastUpdated": "2025-06-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "489_ckpt_FLUX_1",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "4-x-ultra-sharp",
            "knowledge": null,
            "lastUpdated": "2024-11-13",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "4x-UltraSharp",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-11-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ace-step-v-1-3-5b",
            "knowledge": null,
            "lastUpdated": "2025-05-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ACE-Step-v1-3.5B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "agentar-scale-sql-generation-32b",
            "knowledge": null,
            "lastUpdated": "2025-11-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Agentar-Scale-SQL-Generation-32B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ai-glasses-for-navigation",
            "knowledge": null,
            "lastUpdated": "2025-10-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "AIGlasses_for_navigation",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ai-model-hub-25-q3",
            "knowledge": null,
            "lastUpdated": "2025-10-10",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ai_model_hub_25_Q3",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "all-mini-lm-l6-v-2",
            "knowledge": null,
            "lastUpdated": "2025-04-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "all-MiniLM-L6-v2",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-11-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "alpamayo-r1-10b",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Alpamayo-R1-10B",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "animatediff",
            "knowledge": null,
            "lastUpdated": "2023-12-18",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "animatediff",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-11-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "anime-gpt-sovits-models",
            "knowledge": null,
            "lastUpdated": "2025-05-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Anime_GPT-Sovits_Models",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "animetoliveaction",
            "knowledge": null,
            "lastUpdated": "2025-12-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Animetoliveaction",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ant-angel-med",
            "knowledge": null,
            "lastUpdated": "2026-01-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "AntAngelMed",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ant-angel-med-eagle-3",
            "knowledge": null,
            "lastUpdated": "2026-01-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "AntAngelMed-eagle3",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ant-angel-med-fp8",
            "knowledge": null,
            "lastUpdated": "2026-01-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "AntAngelMed-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "any-pose",
            "knowledge": null,
            "lastUpdated": "2026-01-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "AnyPose",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "anythingto-real-characters",
            "knowledge": null,
            "lastUpdated": "2025-12-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "AnythingtoRealCharacters",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "anyto-3-dfigure-v-2",
            "knowledge": null,
            "lastUpdated": "2025-12-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Anyto3DfigureV2",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "arunk-25-qwen-image-edit-rapid-aio-gguf",
            "knowledge": null,
            "lastUpdated": "2026-01-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Arunk25-Qwen-Image-Edit-Rapid-AIO-GGUF",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "auto-glm-phone-9b",
            "knowledge": null,
            "lastUpdated": "2025-12-09",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "AutoGLM-Phone-9B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "auto-glm-phone-9b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-12-18",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "AutoGLM-Phone-9B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "auto-glm-phone-9b-multilingual",
            "knowledge": null,
            "lastUpdated": "2025-12-09",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "AutoGLM-Phone-9B-Multilingual",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "aw-portrait-z",
            "knowledge": null,
            "lastUpdated": "2025-12-14",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "AWPortrait-Z",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bagel-7b-mo-t",
            "knowledge": null,
            "lastUpdated": "2025-12-09",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "BAGEL-7B-MoT",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "baichuan-2-13b-chat",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Baichuan2-13B-Chat",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-09-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "baichuan-2-7b-chat",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Baichuan2-7B-Chat",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-09-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "baichuan-m2-32b",
            "knowledge": null,
            "lastUpdated": "2025-12-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Baichuan-M2-32B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "baichuan-m2-32b-gptq-int-4",
            "knowledge": null,
            "lastUpdated": "2025-08-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Baichuan-M2-32B-GPTQ-Int4",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bce-embedding-base-v-1",
            "knowledge": null,
            "lastUpdated": "2024-03-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "bce-embedding-base_v1",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-01-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bce-reranker-base-v-1",
            "knowledge": null,
            "lastUpdated": "2024-11-14",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "bce-reranker-base_v1",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-01-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bert-base-chinese",
            "knowledge": null,
            "lastUpdated": "2025-08-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "bert-base-chinese",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-11-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bert-base-uncased",
            "knowledge": null,
            "lastUpdated": "2023-10-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "bert-base-uncased",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-09-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "beyond-reality-z-image",
            "knowledge": null,
            "lastUpdated": "2025-12-31",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "BEYOND_REALITY_Z_IMAGE",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bfs-best-face-swap",
            "knowledge": null,
            "lastUpdated": "2026-01-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "BFS-Best-Face-Swap",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bge-base-zh-v-1-5",
            "knowledge": null,
            "lastUpdated": "2024-09-13",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "bge-base-zh-v1.5",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bge-large-zh",
            "knowledge": null,
            "lastUpdated": "2023-08-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "bge-large-zh",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-08-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bge-large-zh-v-1-5",
            "knowledge": null,
            "lastUpdated": "2024-01-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "bge-large-zh-v1.5",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-01-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bge-m-3",
            "knowledge": null,
            "lastUpdated": "2024-09-14",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "bge-m3",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bge-reranker-large",
            "knowledge": null,
            "lastUpdated": "2024-09-13",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "bge-reranker-large",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bge-reranker-v-2-m-3",
            "knowledge": null,
            "lastUpdated": "2024-09-13",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "bge-reranker-v2-m3",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bge-small-zh-v-1-5",
            "knowledge": null,
            "lastUpdated": "2024-11-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "bge-small-zh-v1.5",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bi-ref-net",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "BiRefNet",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-08-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "blip2-chinese",
            "knowledge": null,
            "lastUpdated": "2023-08-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "BLIP2-Chinese",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-08-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bounce-high-wan-2-2",
            "knowledge": null,
            "lastUpdated": "2025-12-31",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "BounceHighWan2_2",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "breast-q-wen-2512",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "breastQWen2512",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "chandra",
            "knowledge": null,
            "lastUpdated": "2025-10-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "chandra",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "chat-glm-6b",
            "knowledge": null,
            "lastUpdated": "2023-12-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ChatGLM-6B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-03-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "chat-law-text-2-vec",
            "knowledge": null,
            "lastUpdated": "2023-10-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ChatLaw-Text2Vec",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-10-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "chat-tts",
            "knowledge": null,
            "lastUpdated": "2024-10-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ChatTTS",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-06-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "chat-tts-model-scope",
            "knowledge": null,
            "lastUpdated": "2024-06-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ChatTTS-ModelScope",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-06-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "chatglm-2-6-b",
            "knowledge": null,
            "lastUpdated": "2023-10-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "chatglm2-6b",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-06-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "chatglm-3-6-b",
            "knowledge": null,
            "lastUpdated": "2025-05-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "chatglm3-6b",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-10-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "chatglm-3-6-b-base",
            "knowledge": null,
            "lastUpdated": "2023-11-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "chatglm3-6b-base",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-10-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "chenkin-noob-xl-v0-1",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "ChenkinNoob-XL-V0.1",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "chenkin-noob-xl-v0-2",
            "knowledge": null,
            "lastUpdated": "2025-12-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "ChenkinNoob-XL-V0.2",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "chinese-clip-vit-base-patch-16",
            "knowledge": null,
            "lastUpdated": "2024-10-10",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "chinese-clip-vit-base-patch16",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-10-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "chinese-roberta-wwm-ext-large",
            "knowledge": null,
            "lastUpdated": "2025-08-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "chinese-roberta-wwm-ext-large",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "chinese-wav-2-vec-2-base",
            "knowledge": null,
            "lastUpdated": "2025-08-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "chinese-wav2vec2-base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "chroma-1-hd-repackaged",
            "knowledge": null,
            "lastUpdated": "2025-12-31",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image"]
            },
            "name": "Chroma1-HD_repackaged",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ckpt-sd-1-5-anime",
            "knowledge": null,
            "lastUpdated": "2025-03-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "ckpt_sd1.5_anime",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "claude-4-5-sonnet-thinking-stackexchange-overflow-32-ep-32-k-traces",
            "knowledge": null,
            "lastUpdated": "2025-12-09",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "claude-4-5-sonnet-thinking-stackexchange-overflow-32ep-32k-traces",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-12-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "clearer-voice-studio",
            "knowledge": null,
            "lastUpdated": "2025-01-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ClearerVoice-Studio",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-12-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "clip-vi-t-h-14-laion-2-b-s-32-b-b-79-k",
            "knowledge": null,
            "lastUpdated": "2025-01-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "CLIP-ViT-H-14-laion2B-s32B-b79K",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-10-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "clip-vi-t-h-14-laion-2-b-s-32-b-b-79-k-repackaged",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "CLIP-ViT-H-14-laion2B-s32B-b79K_repackaged",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "clip-vision-h",
            "knowledge": null,
            "lastUpdated": "2025-09-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "clip_vision_h",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "clip-vit-base-patch-32",
            "knowledge": null,
            "lastUpdated": "2025-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "clip-vit-base-patch32",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "clip-vit-large-patch-14",
            "knowledge": null,
            "lastUpdated": "2023-10-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "clip-vit-large-patch14",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-10-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "code-qwen-1-5-7b-chat",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "CodeQwen1.5-7B-Chat",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-04-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cog-video-x-1-5-5b-sat",
            "knowledge": null,
            "lastUpdated": "2024-11-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "CogVideoX1.5-5B-SAT",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-11-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cog-video-x-5-b",
            "knowledge": null,
            "lastUpdated": "2024-09-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "CogVideoX-5b",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-08-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cog-view-4-6b",
            "knowledge": null,
            "lastUpdated": "2025-03-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "CogView4-6B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-03-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "comfy-ui-notebook",
            "knowledge": null,
            "lastUpdated": "2024-06-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "ComfyUI_Notebook",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-01-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "comfy-ui-qwen-image",
            "knowledge": null,
            "lastUpdated": "2025-08-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "ComfyUI-Qwen-Image",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cosy-voice-2-0-5b",
            "knowledge": null,
            "lastUpdated": "2025-12-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "CosyVoice2-0.5B",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-12-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cosy-voice-2-0-5b-zhenghebao",
            "knowledge": null,
            "lastUpdated": "2025-06-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "CosyVoice2-0.5B-zhenghebao",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cosy-voice-300m",
            "knowledge": null,
            "lastUpdated": "2025-12-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "CosyVoice-300M",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-07-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cosy-voice-300m-instruct",
            "knowledge": null,
            "lastUpdated": "2025-12-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "CosyVoice-300M-Instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-07-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cosy-voice-300m-sft",
            "knowledge": null,
            "lastUpdated": "2025-12-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "CosyVoice-300M-SFT",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-07-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cosy-voice-ttsfrd",
            "knowledge": null,
            "lastUpdated": "2025-12-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "CosyVoice-ttsfrd",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-07-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-convnext-tiny-ocr-recognition-document-damo",
            "knowledge": null,
            "lastUpdated": "2023-11-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_convnextTiny_ocr-recognition-document_damo",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-convnext-tiny-ocr-recognition-general-damo",
            "knowledge": null,
            "lastUpdated": "2023-11-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_convnextTiny_ocr-recognition-general_damo",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-convnext-tiny-ocr-recognition-handwritten-damo",
            "knowledge": null,
            "lastUpdated": "2023-11-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_convnextTiny_ocr-recognition-handwritten_damo",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-convnext-tiny-ocr-recognition-licenseplate-damo",
            "knowledge": null,
            "lastUpdated": "2023-11-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_convnextTiny_ocr-recognition-licenseplate_damo",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-11-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-cspnet-video-object-detection-streamyolo",
            "knowledge": null,
            "lastUpdated": "2023-04-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_cspnet_video-object-detection_streamyolo",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-09-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-ddcolor-image-colorization",
            "knowledge": null,
            "lastUpdated": "2024-01-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "cv_ddcolor_image-colorization",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-12-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-ddsar-face-detection-iclr-23-damofd",
            "knowledge": null,
            "lastUpdated": "2023-08-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_ddsar_face-detection_iclr23-damofd",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-02-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-diffusion-text-to-image-synthesis",
            "knowledge": null,
            "lastUpdated": "2023-05-09",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "cv_diffusion_text-to-image-synthesis",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-09-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-dla-34-table-structure-recognition-cycle-centernet",
            "knowledge": null,
            "lastUpdated": "2022-12-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_dla34_table-structure-recognition_cycle-centernet",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-11-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-fft-inpainting-lama",
            "knowledge": null,
            "lastUpdated": "2023-03-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "cv_fft_inpainting_lama",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-09-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-gpen-image-portrait-enhancement",
            "knowledge": null,
            "lastUpdated": "2022-12-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "cv_gpen_image-portrait-enhancement",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-hrn-head-reconstruction",
            "knowledge": null,
            "lastUpdated": "2023-11-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_HRN_head-reconstruction",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-08-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-hrnetv-2-w-32-body-2-d-keypoints-image",
            "knowledge": null,
            "lastUpdated": "2024-10-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "cv_hrnetv2w32_body-2d-keypoints_image",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-hrnetw-48-human-wholebody-keypoint-image",
            "knowledge": null,
            "lastUpdated": "2023-05-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "cv_hrnetw48_human-wholebody-keypoint_image",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-09-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-ir-50-face-recognition-arcface",
            "knowledge": null,
            "lastUpdated": "2023-02-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_ir50_face-recognition_arcface",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-11-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-mobilenet-face-2-d-keypoints-alignment",
            "knowledge": null,
            "lastUpdated": "2023-06-13",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_mobilenet_face-2d-keypoints_alignment",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-res-net-c-3-d-action-detection-detection-2-d",
            "knowledge": null,
            "lastUpdated": "2023-05-10",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_ResNetC3D_action-detection_detection2d",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-resnest-101-general-recognition",
            "knowledge": null,
            "lastUpdated": "2022-10-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_resnest101_general_recognition",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-resnet-101-face-detection-cvpr-22-papermogface",
            "knowledge": null,
            "lastUpdated": "2023-02-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_resnet101_face-detection_cvpr22papermogface",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-resnet-18-card-correction",
            "knowledge": null,
            "lastUpdated": "2024-01-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_resnet18_card_correction",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-09-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-resnet-18-human-detection",
            "knowledge": null,
            "lastUpdated": "2024-10-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_resnet18_human-detection",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-resnet-18-ocr-detection-db-line-level-damo",
            "knowledge": null,
            "lastUpdated": "2023-10-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_resnet18_ocr-detection-db-line-level_damo",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-02-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-resnet-34-face-attribute-recognition-fairface",
            "knowledge": null,
            "lastUpdated": "2023-02-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_resnet34_face-attribute-recognition_fairface",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-11-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-resnet-50-face-detection-retinaface",
            "knowledge": null,
            "lastUpdated": "2023-02-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_resnet50_face-detection_retinaface",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-resnet-50-face-reconstruction",
            "knowledge": null,
            "lastUpdated": "2023-11-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_resnet50_face-reconstruction",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-01-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-retinafce-recognition",
            "knowledge": null,
            "lastUpdated": "2023-09-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_retinafce_recognition",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-09-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-stable-diffusion-v-2-image-inpainting-base",
            "knowledge": null,
            "lastUpdated": "2025-08-13",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "cv_stable-diffusion-v2_image-inpainting_base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-02-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-tinynas-head-detection-damoyolo",
            "knowledge": null,
            "lastUpdated": "2025-06-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_tinynas_head-detection_damoyolo",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-02-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-tinynas-human-detection-damoyolo",
            "knowledge": null,
            "lastUpdated": "2025-06-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_tinynas_human-detection_damoyolo",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-12-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-tinynas-object-detection-damoyolo",
            "knowledge": null,
            "lastUpdated": "2025-06-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "cv_tinynas_object-detection_damoyolo",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-10-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-tinynas-object-detection-damoyolo-cigarette",
            "knowledge": null,
            "lastUpdated": "2025-06-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_tinynas_object-detection_damoyolo_cigarette",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-12-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-tinynas-object-detection-damoyolo-safety-helmet",
            "knowledge": null,
            "lastUpdated": "2025-06-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_tinynas_object-detection_damoyolo_safety-helmet",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-12-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-u-2-net-salient-detection",
            "knowledge": null,
            "lastUpdated": "2022-10-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "cv_u2net_salient-detection",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-unet-image-face-fusion-damo",
            "knowledge": null,
            "lastUpdated": "2023-09-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "cv_unet-image-face-fusion_damo",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-01-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-unet-image-matting",
            "knowledge": null,
            "lastUpdated": "2023-10-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "cv_unet_image-matting",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-unet-person-image-cartoon-compound-models",
            "knowledge": null,
            "lastUpdated": "2023-04-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "cv_unet_person-image-cartoon_compound-models",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-unet-skin-retouching",
            "knowledge": null,
            "lastUpdated": "2023-08-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_unet_skin-retouching",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-unet-universal-matting",
            "knowledge": null,
            "lastUpdated": "2023-03-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_unet_universal-matting",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-01-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-vgg-19-facial-expression-recognition-fer",
            "knowledge": null,
            "lastUpdated": "2023-02-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "cv_vgg19_facial-expression-recognition_fer",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-vit-base-image-classification-dailylife-labels",
            "knowledge": null,
            "lastUpdated": "2023-03-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "cv_vit-base_image-classification_Dailylife-labels",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cv-vit-base-image-classification-image-net-labels",
            "knowledge": null,
            "lastUpdated": "2023-01-31",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "cv_vit-base_image-classification_ImageNet-labels",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-analyze-8b",
            "knowledge": null,
            "lastUpdated": "2025-10-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepAnalyze-8B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-math-v2",
            "knowledge": null,
            "lastUpdated": "2025-11-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-Math-V2",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-ocr",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "DeepSeek-OCR",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00075,
                "inputCacheHit": null,
                "output": 0.00099
            },
            "extendedThinking": false,
            "id": "deep-seek-r1",
            "knowledge": null,
            "lastUpdated": "2025-03-07",
            "limit": {
                "context": 163840,
                "output": 163840
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-r1-0528-bf16",
            "knowledge": null,
            "lastUpdated": "2025-07-14",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-0528-BF16",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00003,
                "inputCacheHit": null,
                "output": 0.00011
            },
            "extendedThinking": false,
            "id": "deep-seek-r1-0528-qwen-3-8b",
            "knowledge": null,
            "lastUpdated": "2025-05-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-0528-Qwen3-8B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-r1-0528-qwen-3-8b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-06-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-0528-Qwen3-8B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-r1-0528-w8a8",
            "knowledge": null,
            "lastUpdated": "2025-06-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-0528-W8A8",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-r1-0528-w8a8-mind-ie",
            "knowledge": null,
            "lastUpdated": "2025-07-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-0528-W8A8-MindIE",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-r1-distill-qwen-14b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-01-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-Distill-Qwen-14B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-r1-distill-qwen-1-5b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-04-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-Distill-Qwen-1.5B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-r1-distill-qwen-32b-awq",
            "knowledge": null,
            "lastUpdated": "2025-02-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-Distill-Qwen-32B-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-r1-distill-qwen-32b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-01-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-Distill-Qwen-32B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-r1-distill-qwen-7b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-01-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-Distill-Qwen-7B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-r1-gguf",
            "knowledge": null,
            "lastUpdated": "2025-02-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-R1-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-v2-chat",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V2-Chat",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-05-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-v2-lite",
            "knowledge": null,
            "lastUpdated": "2024-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V2-Lite",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-05-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00023,
                "inputCacheHit": null,
                "output": 0.0009
            },
            "extendedThinking": false,
            "id": "deep-seek-v3-1",
            "knowledge": null,
            "lastUpdated": "2025-08-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.1",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-v3-1-base",
            "knowledge": null,
            "lastUpdated": "2025-08-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.1-Base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-v3-1-bf16",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.1-BF16",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-v3-1-nex-n1",
            "knowledge": null,
            "lastUpdated": "2025-12-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.1-Nex-N1",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00023,
                "inputCacheHit": null,
                "output": 0.0009
            },
            "extendedThinking": false,
            "id": "deep-seek-v3-1-terminus",
            "knowledge": null,
            "lastUpdated": "2025-09-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.1-Terminus",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-v3-1-terminus-w-4-a-8-mtp-qua-rot",
            "knowledge": null,
            "lastUpdated": "2025-12-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.1-Terminus-w4a8-mtp-QuaRot",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00027,
                "inputCacheHit": null,
                "output": 0.0004
            },
            "extendedThinking": false,
            "id": "deep-seek-v3-2",
            "knowledge": null,
            "lastUpdated": "2025-12-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.2",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-v3-2-awq",
            "knowledge": null,
            "lastUpdated": "2025-12-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.2-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00027,
                "inputCacheHit": null,
                "output": 0.0004
            },
            "extendedThinking": false,
            "id": "deep-seek-v3-2-exp",
            "knowledge": null,
            "lastUpdated": "2025-11-18",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.2-Exp",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-v3-2-exp-base",
            "knowledge": null,
            "lastUpdated": "2025-09-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.2-Exp-Base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-v3-2-speciale",
            "knowledge": null,
            "lastUpdated": "2025-12-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.2-Speciale",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-v3-2-w8a8",
            "knowledge": null,
            "lastUpdated": "2025-12-18",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.2-W8A8",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deep-seek-v3-2-w-4-a-8",
            "knowledge": null,
            "lastUpdated": "2025-12-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.2-w4a8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0008,
                "inputCacheHit": null,
                "output": 0.0008
            },
            "extendedThinking": false,
            "id": "deepseek-coder-33-b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-coder-33b-instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-11-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek-coder-6-7-b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-coder-6.7b-instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-11-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek-llm-7-b-chat",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-llm-7b-chat",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-11-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek-r-1-distill-qwen-32-b-gptq-int-4",
            "knowledge": null,
            "lastUpdated": "2025-03-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek-r1-distill-qwen-32b-gptq-int4",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek-vl-2",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "deepseek-vl2",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-12-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek-vl-2-tiny",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "deepseek-vl2-tiny",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-12-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "dinov-3-vit-7-b-16-pretrain-lvd-1689-m",
            "knowledge": null,
            "lastUpdated": "2025-08-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "dinov3-vit7b16-pretrain-lvd1689m",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "dinov-3-vitb-16-pretrain-lvd-1689-m",
            "knowledge": null,
            "lastUpdated": "2025-08-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "dinov3-vitb16-pretrain-lvd1689m",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "dinov-3-vitl-16-pretrain-lvd-1689-m",
            "knowledge": null,
            "lastUpdated": "2025-08-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "dinov3-vitl16-pretrain-lvd1689m",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "dinov-3-vits-16-pretrain-lvd-1689-m",
            "knowledge": null,
            "lastUpdated": "2025-08-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "dinov3-vits16-pretrain-lvd1689m",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": 0.0009,
                "inputCacheHit": null,
                "output": 0.0009
            },
            "extendedThinking": false,
            "id": "dolphin",
            "knowledge": null,
            "lastUpdated": "2025-07-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Dolphin",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "dolphin-small",
            "knowledge": null,
            "lastUpdated": "2025-07-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "dolphin-small",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-03-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "dolphin-v-2",
            "knowledge": null,
            "lastUpdated": "2025-12-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Dolphin-v2",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "dots-ocr",
            "knowledge": null,
            "lastUpdated": "2025-11-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "dots.ocr",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "dots-vlm-1-inst",
            "knowledge": null,
            "lastUpdated": "2025-08-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "dots.vlm1.inst",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "dou-bao-flux",
            "knowledge": null,
            "lastUpdated": "2025-05-14",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "DouBaoFlux",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "doubao-1-5-embedding",
            "knowledge": null,
            "lastUpdated": "2025-05-13",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Doubao-1.5-Embedding",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "dream-shaper-8",
            "knowledge": null,
            "lastUpdated": "2024-11-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "DreamShaper_8",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-11-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "duguang-ocr-onnx",
            "knowledge": null,
            "lastUpdated": "2025-11-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "duguang-ocr-onnx",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-10-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "duguang-ocr-onnx-v-2",
            "knowledge": null,
            "lastUpdated": "2025-11-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "duguang-ocr-onnx-v2",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "duke-g-qwen-beauty-dim32-lo-ra-plus-1",
            "knowledge": null,
            "lastUpdated": "2026-01-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "DukeG_Qwen_Beauty_DIM32_LoRA_Plus1",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "duke-g-qwen-beauty-public-version",
            "knowledge": null,
            "lastUpdated": "2025-12-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "DukeG_Qwen_Beauty_Public_Version",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "duke-g-qwen-light-and-shadow-public",
            "knowledge": null,
            "lastUpdated": "2025-12-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "DukeG_Qwen_Light_And_Shadow_Public",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "echo-mimic-v-3",
            "knowledge": null,
            "lastUpdated": "2025-08-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "EchoMimicV3",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "emotion-2-vec-base-finetuned",
            "knowledge": null,
            "lastUpdated": "2024-03-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "emotion2vec_base_finetuned",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-01-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "emotion-2-vec-plus-base",
            "knowledge": null,
            "lastUpdated": "2024-06-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "emotion2vec_plus_base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-05-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "emotion-2-vec-plus-large",
            "knowledge": null,
            "lastUpdated": "2024-07-10",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "emotion2vec_plus_large",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-05-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ernie-4-5-0-3b-pt",
            "knowledge": null,
            "lastUpdated": "2025-12-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ERNIE-4.5-0.3B-PT",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ernie-4-5-vl-28b-a3b-paddle",
            "knowledge": null,
            "lastUpdated": "2025-07-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "ERNIE-4.5-VL-28B-A3B-Paddle",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ernie-4-5-vl-28b-a3b-pt",
            "knowledge": null,
            "lastUpdated": "2025-07-18",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "ERNIE-4.5-VL-28B-A3B-PT",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "ernie-4-5-vl-28b-a3b-thinking",
            "knowledge": null,
            "lastUpdated": "2025-11-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "ERNIE-4.5-VL-28B-A3B-Thinking",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-11-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "f5-tts",
            "knowledge": null,
            "lastUpdated": "2025-03-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "F5-TTS",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-10-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "f5-tts-emilia-zh-en",
            "knowledge": null,
            "lastUpdated": "2025-03-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "F5-TTS_Emilia-ZH-EN",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-10-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "faster-whisper-large-v-3-turbo",
            "knowledge": null,
            "lastUpdated": "2024-10-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "faster-whisper-large-v3-turbo",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-10-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "faster-whisper-small",
            "knowledge": null,
            "lastUpdated": "2024-03-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "faster-whisper-small",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-03-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "fire-red-asr-aed-l",
            "knowledge": null,
            "lastUpdated": "2025-09-18",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FireRedASR-AED-L",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "fish-speech-1-5",
            "knowledge": null,
            "lastUpdated": "2025-03-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "fish-speech-1.5",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-12-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "fix-bad-image-kontext-lora",
            "knowledge": null,
            "lastUpdated": "2025-08-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FixBadImage-KontextLora",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "florence-2-base",
            "knowledge": null,
            "lastUpdated": "2025-08-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Florence-2-base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-06-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "florence-2-large-prompt-gen-v-2-0",
            "knowledge": null,
            "lastUpdated": "2024-12-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Florence-2-large-PromptGen-v2.0",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-12-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-dev",
            "knowledge": null,
            "lastUpdated": "2025-06-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX.1-dev",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-12-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-dev-control-net-union-pro-2-0",
            "knowledge": null,
            "lastUpdated": "2025-04-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX.1-dev-ControlNet-Union-Pro-2.0",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-dev-fp-8-dit",
            "knowledge": null,
            "lastUpdated": "2025-07-31",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX.1-dev-fp8-dit",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-dev-gguf",
            "knowledge": null,
            "lastUpdated": "2024-09-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX.1-dev-gguf",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-08-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-fill-dev",
            "knowledge": null,
            "lastUpdated": "2025-06-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX.1-Fill-dev",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-11-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-fill-dev-gguf",
            "knowledge": null,
            "lastUpdated": "2025-01-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX.1-Fill-dev-GGUF",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-fill-dev-one-reward",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "flux.1-fill-dev-OneReward",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-kontext-dev",
            "knowledge": null,
            "lastUpdated": "2025-08-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX.1-Kontext-Dev",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-kontext-dev-fp-8",
            "knowledge": null,
            "lastUpdated": "2025-07-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "flux1-kontext-dev-fp8",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-kontext-dev-lora-art-aug",
            "knowledge": null,
            "lastUpdated": "2025-07-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX.1-Kontext-dev-lora-ArtAug",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-kontext-dev-lora-highresfix",
            "knowledge": null,
            "lastUpdated": "2025-07-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX.1-Kontext-dev-lora-highresfix",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-kontext-dev-lora-super-outpainting",
            "knowledge": null,
            "lastUpdated": "2025-07-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX.1-Kontext-dev-lora-SuperOutpainting",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-krea-dev",
            "knowledge": null,
            "lastUpdated": "2025-08-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX.1-Krea-dev",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-krea-dev-comfy-ui",
            "knowledge": null,
            "lastUpdated": "2025-08-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image"]
            },
            "name": "FLUX.1-Krea-dev_ComfyUI",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-krea-dev-gguf",
            "knowledge": null,
            "lastUpdated": "2025-07-31",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX.1-Krea-dev-GGUF",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-1-turbo-alpha",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX.1-Turbo-Alpha",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-10-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-2-dev-bnb-4-bit",
            "knowledge": null,
            "lastUpdated": "2025-11-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX.2-dev-bnb-4bit",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-2-dev-fp-8-scaled",
            "knowledge": null,
            "lastUpdated": "2025-12-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX.2-dev-fp8_scaled",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-2-dev-gguf",
            "knowledge": null,
            "lastUpdated": "2025-11-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX.2-dev-gguf",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-2-dev-nvfp4",
            "knowledge": null,
            "lastUpdated": "2026-01-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX.2-dev-NVFP4",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-2-dev-turbo",
            "knowledge": null,
            "lastUpdated": "2025-12-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX.2-dev-Turbo",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-high-res",
            "knowledge": null,
            "lastUpdated": "2025-06-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "flux-high-res",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-realistic-pure-desire-beautiful-girl-v-1-0",
            "knowledge": null,
            "lastUpdated": "2025-07-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX-Realistic-Pure-Desire-Beautiful-Girl-v1.0",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-text-encoders",
            "knowledge": null,
            "lastUpdated": "2024-11-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "flux_text_encoders",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-vae",
            "knowledge": null,
            "lastUpdated": "2024-10-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "flux_vae",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-10-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "flux-xiao-hong-shu-ji-zhi-zhen-shi-v2",
            "knowledge": null,
            "lastUpdated": "2025-03-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "FLUX_xiao_hong_shu_ji_zhi_zhen_shi_V2",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "fst-itn-zh",
            "knowledge": null,
            "lastUpdated": "2023-09-14",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "fst_itn_zh",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-08-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "fun-asr-mlt-nano-2512",
            "knowledge": null,
            "lastUpdated": "2025-12-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Fun-ASR-MLT-Nano-2512",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "fun-asr-nano-2512",
            "knowledge": null,
            "lastUpdated": "2026-01-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Fun-ASR-Nano-2512",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "fun-asr-nano-onnx",
            "knowledge": null,
            "lastUpdated": "2026-01-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FunASR-nano-onnx",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "fun-asr-nano-onnx-v2",
            "knowledge": null,
            "lastUpdated": "2025-12-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FunASR-nano-onnx-V2",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "fun-audio-chat-8b",
            "knowledge": null,
            "lastUpdated": "2025-12-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Fun-Audio-Chat-8B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "fun-cosy-voice-3-0-5b-2512",
            "knowledge": null,
            "lastUpdated": "2025-12-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Fun-CosyVoice3-0.5B-2512",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "fun-cosy-voice-3-0-5b-2512-4-bit",
            "knowledge": null,
            "lastUpdated": "2025-12-18",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Fun-CosyVoice3-0.5B-2512-4bit",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "funasr-runtime-win-cpu-x-64",
            "knowledge": null,
            "lastUpdated": "2024-05-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "funasr-runtime-win-cpu-x64",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-12-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "fuxi-2",
            "knowledge": null,
            "lastUpdated": "2025-09-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "fuxi2",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ge-lab-zero-4b-preview",
            "knowledge": null,
            "lastUpdated": "2025-12-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "GELab-Zero-4B-preview",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemini-nano",
            "knowledge": null,
            "lastUpdated": "2024-06-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemini-nano",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-06-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00003,
                "inputCacheHit": null,
                "output": 0.0001
            },
            "extendedThinking": false,
            "id": "gemma-3-12-b-it",
            "knowledge": null,
            "lastUpdated": "2025-03-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gemma-3-12b-it",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-03-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemma-3-12-b-it-gguf",
            "knowledge": null,
            "lastUpdated": "2025-03-13",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gemma-3-12b-it-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-03-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemma-3-12-b-it-qat-q-4-0-unquantized",
            "knowledge": null,
            "lastUpdated": "2025-04-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gemma-3-12b-it-qat-q4_0-unquantized",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemma-3-1-b-it",
            "knowledge": null,
            "lastUpdated": "2025-04-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemma-3-1b-it",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-03-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gemma-3-270-m",
            "knowledge": null,
            "lastUpdated": "2025-08-14",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gemma-3-270m",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00009,
                "inputCacheHit": null,
                "output": 0.00016
            },
            "extendedThinking": false,
            "id": "gemma-3-27-b-it",
            "knowledge": null,
            "lastUpdated": "2025-03-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gemma-3-27b-it",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-03-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000170301,
                "inputCacheHit": null,
                "output": 0.0000681536
            },
            "extendedThinking": false,
            "id": "gemma-3-4-b-it",
            "knowledge": null,
            "lastUpdated": "2025-04-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gemma-3-4b-it",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00002,
                "inputCacheHit": null,
                "output": 0.00004
            },
            "extendedThinking": false,
            "id": "gemma-3-n-e4b-it",
            "knowledge": null,
            "lastUpdated": "2025-07-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gemma-3n-E4B-it",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "genos-10b",
            "knowledge": null,
            "lastUpdated": "2025-12-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Genos-10B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "genos-megatron-10b",
            "knowledge": null,
            "lastUpdated": "2025-10-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Genos-Megatron-10B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-1v-9b-base",
            "knowledge": null,
            "lastUpdated": "2025-07-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.1V-9B-Base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000035,
                "inputCacheHit": null,
                "output": 0.000138
            },
            "extendedThinking": true,
            "id": "glm-4-1v-9b-thinking",
            "knowledge": null,
            "lastUpdated": "2025-10-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.1V-9B-Thinking",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-06-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "glm-4-1v-9b-thinking-gguf",
            "knowledge": null,
            "lastUpdated": "2025-07-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "GLM-4.1V-9B-Thinking-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-07-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-5-air-fp8",
            "knowledge": null,
            "lastUpdated": "2025-08-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.5-Air-FP8",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-5-air-gguf",
            "knowledge": null,
            "lastUpdated": "2025-08-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.5-Air-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-5-awq",
            "knowledge": null,
            "lastUpdated": "2025-07-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.5-AWQ",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-5-fp8",
            "knowledge": null,
            "lastUpdated": "2025-08-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.5-FP8",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-5-gguf",
            "knowledge": null,
            "lastUpdated": "2025-08-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.5-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0006,
                "inputCacheHit": null,
                "output": 0.0018
            },
            "extendedThinking": false,
            "id": "glm-4-5v",
            "knowledge": null,
            "lastUpdated": "2025-08-18",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "GLM-4.5V",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-5v-awq",
            "knowledge": null,
            "lastUpdated": "2025-08-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "GLM-4.5V-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-5v-fp8",
            "knowledge": null,
            "lastUpdated": "2025-08-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "GLM-4.5V-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0005,
                "inputCacheHit": null,
                "output": 0.00175
            },
            "extendedThinking": false,
            "id": "glm-4-6",
            "knowledge": null,
            "lastUpdated": "2025-12-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.6",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-6-fp8",
            "knowledge": null,
            "lastUpdated": "2025-10-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.6-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-6v",
            "knowledge": null,
            "lastUpdated": "2025-12-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "GLM-4.6V",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-6v-flash",
            "knowledge": null,
            "lastUpdated": "2025-12-09",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "GLM-4.6V-Flash",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-6v-flash-gguf",
            "knowledge": null,
            "lastUpdated": "2025-12-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "GLM-4.6V-Flash-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-6v-fp8",
            "knowledge": null,
            "lastUpdated": "2025-12-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "GLM-4.6V-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-7",
            "knowledge": null,
            "lastUpdated": "2025-12-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.7",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-7-awq",
            "knowledge": null,
            "lastUpdated": "2025-12-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.7-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-7-fp8",
            "knowledge": null,
            "lastUpdated": "2025-12-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.7-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-7-gguf",
            "knowledge": null,
            "lastUpdated": "2025-12-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.7-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-7-gptq-int-4-int-8-mix",
            "knowledge": null,
            "lastUpdated": "2025-12-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.7-GPTQ-Int4-Int8Mix",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-7-w8a8",
            "knowledge": null,
            "lastUpdated": "2025-12-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.7-W8A8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-9-b",
            "knowledge": null,
            "lastUpdated": "2024-08-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "glm-4-9b",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-06-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-9-b-chat",
            "knowledge": null,
            "lastUpdated": "2025-01-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "glm-4-9b-chat",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-06-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-9-b-chat-1-m",
            "knowledge": null,
            "lastUpdated": "2024-08-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "glm-4-9b-chat-1m",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-06-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-9b-0414",
            "knowledge": null,
            "lastUpdated": "2025-04-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4-9B-0414",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-v-9-b",
            "knowledge": null,
            "lastUpdated": "2024-08-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "glm-4v-9b",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-06-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-4-voice-tokenizer",
            "knowledge": null,
            "lastUpdated": "2024-10-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "glm-4-voice-tokenizer",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-10-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-asr-nano-2512",
            "knowledge": null,
            "lastUpdated": "2025-12-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-ASR-Nano-2512",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "glm-tts",
            "knowledge": null,
            "lastUpdated": "2025-12-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-TTS",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gme-qwen-2-vl-2b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-09-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gme-Qwen2-VL-2B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-12-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gme-qwen-2-vl-7b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-09-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "gme-Qwen2-VL-7B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-12-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gpt-2",
            "knowledge": null,
            "lastUpdated": "2025-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt2",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0001,
                "inputCacheHit": null,
                "output": 0.0001
            },
            "extendedThinking": false,
            "id": "gpt-oss-120-b",
            "knowledge": null,
            "lastUpdated": "2025-08-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-oss-120b",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gpt-oss-120-b-bf16",
            "knowledge": null,
            "lastUpdated": "2025-08-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-oss-120b-BF16",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gpt-oss-120-b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-08-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-oss-120b-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0001,
                "inputCacheHit": null,
                "output": 0.0001
            },
            "extendedThinking": false,
            "id": "gpt-oss-20-b",
            "knowledge": null,
            "lastUpdated": "2025-08-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-oss-20b",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gpt-oss-20-b-bf16",
            "knowledge": null,
            "lastUpdated": "2025-08-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-oss-20b-BF16",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gpt-oss-20-b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-12-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpt-oss-20b-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gpt-so-vits",
            "knowledge": null,
            "lastUpdated": "2025-06-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GPT-SoVITS",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-01-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gpt-so-vits-inference",
            "knowledge": null,
            "lastUpdated": "2025-11-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GPT-SoVITS-Inference",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gpt-so-vits-model-collection",
            "knowledge": null,
            "lastUpdated": "2025-11-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GPT-SoVITS_Model_Collection",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gpt-so-vits-v-2-pro-20250604",
            "knowledge": null,
            "lastUpdated": "2025-09-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GPT-SoVITS-v2pro-20250604",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gpu-course-lyt-0-6b",
            "knowledge": null,
            "lastUpdated": "2026-01-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gpu_course_lyt_0.6B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "grounding-dino",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GroundingDINO",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-05-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gte-qwen-2-1-5b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-06-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gte_Qwen2-1.5B-instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-07-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gte-qwen-2-7b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-06-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "gte_Qwen2-7B-instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-06-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gui-owl-32b",
            "knowledge": null,
            "lastUpdated": "2025-08-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "GUI-Owl-32B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gui-owl-7b",
            "knowledge": null,
            "lastUpdated": "2025-08-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "GUI-Owl-7B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "handwritten-poster",
            "knowledge": null,
            "lastUpdated": "2025-08-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Handwritten_poster",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "happy-llm-215m-base",
            "knowledge": null,
            "lastUpdated": "2025-06-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "happy-llm-215M-base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "higgs-audio-v-2-generation-3b-base",
            "knowledge": null,
            "lastUpdated": "2025-07-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "higgs-audio-v2-generation-3B-base",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "huihui-qwen-3-vl-4b-instruct-abliterated",
            "knowledge": null,
            "lastUpdated": "2025-10-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Huihui-Qwen3-VL-4B-Instruct-abliterated",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "huihui-qwen-3-vl-8b-instruct-abliterated",
            "knowledge": null,
            "lastUpdated": "2025-10-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Huihui-Qwen3-VL-8B-Instruct-abliterated",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hulu-med",
            "knowledge": null,
            "lastUpdated": "2025-12-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Hulu-Med",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hunyuan-0-5b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-08-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Hunyuan-0.5B-Instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hunyuan-1-8b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-08-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Hunyuan-1.8B-Instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hunyuan-3-d-2",
            "knowledge": null,
            "lastUpdated": "2025-10-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Hunyuan3D-2",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hunyuan-3-d-2-1",
            "knowledge": null,
            "lastUpdated": "2025-10-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Hunyuan3D-2.1",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hunyuan-4b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-08-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Hunyuan-4B-Instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hunyuan-7b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-08-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Hunyuan-7B-Instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00003,
                "inputCacheHit": null,
                "output": 0.00003
            },
            "extendedThinking": false,
            "id": "hunyuan-a13b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-07-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Hunyuan-A13B-Instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hunyuan-game-craft-1-0",
            "knowledge": null,
            "lastUpdated": "2025-08-14",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Hunyuan-GameCraft-1.0",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hunyuan-image-2-1",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "HunyuanImage-2.1",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hunyuan-image-3-0",
            "knowledge": null,
            "lastUpdated": "2025-10-14",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "HunyuanImage-3.0",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hunyuan-mt-7b",
            "knowledge": null,
            "lastUpdated": "2025-09-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Hunyuan-MT-7B",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hunyuan-mt-chimera-7b",
            "knowledge": null,
            "lastUpdated": "2025-09-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Hunyuan-MT-Chimera-7B",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hunyuan-ocr",
            "knowledge": null,
            "lastUpdated": "2025-11-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "HunyuanOCR",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hunyuan-video-1-5",
            "knowledge": null,
            "lastUpdated": "2025-12-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "HunyuanVideo-1.5",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hunyuan-video-1-5-repackaged",
            "knowledge": null,
            "lastUpdated": "2025-12-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image"]
            },
            "name": "HunyuanVideo_1.5_repackaged",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hunyuan-video-foley",
            "knowledge": null,
            "lastUpdated": "2025-09-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "HunyuanVideo-Foley",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hunyuan-world-1",
            "knowledge": null,
            "lastUpdated": "2025-07-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "HunyuanWorld-1",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hunyuan-world-voyager",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "HunyuanWorld-Voyager",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hy-motion-1-0",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "HY-Motion-1.0",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hy-mt1-5-1-8b",
            "knowledge": null,
            "lastUpdated": "2025-12-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "HY-MT1.5-1.8B",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hy-mt1-5-1-8b-fp8",
            "knowledge": null,
            "lastUpdated": "2025-12-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "HY-MT1.5-1.8B-FP8",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hy-mt1-5-1-8b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-12-31",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "HY-MT1.5-1.8B-GGUF",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hy-mt1-5-1-8b-gptq-int-4",
            "knowledge": null,
            "lastUpdated": "2025-12-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "HY-MT1.5-1.8B-GPTQ-Int4",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hy-mt1-5-7b",
            "knowledge": null,
            "lastUpdated": "2025-12-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "HY-MT1.5-7B",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hy-mt1-5-7b-fp8",
            "knowledge": null,
            "lastUpdated": "2025-12-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "HY-MT1.5-7B-FP8",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hy-mt1-5-7b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-12-31",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "HY-MT1.5-7B-GGUF",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hy-mt1-5-7b-gptq-int-4",
            "knowledge": null,
            "lastUpdated": "2025-12-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "HY-MT1.5-7B-GPTQ-Int4",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "hy-world-play",
            "knowledge": null,
            "lastUpdated": "2026-01-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "HY-WorldPlay",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "i-quest-coder-v1-40b-base",
            "knowledge": null,
            "lastUpdated": "2026-01-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "IQuest-Coder-V1-40B-Base",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "i-quest-coder-v1-40b-base-stage-1",
            "knowledge": null,
            "lastUpdated": "2026-01-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "IQuest-Coder-V1-40B-Base-Stage1",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "i-quest-coder-v1-40b-instruct",
            "knowledge": null,
            "lastUpdated": "2026-01-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "IQuest-Coder-V1-40B-Instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "i-quest-coder-v1-40b-instruct-4-bit",
            "knowledge": null,
            "lastUpdated": "2026-01-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "IQuest-Coder-V1-40B-Instruct-4bit",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "i-quest-coder-v1-40b-instruct-awq-4-bit",
            "knowledge": null,
            "lastUpdated": "2026-01-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "IQuest-Coder-V1-40B-Instruct-AWQ-4bit",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "i-quest-coder-v1-40b-loop-instruct",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "IQuest-Coder-V1-40B-Loop-Instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "i-quest-coder-v1-40b-loop-instruct-4-bit",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "IQuest-Coder-V1-40B-Loop-Instruct-4bit",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "i-quest-lab-i-quest-coder-v1-40b-instruct-gguf",
            "knowledge": null,
            "lastUpdated": "2026-01-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "IQuestLab.IQuest-Coder-V1-40B-Instruct-GGUF",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "illustrious-xl",
            "knowledge": null,
            "lastUpdated": "2025-08-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Illustrious-XL",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-03-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "image-to-video",
            "knowledge": null,
            "lastUpdated": "2023-12-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Image-to-Video",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-08-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "index-anisora",
            "knowledge": null,
            "lastUpdated": "2025-10-31",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Index-anisora",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "index-tts",
            "knowledge": null,
            "lastUpdated": "2025-04-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Index-TTS",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-03-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "index-tts-1-5",
            "knowledge": null,
            "lastUpdated": "2025-05-14",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "IndexTTS-1.5",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "index-tts-2",
            "knowledge": null,
            "lastUpdated": "2025-11-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "index-tts2",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "index-tts-2-v-llm",
            "knowledge": null,
            "lastUpdated": "2025-09-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "IndexTTS-2-vLLM",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "infinite-talk",
            "knowledge": null,
            "lastUpdated": "2025-09-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "InfiniteTalk",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "intern-s1",
            "knowledge": null,
            "lastUpdated": "2025-10-31",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Intern-S1",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "intern-s1-gguf",
            "knowledge": null,
            "lastUpdated": "2025-07-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Intern-S1-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "intern-vl-3-14b",
            "knowledge": null,
            "lastUpdated": "2025-05-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "InternVL3-14B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "intern-vl-3-1b",
            "knowledge": null,
            "lastUpdated": "2025-05-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "InternVL3-1B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "intern-vl-3-2b",
            "knowledge": null,
            "lastUpdated": "2025-05-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "InternVL3-2B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "intern-vl-3-5-1b",
            "knowledge": null,
            "lastUpdated": "2025-08-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "InternVL3_5-1B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "intern-vl-3-5-241b-a28b",
            "knowledge": null,
            "lastUpdated": "2025-08-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "InternVL3_5-241B-A28B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "intern-vl-3-5-8b",
            "knowledge": null,
            "lastUpdated": "2025-08-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "InternVL3_5-8B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "intern-vla-a1-3b",
            "knowledge": null,
            "lastUpdated": "2026-01-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "InternVLA-A1-3B",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0004,
                "inputCacheHit": null,
                "output": 0.0004
            },
            "extendedThinking": false,
            "id": "ip-adapter",
            "knowledge": null,
            "lastUpdated": "2024-04-10",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "IP-Adapter",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-04-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "janus-pro-7b",
            "knowledge": null,
            "lastUpdated": "2025-02-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Janus-Pro-7B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "jimeng",
            "knowledge": null,
            "lastUpdated": "2025-06-09",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "jimeng",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "jina-embeddings-v-3",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "jina-embeddings-v3",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "jina-embeddings-v-4",
            "knowledge": "Available",
            "lastUpdated": "2025-09-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "jina-embeddings-v4",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "jina-reranker-v-3",
            "knowledge": null,
            "lastUpdated": "2025-11-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "jina-reranker-v3",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "joy-caption-alpha-two",
            "knowledge": null,
            "lastUpdated": "2024-12-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "joy-caption-alpha-two",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-12-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "jt-da-8b",
            "knowledge": null,
            "lastUpdated": "2025-07-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "JT-DA-8B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "keqing-z-image-4",
            "knowledge": null,
            "lastUpdated": "2026-01-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "keqing_z_image_4",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "kfm-poster",
            "knowledge": null,
            "lastUpdated": "2025-08-13",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "KFM-poster",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "kimi-audio-7b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-05-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kimi-Audio-7B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "kimi-k2-base",
            "knowledge": null,
            "lastUpdated": "2025-07-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kimi-K2-Base",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "kimi-k2-instruct-0905",
            "knowledge": null,
            "lastUpdated": "2025-11-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kimi-K2-Instruct-0905",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "kimi-k2-instruct-gguf",
            "knowledge": null,
            "lastUpdated": "2025-07-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kimi-K2-Instruct-GGUF",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0006,
                "inputCacheHit": null,
                "output": 0.0025
            },
            "extendedThinking": true,
            "id": "kimi-k2-thinking",
            "knowledge": null,
            "lastUpdated": "2025-11-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kimi-K2-Thinking",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-11-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "kimi-linear-48b-a3b-instruct",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kimi-Linear-48B-A3B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "kimi-vl-a3b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-07-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Kimi-VL-A3B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "kimi-vl-a3b-thinking",
            "knowledge": null,
            "lastUpdated": "2025-06-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Kimi-VL-A3B-Thinking",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-04-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "kimi-vl-a3b-thinking-2506",
            "knowledge": null,
            "lastUpdated": "2025-08-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Kimi-VL-A3B-Thinking-2506",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-06-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "kitten-tts-nano-0-1",
            "knowledge": null,
            "lastUpdated": "2025-08-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "kitten-tts-nano-0.1",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "kokoro-82m-v-1-1-zh",
            "knowledge": null,
            "lastUpdated": "2025-03-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kokoro-82M-v1.1-zh",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "kook-qwen-2512-jzzs",
            "knowledge": null,
            "lastUpdated": "2026-01-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Kook_Qwen_2512_jzzs",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "kook-qwen-2512-qwxs-v2",
            "knowledge": null,
            "lastUpdated": "2026-01-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "KOOK_Qwen_2512_qwxs_V2",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "kook-qwen-2512-zshx",
            "knowledge": null,
            "lastUpdated": "2026-01-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Kook_Qwen_2512_Zshx",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "kook-qwen-2512-zshx-v2",
            "knowledge": null,
            "lastUpdated": "2026-01-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "KOOK_Qwen_2512_zshx_V2",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "kook-qwen-jizhizhenshi",
            "knowledge": null,
            "lastUpdated": "2025-11-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kook_Qwen_JIZHIZHENSHI",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "kook-qwen-zshx-v-2",
            "knowledge": null,
            "lastUpdated": "2025-11-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Kook_Qwen_zshx_v2",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "kook-xieshi-kook-qwen",
            "knowledge": null,
            "lastUpdated": "2025-11-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Kook_xieshi_Kook_Qwen",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "kook-xieshi-kook-qwen-v2",
            "knowledge": null,
            "lastUpdated": "2025-11-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kook_xieshi_Kook_Qwen_V2",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "kook-zimage-zshx-turbo",
            "knowledge": null,
            "lastUpdated": "2025-12-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Kook_Zimage_Zshx_Turbo",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "lenovo-ultra-real-z-image-turbo",
            "knowledge": null,
            "lastUpdated": "2025-12-09",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Lenovo_UltraReal_Z_Image_Turbo",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0004,
                "inputCacheHit": null,
                "output": 0.002
            },
            "extendedThinking": false,
            "id": "ling-1t",
            "knowledge": null,
            "lastUpdated": "2025-12-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Ling-1T",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ling-flash-2-0",
            "knowledge": null,
            "lastUpdated": "2025-12-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Ling-flash-2.0",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "linly-talker",
            "knowledge": null,
            "lastUpdated": "2024-08-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Linly-Talker",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-02-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "lite-avatar-gallery",
            "knowledge": null,
            "lastUpdated": "2025-06-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "LiteAvatarGallery",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-03-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-2-7-b",
            "knowledge": null,
            "lastUpdated": "2024-09-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "llama-2-7b",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-08-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-2-7-b-chat-hf",
            "knowledge": null,
            "lastUpdated": "2023-12-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama-2-7b-chat-hf",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-12-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "llama-2-7-b-hf",
            "knowledge": null,
            "lastUpdated": "2023-12-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama-2-7b-hf",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-12-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "llava-1-5-7-b-hf",
            "knowledge": null,
            "lastUpdated": "2025-06-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "llava-1.5-7b-hf",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-12-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "long-cat-image",
            "knowledge": null,
            "lastUpdated": "2025-12-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "LongCat-Image",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "long-cat-image-dev",
            "knowledge": null,
            "lastUpdated": "2025-12-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "LongCat-Image-Dev",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "long-cat-image-edit",
            "knowledge": null,
            "lastUpdated": "2025-12-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "LongCat-Image-Edit",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "long-cat-video",
            "knowledge": null,
            "lastUpdated": "2025-10-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "LongCat-Video",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "long-cat-video-avatar",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "LongCat-Video-Avatar",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "longlegs",
            "knowledge": null,
            "lastUpdated": "2025-04-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "longlegs",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "lora-rioko-kontext",
            "knowledge": null,
            "lastUpdated": "2025-07-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "lora_rioko_kontext",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ltx-2",
            "knowledge": null,
            "lastUpdated": "2026-01-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ltx-2",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ltx-video",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "LTX-Video",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "m-3-e-base",
            "knowledge": null,
            "lastUpdated": "2023-08-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "m3e-base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-08-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "magic-wan-image-v2",
            "knowledge": null,
            "lastUpdated": "2025-11-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Magic-Wan-Image-V2",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mai-ui-2b",
            "knowledge": null,
            "lastUpdated": "2026-01-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "MAI-UI-2B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mai-ui-8b",
            "knowledge": null,
            "lastUpdated": "2026-01-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "MAI-UI-8B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "majic-mix-realistic",
            "knowledge": null,
            "lastUpdated": "2025-03-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "majicMIX_realistic",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-12-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "majic-mix-realistic-maijuxieshi-sd-1-5",
            "knowledge": null,
            "lastUpdated": "2025-03-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "majicMIX_realistic_maijuxieshi_SD_1_5",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "majicbeauty-qwen-1",
            "knowledge": null,
            "lastUpdated": "2025-08-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "majicbeauty-qwen1",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "majicflus-v-1",
            "knowledge": null,
            "lastUpdated": "2025-03-13",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "majicflus_v1",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-12-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "matcha-tts-zh-en-20251010",
            "knowledge": null,
            "lastUpdated": "2025-12-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "matcha_tts_zh_en_20251010",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "medical-deep-seek-large-language-model",
            "knowledge": null,
            "lastUpdated": "2025-03-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Medical_DeepSeek_Large_Language_Model",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "medical-qwen-3-8b-large-language-model",
            "knowledge": null,
            "lastUpdated": "2025-05-09",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Medical_Qwen3_8B_Large_Language_Model",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mega-tts-3",
            "knowledge": null,
            "lastUpdated": "2025-04-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MegaTTS3",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-03-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mengzi-t-5-base",
            "knowledge": null,
            "lastUpdated": "2022-12-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mengzi-t5-base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-10-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00045,
                "inputCacheHit": null,
                "output": 0.00045
            },
            "extendedThinking": false,
            "id": "meta-llama-3-1-70b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta-Llama-3.1-70B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-07-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0001,
                "inputCacheHit": null,
                "output": 0.0001
            },
            "extendedThinking": false,
            "id": "meta-llama-3-1-8b",
            "knowledge": null,
            "lastUpdated": "2024-10-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta-Llama-3.1-8B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-07-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0001,
                "inputCacheHit": null,
                "output": 0.0001
            },
            "extendedThinking": false,
            "id": "meta-llama-3-1-8b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": 16384,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta-Llama-3.1-8B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-07-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama-3-8b",
            "knowledge": null,
            "lastUpdated": "2024-12-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta-Llama-3-8B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-04-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mgeo-backbone-chinese-base",
            "knowledge": null,
            "lastUpdated": "2023-08-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mgeo_backbone_chinese_base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mgeo-geographic-composition-analysis-chinese-base",
            "knowledge": null,
            "lastUpdated": "2025-12-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mgeo_geographic_composition_analysis_chinese_base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mgeo-geographic-elements-tagging-chinese-base",
            "knowledge": null,
            "lastUpdated": "2025-12-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mgeo_geographic_elements_tagging_chinese_base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mgeo-geographic-entity-alignment-chinese-base",
            "knowledge": null,
            "lastUpdated": "2025-12-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mgeo_geographic_entity_alignment_chinese_base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mgeo-geographic-textual-similarity-rerank-chinese-base",
            "knowledge": null,
            "lastUpdated": "2025-12-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mgeo_geographic_textual_similarity_rerank_chinese_base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mi-mo-7b-rl",
            "knowledge": null,
            "lastUpdated": "2025-06-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiMo-7B-RL",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mi-mo-audio-7b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-09-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiMo-Audio-7B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mi-mo-v2-flash",
            "knowledge": null,
            "lastUpdated": "2025-12-18",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiMo-V2-Flash",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mi-mo-v2-flash-base",
            "knowledge": null,
            "lastUpdated": "2025-12-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiMo-V2-Flash-Base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mi-mo-v2-flash-gguf",
            "knowledge": null,
            "lastUpdated": "2025-12-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiMo-V2-Flash-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mi-mo-vl-7b-rl",
            "knowledge": null,
            "lastUpdated": "2025-06-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "MiMo-VL-7B-RL",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mi-mo-vl-7b-rl-2508",
            "knowledge": null,
            "lastUpdated": "2025-08-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "MiMo-VL-7B-RL-2508",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "midashenglm-7-b",
            "knowledge": null,
            "lastUpdated": "2025-08-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "midashenglm-7b",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "miner-u-2-0-2505-0-9b",
            "knowledge": null,
            "lastUpdated": "2025-06-13",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MinerU2.0-2505-0.9B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "miner-u-2-5-2509-1-2b",
            "knowledge": null,
            "lastUpdated": "2025-09-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "MinerU2.5-2509-1.2B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "miner-u-html",
            "knowledge": null,
            "lastUpdated": "2025-12-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MinerU-HTML",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ming-lite-omni-1-5",
            "knowledge": null,
            "lastUpdated": "2025-07-18",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Ming-Lite-Omni-1.5",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mini-cpm-4-1-8b",
            "knowledge": null,
            "lastUpdated": "2025-10-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniCPM4.1-8B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mini-cpm-4-8b",
            "knowledge": null,
            "lastUpdated": "2025-06-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniCPM4-8B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mini-cpm-o-2-6",
            "knowledge": null,
            "lastUpdated": "2025-10-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "MiniCPM-o-2_6",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mini-cpm-v",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniCPM-V",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-01-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mini-cpm-v-2-6",
            "knowledge": null,
            "lastUpdated": "2025-06-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "MiniCPM-V-2_6",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mini-cpm-v-4",
            "knowledge": null,
            "lastUpdated": "2025-08-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "MiniCPM-V-4",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mini-cpm-v-4-5",
            "knowledge": null,
            "lastUpdated": "2025-12-18",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "MiniCPM-V-4_5",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mini-cpm-v-4-5-gguf",
            "knowledge": null,
            "lastUpdated": "2025-09-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "MiniCPM-V-4_5-gguf",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mini-cpm-v-4-5-int-4",
            "knowledge": null,
            "lastUpdated": "2025-09-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "MiniCPM-V-4_5-int4",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mini-cpm-v-4-gguf",
            "knowledge": null,
            "lastUpdated": "2025-08-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "MiniCPM-V-4-gguf",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mini-max-m2",
            "knowledge": null,
            "lastUpdated": "2025-12-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniMax-M2",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mini-max-m2-1",
            "knowledge": null,
            "lastUpdated": "2025-12-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniMax-M2.1",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mini-max-m2-1-awq",
            "knowledge": null,
            "lastUpdated": "2025-12-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniMax-M2.1-AWQ",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mini-max-m2-1-awq-4-bit",
            "knowledge": null,
            "lastUpdated": "2025-12-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniMax-M2.1-AWQ-4bit",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mini-max-m2-1-gguf",
            "knowledge": null,
            "lastUpdated": "2025-12-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniMax-M2.1-GGUF",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mini-mind-2",
            "knowledge": null,
            "lastUpdated": "2025-12-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniMind2",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mini-mind-2-py-torch",
            "knowledge": null,
            "lastUpdated": "2025-10-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniMind2-PyTorch",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ministral-3-14b-instruct-2512",
            "knowledge": null,
            "lastUpdated": "2025-12-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Ministral-3-14B-Instruct-2512",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "miro-thinker-v-1-5-235b",
            "knowledge": null,
            "lastUpdated": "2026-01-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiroThinker-v1.5-235B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "miro-thinker-v-1-5-30b",
            "knowledge": null,
            "lastUpdated": "2026-01-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiroThinker-v1.5-30B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "monkey-ocr",
            "knowledge": null,
            "lastUpdated": "2025-08-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "MonkeyOCR",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mplug-image-captioning-coco-base-zh",
            "knowledge": null,
            "lastUpdated": "2025-12-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "mplug_image-captioning_coco_base_zh",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-10-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "multi-modal-chinese-stable-diffusion-v-1-0",
            "knowledge": null,
            "lastUpdated": "2023-11-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "multi-modal_chinese_stable_diffusion_v1.0",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-01-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "multi-modal-clip-vit-base-patch-16-zh",
            "knowledge": null,
            "lastUpdated": "2023-09-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "multi-modal_clip-vit-base-patch16_zh",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "multi-modal-clip-vit-huge-patch-14-zh",
            "knowledge": null,
            "lastUpdated": "2023-09-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "multi-modal_clip-vit-huge-patch14_zh",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-10-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "multi-modal-clip-vit-large-patch-14-336-zh",
            "knowledge": null,
            "lastUpdated": "2023-09-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "multi-modal_clip-vit-large-patch14_336_zh",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-09-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "multi-modal-clip-vit-large-patch-14-zh",
            "knowledge": null,
            "lastUpdated": "2023-09-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "multi-modal_clip-vit-large-patch14_zh",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "multi-modal-convnext-roberta-base-vldoc-embedding",
            "knowledge": null,
            "lastUpdated": "2025-06-13",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "multi-modal_convnext-roberta-base_vldoc-embedding",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-12-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "multi-modal-hitea-video-captioning-base-en",
            "knowledge": null,
            "lastUpdated": "2023-01-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "multi-modal_hitea_video-captioning_base_en",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-11-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "multi-modal-team-vit-large-patch-14-multi-modal-similarity",
            "knowledge": null,
            "lastUpdated": "2022-10-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "multi-modal_team-vit-large-patch14_multi-modal-similarity",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mv001",
            "knowledge": null,
            "lastUpdated": "2025-03-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "MV001",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-03-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mw-hanfu",
            "knowledge": null,
            "lastUpdated": "2025-08-10",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "MW-hanfu",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "nanbeige-4-3b-thinking-2511",
            "knowledge": null,
            "lastUpdated": "2025-12-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nanbeige4-3B-Thinking-2511",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-12-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nano-banana-pro",
            "knowledge": null,
            "lastUpdated": "2025-12-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "nano-banana-pro",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nano-banana-trending-disassemble-clothes-one-click-generation",
            "knowledge": null,
            "lastUpdated": "2025-12-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Nano-Banana_Trending_Disassemble_Clothes_One-Click-Generation",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nanonets-ocr-s",
            "knowledge": null,
            "lastUpdated": "2025-06-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Nanonets-OCR-s",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nanqiao-mote-z-image-turbo-tongyi-mai-v-1-0",
            "knowledge": null,
            "lastUpdated": "2026-01-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "nanqiao-mote-Z-Image-Turbo-Tongyi-MAI-v1.0",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nemotron-3-nano-30b-a3b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-12-31",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nemotron-3-Nano-30B-A3B-GGUF",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "neutts-air",
            "knowledge": null,
            "lastUpdated": "2025-10-10",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "neutts-air",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "new-bie-image-exp-0-1",
            "knowledge": null,
            "lastUpdated": "2025-12-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "NewBie-image-Exp0.1",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "new-bie-image-exp-0-1-repackaged",
            "knowledge": null,
            "lastUpdated": "2025-12-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "NewBie-image-Exp0.1_repackaged",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "next-scene-qwen-image-lora-2509",
            "knowledge": null,
            "lastUpdated": "2025-10-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "next-scene-qwen-image-lora-2509",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nike",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "nike",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nlp-bart-text-error-correction-chinese",
            "knowledge": null,
            "lastUpdated": "2023-03-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nlp_bart_text-error-correction_chinese",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nlp-bert-document-segmentation-chinese-base",
            "knowledge": null,
            "lastUpdated": "2025-12-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nlp_bert_document-segmentation_chinese-base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nlp-convai-text-2-sql-pretrain-cn",
            "knowledge": null,
            "lastUpdated": "2023-02-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nlp_convai_text2sql_pretrain_cn",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nlp-corom-sentence-embedding-chinese-base-ecom",
            "knowledge": "Available",
            "lastUpdated": "2025-12-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nlp_corom_sentence-embedding_chinese-base-ecom",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nlp-deberta-rex-uninlu-chinese-base",
            "knowledge": null,
            "lastUpdated": "2025-09-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nlp_deberta_rex-uninlu_chinese-base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-11-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nlp-gte-sentence-embedding-chinese-base",
            "knowledge": "Available",
            "lastUpdated": "2025-12-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nlp_gte_sentence-embedding_chinese-base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-10-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nlp-gte-sentence-embedding-chinese-large",
            "knowledge": null,
            "lastUpdated": "2025-06-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nlp_gte_sentence-embedding_chinese-large",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-10-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nlp-language-identification-classification-base",
            "knowledge": null,
            "lastUpdated": "2023-02-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nlp_language_identification-classification-base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-02-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nlp-maoe-named-entity-recognition-chinese-base-general",
            "knowledge": null,
            "lastUpdated": "2023-04-09",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nlp_maoe_named-entity-recognition_chinese-base-general",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-02-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nlp-mt-5-zero-shot-augment-chinese-base",
            "knowledge": null,
            "lastUpdated": "2025-12-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nlp_mt5_zero-shot-augment_chinese-base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-01-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nlp-polylm-13-b-text-generation",
            "knowledge": null,
            "lastUpdated": "2025-06-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nlp_polylm_13b_text_generation",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-07-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nlp-polylm-qwen-7-b-text-generation",
            "knowledge": null,
            "lastUpdated": "2024-04-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nlp_polylm_qwen_7b_text_generation",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-08-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nlp-raner-named-entity-recognition-chinese-base-cmeee",
            "knowledge": null,
            "lastUpdated": "2025-12-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nlp_raner_named-entity-recognition_chinese-base-cmeee",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nlp-raner-named-entity-recognition-chinese-base-ecom-50-cls",
            "knowledge": null,
            "lastUpdated": "2023-11-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nlp_raner_named-entity-recognition_chinese-base-ecom-50cls",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-09-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nlp-structbert-backbone-base-std",
            "knowledge": null,
            "lastUpdated": "2022-11-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nlp_structbert_backbone_base_std",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nlp-structbert-emotion-classification-chinese-base",
            "knowledge": null,
            "lastUpdated": "2023-08-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nlp_structbert_emotion-classification_chinese-base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-12-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nlp-structbert-outbound-intention-chinese-tiny",
            "knowledge": null,
            "lastUpdated": "2022-10-18",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nlp_structbert_outbound-intention_chinese-tiny",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-09-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nlp-structbert-sentiment-classification-chinese-base",
            "knowledge": null,
            "lastUpdated": "2024-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nlp_structbert_sentiment-classification_chinese-base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nlp-structbert-siamese-uie-chinese-base",
            "knowledge": null,
            "lastUpdated": "2025-12-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nlp_structbert_siamese-uie_chinese-base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-02-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nlp-structbert-siamese-uninlu-chinese-base",
            "knowledge": null,
            "lastUpdated": "2025-12-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nlp_structbert_siamese-uninlu_chinese-base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-02-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nlp-structbert-word-segmentation-chinese-base-ecommerce",
            "knowledge": null,
            "lastUpdated": "2025-08-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nlp_structbert_word-segmentation_chinese-base-ecommerce",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nunchaku",
            "knowledge": null,
            "lastUpdated": "2025-07-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "nunchaku",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nunchaku-flux-1-dev",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "nunchaku-flux.1-dev",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nunchaku-flux-1-kontext-dev",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "nunchaku-flux.1-kontext-dev",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nunchaku-flux-1-krea-dev",
            "knowledge": null,
            "lastUpdated": "2025-08-14",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "nunchaku-flux.1-krea-dev",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nunchaku-qwen-image",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "nunchaku-qwen-image",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nunchaku-qwen-image-edit",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "nunchaku-qwen-image-edit",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nunchaku-qwen-image-edit-2509",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "nunchaku-qwen-image-edit-2509",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nunchaku-z-image-turbo",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "nunchaku-z-image-turbo",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nuwa-script",
            "knowledge": null,
            "lastUpdated": "2025-09-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nuwa-script",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nvidia-nemotron-3-nano-30b-a3b-bf16",
            "knowledge": null,
            "lastUpdated": "2026-01-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "NVIDIA-Nemotron-3-Nano-30B-A3B-BF16",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nvzhuangdalao",
            "knowledge": null,
            "lastUpdated": "2025-12-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nvzhuangdalao",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ocr-flux-3b",
            "knowledge": null,
            "lastUpdated": "2025-07-09",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "OCRFlux-3B",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ofa-image-caption-coco-large-en",
            "knowledge": null,
            "lastUpdated": "2025-06-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "ofa_image-caption_coco_large_en",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ofa-image-caption-muge-base-zh",
            "knowledge": null,
            "lastUpdated": "2025-06-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "ofa_image-caption_muge_base_zh",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-09-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ofa-ocr-recognition-handwriting-base-zh",
            "knowledge": null,
            "lastUpdated": "2025-06-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ofa_ocr-recognition_handwriting_base_zh",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-11-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ofa-visual-grounding-refcoco-large-zh",
            "knowledge": null,
            "lastUpdated": "2025-12-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ofa_visual-grounding_refcoco_large_zh",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "ollama",
            "knowledge": null,
            "lastUpdated": "2025-09-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ollama",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "ollama-ipex-llm",
            "knowledge": null,
            "lastUpdated": "2025-04-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ollama-ipex-llm",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "ollama-linux",
            "knowledge": null,
            "lastUpdated": "2025-12-10",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ollama-linux",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-06-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "omni-gen-2",
            "knowledge": null,
            "lastUpdated": "2025-07-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OmniGen2",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "one-ke",
            "knowledge": null,
            "lastUpdated": "2024-05-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OneKE",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-04-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "open-sora-2-0",
            "knowledge": null,
            "lastUpdated": "2025-07-14",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenSora2.0",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai-clip-vit-large-patch-14",
            "knowledge": null,
            "lastUpdated": "2024-08-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "openai-clip-vit-large-patch14",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-08-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openaudio-s-1-mini",
            "knowledge": null,
            "lastUpdated": "2025-06-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "openaudio-s1-mini",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "paddle-ocr-vl",
            "knowledge": null,
            "lastUpdated": "2025-11-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "PaddleOCR-VL",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "paddle-ocr-vl-receipt",
            "knowledge": null,
            "lastUpdated": "2025-12-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "PaddleOCR-VL-Receipt",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "paraphrase-multilingual-mini-lm-l12-v-2",
            "knowledge": null,
            "lastUpdated": "2025-04-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "paraphrase-multilingual-MiniLM-L12-v2",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-11-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "pdf-extract-kit",
            "knowledge": null,
            "lastUpdated": "2024-10-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "PDF-Extract-Kit",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-07-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "pdf-extract-kit-1-0",
            "knowledge": null,
            "lastUpdated": "2025-10-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "PDF-Extract-Kit-1.0",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-10-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "pelican-1-0-vl-7b",
            "knowledge": null,
            "lastUpdated": "2025-12-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Pelican1.0-VL-7B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "persona-live",
            "knowledge": null,
            "lastUpdated": "2025-12-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "PersonaLive",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "phi-3-mini-4-k-instruct",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Phi-3-mini-4k-instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-04-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00006,
                "inputCacheHit": null,
                "output": 0.00014
            },
            "extendedThinking": false,
            "id": "phi-4",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "phi-4",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "pi-0",
            "knowledge": null,
            "lastUpdated": "2025-09-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "pi0",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "pixel-art-style-lora-z-image-turbo",
            "knowledge": null,
            "lastUpdated": "2025-11-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "pixel_art_style_lora_z_image_turbo",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "pony-realistic-pure-desire-beauty-sdxl-v-1-0",
            "knowledge": null,
            "lastUpdated": "2025-06-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Pony_Realistic-Pure-Desire-Beauty-SDXL_v1.0",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "pp-doc-layout-v-2",
            "knowledge": null,
            "lastUpdated": "2025-10-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "PP-DocLayoutV2",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "pp-ocrv-5-server",
            "knowledge": null,
            "lastUpdated": "2025-06-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "pp-ocrv5-server",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "prompt-clue",
            "knowledge": null,
            "lastUpdated": "2023-04-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "PromptCLUE",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-11-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "punc-ct-transformer-cn-en-common-vocab-471067-large",
            "knowledge": null,
            "lastUpdated": "2024-02-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "punc_ct-transformer_cn-en-common-vocab471067-large",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-07-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "punc-ct-transformer-zh-cn-common-vad-realtime-vocab-272727-onnx",
            "knowledge": null,
            "lastUpdated": "2024-09-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "punc_ct-transformer_zh-cn-common-vad_realtime-vocab272727-onnx",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-08-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "punc-ct-transformer-zh-cn-common-vocab-272727-pytorch",
            "knowledge": null,
            "lastUpdated": "2024-12-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "punc_ct-transformer_zh-cn-common-vocab272727-pytorch",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-01-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "python-data-science",
            "knowledge": null,
            "lastUpdated": "2025-08-13",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "python-data-science",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qvq-72b-preview",
            "knowledge": null,
            "lastUpdated": "2025-01-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "QVQ-72B-Preview",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-12-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00003,
                "inputCacheHit": null,
                "output": 0.00011
            },
            "extendedThinking": false,
            "id": "qw-q-32b",
            "knowledge": null,
            "lastUpdated": "2025-03-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "QwQ-32B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-03-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qw-q-32b-awq",
            "knowledge": null,
            "lastUpdated": "2025-03-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "QwQ-32B-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-03-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qw-q-32b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-03-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "QwQ-32B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-03-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0001,
                "inputCacheHit": null,
                "output": 0.0001
            },
            "extendedThinking": false,
            "id": "qwen-1-5-0-5b-chat",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen1.5-0.5B-Chat",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-02-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0001,
                "inputCacheHit": null,
                "output": 0.0001
            },
            "extendedThinking": false,
            "id": "qwen-1-5-1-8b-chat",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen1.5-1.8B-Chat",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-02-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0002,
                "inputCacheHit": null,
                "output": 0.0002
            },
            "extendedThinking": false,
            "id": "qwen-1-5-7b-chat",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen1.5-7B-Chat",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-02-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-1-8b-chat",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen-1_8B-Chat",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-11-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-0-5b",
            "knowledge": null,
            "lastUpdated": "2025-04-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2-0.5B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-05-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-0-5b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2-0.5B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-06-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-1-5b",
            "knowledge": null,
            "lastUpdated": "2025-04-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2-1.5B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-05-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-0-5b",
            "knowledge": null,
            "lastUpdated": "2024-09-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-0.5B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-0-5b-instruct-gguf",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-0.5B-Instruct-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-14b-instruct-1m",
            "knowledge": null,
            "lastUpdated": "2025-01-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-14B-Instruct-1M",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-32b-instruct-awq",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-32B-Instruct-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-3b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-3B-Instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-3b-instruct-gguf",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-3B-Instruct-GGUF",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-3b-instruct-gpu",
            "knowledge": null,
            "lastUpdated": "2026-01-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-3B-Instruct-GPU",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-72b-instruct-awq",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-72B-Instruct-AWQ",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-7b-instruct-awq",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-7B-Instruct-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-7b-instruct-gguf",
            "knowledge": null,
            "lastUpdated": "2024-11-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5-7B-Instruct-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-omni-3b",
            "knowledge": null,
            "lastUpdated": "2025-04-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Omni-3B",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-omni-7b",
            "knowledge": null,
            "lastUpdated": "2025-04-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Omni-7B",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-03-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-omni-7b-awq",
            "knowledge": null,
            "lastUpdated": "2025-05-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2.5-Omni-7B-AWQ",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-vl-32b-instruct-awq",
            "knowledge": null,
            "lastUpdated": "2025-04-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2.5-VL-32B-Instruct-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-03-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-vl-3b-instruct-awq",
            "knowledge": null,
            "lastUpdated": "2025-04-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2.5-VL-3B-Instruct-AWQ",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-vl-72b-instruct-awq",
            "knowledge": null,
            "lastUpdated": "2025-04-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2.5-VL-72B-Instruct-AWQ",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-vl-7-b-fp-8-scaled-safetensors",
            "knowledge": null,
            "lastUpdated": "2025-12-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-vl-7b-instruct-awq",
            "knowledge": null,
            "lastUpdated": "2025-04-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2.5-VL-7B-Instruct-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-vl-7b-instruct-gguf",
            "knowledge": null,
            "lastUpdated": "2025-05-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen2.5-VL-7B-Instruct-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-5-vl-ocr-lora-7b",
            "knowledge": null,
            "lastUpdated": "2025-08-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "qwen2.5-VL-OCR-lora-7B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-7b",
            "knowledge": null,
            "lastUpdated": "2025-04-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2-7B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-06-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-audio-7b",
            "knowledge": null,
            "lastUpdated": "2024-11-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2-Audio-7B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-07-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-2-audio-7b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-01-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2-Audio-7B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-08-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-0-6b-base",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-0.6B-Base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-0-6b-fp8",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-0.6B-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-0-6b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-06-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-0.6B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-0-6b-gptq-int-8",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-0.6B-GPTQ-Int8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-0-6b-gpu-basic",
            "knowledge": null,
            "lastUpdated": "2025-12-31",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-0.6B-GPU-basic",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-0-6b-gpu-basic-mlx",
            "knowledge": null,
            "lastUpdated": "2025-12-31",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-0.6B-GPU-basic-MLX",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-0-6b-instruct-2512",
            "knowledge": null,
            "lastUpdated": "2025-12-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-0.6B-Instruct-2512",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-0-6b-tts",
            "knowledge": null,
            "lastUpdated": "2025-09-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-0.6B-TTS",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-14b-awq",
            "knowledge": null,
            "lastUpdated": "2025-05-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-14B-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-14b-base",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-14B-Base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-14b-fp8",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-14B-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.002,
                "inputCacheHit": null,
                "output": 0.012
            },
            "extendedThinking": false,
            "id": "qwen-3-14b-gemini-3-pro-preview-high-reasoning-distill-gguf",
            "knowledge": null,
            "lastUpdated": "2025-12-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-14B-Gemini-3-Pro-Preview-High-Reasoning-Distill-GGUF",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-12-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-14b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-05-09",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-14B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-1-7b-base",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-1.7B-Base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-1-7b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-05-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-1.7B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-1-7b-mt-en-2-zh-gungeon-gguf",
            "knowledge": null,
            "lastUpdated": "2025-07-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-1.7B-MT-en2zh-Gungeon-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-1-7b-multilingual-tts",
            "knowledge": null,
            "lastUpdated": "2025-11-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-1.7B-Multilingual-TTS",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-235b-a22b-fp8",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-235B-A22B-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-235b-a22b-gptq-int-4",
            "knowledge": null,
            "lastUpdated": "2025-05-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-235B-A22B-GPTQ-Int4",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-235b-a22b-instruct-2507-awq",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-235B-A22B-Instruct-2507-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-235b-a22b-instruct-2507-fp8",
            "knowledge": null,
            "lastUpdated": "2025-07-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-235B-A22B-Instruct-2507-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-235b-a22b-instruct-2507-gguf",
            "knowledge": null,
            "lastUpdated": "2025-07-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-235B-A22B-Instruct-2507-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-235b-a22b-thinking-2507-awq",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-235B-A22B-Thinking-2507-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-07-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-235b-a22b-thinking-2507-fp8",
            "knowledge": null,
            "lastUpdated": "2025-07-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-235B-A22B-Thinking-2507-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-07-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-235b-a22b-w8a8",
            "knowledge": null,
            "lastUpdated": "2025-12-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-235B-A22B-W8A8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-30b-a3b-awq",
            "knowledge": null,
            "lastUpdated": "2025-05-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-30B-A3B-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-30b-a3b-base",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-30B-A3B-Base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-30b-a3b-fp4",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-30B-A3B-FP4",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-30b-a3b-fp8",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-30B-A3B-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-30b-a3b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-05-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-30B-A3B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-30b-a3b-gptq-int-4",
            "knowledge": null,
            "lastUpdated": "2025-05-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-30B-A3B-GPTQ-Int4",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-30b-a3b-instruct-2507-awq",
            "knowledge": null,
            "lastUpdated": "2025-08-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-30B-A3B-Instruct-2507-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-30b-a3b-instruct-2507-fp8",
            "knowledge": null,
            "lastUpdated": "2025-09-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-30B-A3B-Instruct-2507-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-30b-a3b-instruct-2507-gguf",
            "knowledge": null,
            "lastUpdated": "2025-07-31",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-30B-A3B-Instruct-2507-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-30b-a3b-instruct-2507-gptq-int-8",
            "knowledge": null,
            "lastUpdated": "2025-07-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-30B-A3B-Instruct-2507-GPTQ-Int8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-30b-a3b-instruct-2507-int-4-w4a16",
            "knowledge": null,
            "lastUpdated": "2025-07-31",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-30B-A3B-Instruct-2507-Int4-W4A16",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-30b-a3b-thinking-2507-awq",
            "knowledge": null,
            "lastUpdated": "2025-07-31",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-30B-A3B-Thinking-2507-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-07-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-30b-a3b-thinking-2507-fp8",
            "knowledge": null,
            "lastUpdated": "2025-07-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-30B-A3B-Thinking-2507-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-07-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-30b-a3b-thinking-2507-gguf",
            "knowledge": null,
            "lastUpdated": "2025-08-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-30B-A3B-Thinking-2507-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-07-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-32b-awq",
            "knowledge": null,
            "lastUpdated": "2025-05-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-32B-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-32b-fp8",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-32B-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-32b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-05-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-32B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-32b-gptq-int-4",
            "knowledge": null,
            "lastUpdated": "2025-05-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-32B-GPTQ-Int4",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-32b-gptq-int-8",
            "knowledge": null,
            "lastUpdated": "2025-04-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-32B-GPTQ-Int8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-4b-awq",
            "knowledge": null,
            "lastUpdated": "2025-05-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-4B-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-4b-base",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-4B-Base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-4b-fp8",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-4B-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-4b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-06-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-4B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-4b-instruct-2507",
            "knowledge": null,
            "lastUpdated": "2025-09-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-4B-Instruct-2507",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-4b-instruct-2507-fp8",
            "knowledge": null,
            "lastUpdated": "2025-09-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-4B-Instruct-2507-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-4b-instruct-2507-gguf",
            "knowledge": null,
            "lastUpdated": "2025-08-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-4B-Instruct-2507-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-4b-thinking-2507",
            "knowledge": null,
            "lastUpdated": "2025-08-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-4B-Thinking-2507",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-08-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-4b-thinking-2507-fp8",
            "knowledge": null,
            "lastUpdated": "2025-08-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-4B-Thinking-2507-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-08-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-4b-thinking-2507-gguf",
            "knowledge": null,
            "lastUpdated": "2025-08-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-4B-Thinking-2507-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-08-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-72b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-06-13",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-72B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-8b-awq",
            "knowledge": null,
            "lastUpdated": "2025-05-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-8B-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-8b-base",
            "knowledge": null,
            "lastUpdated": "2025-05-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-8B-Base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-8b-deep-seek-v-3-2-speciale-distill-gguf",
            "knowledge": null,
            "lastUpdated": "2025-12-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-8B-DeepSeek-v3.2-Speciale-Distill-GGUF",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-8b-fp8",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-8B-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-8b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-06-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-8B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-8b-gptq-int-4",
            "knowledge": null,
            "lastUpdated": "2025-09-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-8B-GPTQ-Int4",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-8b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-11-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-8B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-8b-unsloth-bnb-4-bit",
            "knowledge": null,
            "lastUpdated": "2025-05-14",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-8B-unsloth-bnb-4bit",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-coder-30b-a3b-instruct-1m-gguf",
            "knowledge": null,
            "lastUpdated": "2025-08-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Coder-30B-A3B-Instruct-1M-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-coder-30b-a3b-instruct-awq",
            "knowledge": null,
            "lastUpdated": "2025-08-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Coder-30B-A3B-Instruct-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-coder-30b-a3b-instruct-fp8",
            "knowledge": null,
            "lastUpdated": "2025-12-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Coder-30B-A3B-Instruct-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-coder-30b-a3b-instruct-gguf",
            "knowledge": null,
            "lastUpdated": "2025-08-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Coder-30B-A3B-Instruct-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-coder-30b-a3b-instruct-int-4-w4a16",
            "knowledge": null,
            "lastUpdated": "2025-08-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Coder-30B-A3B-Instruct-Int4-W4A16",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-08-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-coder-480b-a35b-instruct-1m-gguf",
            "knowledge": null,
            "lastUpdated": "2025-07-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Coder-480B-A35B-Instruct-1M-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-coder-480b-a35b-instruct-fp8",
            "knowledge": null,
            "lastUpdated": "2025-08-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Coder-480B-A35B-Instruct-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-coder-480b-a35b-instruct-gguf",
            "knowledge": null,
            "lastUpdated": "2025-08-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Coder-480B-A35B-Instruct-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-embedding-0-6-b",
            "knowledge": null,
            "lastUpdated": "2025-08-09",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "qwen3-embedding-0.6b",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-embedding-0-6b",
            "knowledge": null,
            "lastUpdated": "2025-06-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Embedding-0.6B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-embedding-0-6b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-07-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Embedding-0.6B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-embedding-4b",
            "knowledge": null,
            "lastUpdated": "2025-06-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Embedding-4B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-embedding-4b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-08-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Embedding-4B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-embedding-8b",
            "knowledge": null,
            "lastUpdated": "2025-08-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Embedding-8B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-embedding-8b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-07-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Embedding-8B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-guard-gen-0-6b",
            "knowledge": null,
            "lastUpdated": "2025-11-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3Guard-Gen-0.6B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-guard-gen-4b",
            "knowledge": null,
            "lastUpdated": "2025-11-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3Guard-Gen-4B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-guard-gen-8b",
            "knowledge": null,
            "lastUpdated": "2025-11-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3Guard-Gen-8B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-guard-stream-8b",
            "knowledge": null,
            "lastUpdated": "2025-11-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3Guard-Stream-8B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0001,
                "inputCacheHit": null,
                "output": 0.0008
            },
            "extendedThinking": false,
            "id": "qwen-3-next-80b-a3b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-09-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Next-80B-A3B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-next-80b-a3b-instruct-awq-4-bit",
            "knowledge": null,
            "lastUpdated": "2025-11-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Next-80B-A3B-Instruct-AWQ-4bit",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-next-80b-a3b-instruct-fp8",
            "knowledge": null,
            "lastUpdated": "2025-09-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Next-80B-A3B-Instruct-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-next-80b-a3b-instruct-gguf",
            "knowledge": null,
            "lastUpdated": "2025-12-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Next-80B-A3B-Instruct-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00014,
                "inputCacheHit": null,
                "output": 0.0012
            },
            "extendedThinking": true,
            "id": "qwen-3-next-80b-a3b-thinking",
            "knowledge": null,
            "lastUpdated": "2025-12-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Next-80B-A3B-Thinking",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-09-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-next-80b-a3b-thinking-fp8",
            "knowledge": null,
            "lastUpdated": "2025-09-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Next-80B-A3B-Thinking-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-09-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-next-80b-a3b-thinking-gguf",
            "knowledge": null,
            "lastUpdated": "2025-12-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Next-80B-A3B-Thinking-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-12-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-omni-30b-a3b-captioner",
            "knowledge": null,
            "lastUpdated": "2025-09-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-Omni-30B-A3B-Captioner",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-omni-30b-a3b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-09-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-Omni-30B-A3B-Instruct",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-omni-30b-a3b-instruct-awq-4-bit",
            "knowledge": null,
            "lastUpdated": "2025-09-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-Omni-30B-A3B-Instruct-AWQ-4bit",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-omni-30b-a3b-thinking",
            "knowledge": null,
            "lastUpdated": "2025-09-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-Omni-30B-A3B-Thinking",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-09-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-reranker-0-6b",
            "knowledge": null,
            "lastUpdated": "2025-08-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Reranker-0.6B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-reranker-4b",
            "knowledge": null,
            "lastUpdated": "2025-08-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Reranker-4B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-reranker-8b",
            "knowledge": null,
            "lastUpdated": "2025-08-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-Reranker-8B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0012
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-235b-a22b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-11-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-235B-A22B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-235b-a22b-instruct-awq",
            "knowledge": null,
            "lastUpdated": "2025-10-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-235B-A22B-Instruct-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-235b-a22b-instruct-fp8",
            "knowledge": null,
            "lastUpdated": "2025-11-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-235B-A22B-Instruct-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0012
            },
            "extendedThinking": true,
            "id": "qwen-3-vl-235b-a22b-thinking",
            "knowledge": null,
            "lastUpdated": "2025-11-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-235B-A22B-Thinking",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-09-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-vl-235b-a22b-thinking-fp8",
            "knowledge": null,
            "lastUpdated": "2025-11-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-235B-A22B-Thinking-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-10-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-2b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-10-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-2B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-2b-instruct-fp8",
            "knowledge": null,
            "lastUpdated": "2025-10-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-2B-Instruct-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-2b-instruct-gguf",
            "knowledge": null,
            "lastUpdated": "2025-11-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-2B-Instruct-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-vl-2b-thinking",
            "knowledge": null,
            "lastUpdated": "2025-10-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-2B-Thinking",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-10-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-vl-2b-thinking-fp8",
            "knowledge": null,
            "lastUpdated": "2025-11-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-2B-Thinking-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-10-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0002,
                "inputCacheHit": null,
                "output": 0.0007
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-30b-a3b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-11-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-30B-A3B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-30b-a3b-instruct-awq",
            "knowledge": null,
            "lastUpdated": "2025-10-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-30B-A3B-Instruct-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-30b-a3b-instruct-fp8",
            "knowledge": null,
            "lastUpdated": "2025-11-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-30B-A3B-Instruct-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-30b-a3b-instruct-gguf",
            "knowledge": null,
            "lastUpdated": "2025-11-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-30B-A3B-Instruct-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0002,
                "inputCacheHit": null,
                "output": 0.001
            },
            "extendedThinking": true,
            "id": "qwen-3-vl-30b-a3b-thinking",
            "knowledge": null,
            "lastUpdated": "2025-11-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-30B-A3B-Thinking",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-09-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-vl-30b-a3b-thinking-fp8",
            "knowledge": null,
            "lastUpdated": "2025-11-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-30B-A3B-Thinking-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-10-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-vl-30b-a3b-thinking-gguf",
            "knowledge": null,
            "lastUpdated": "2026-01-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-30B-A3B-Thinking-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-10-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-32b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-10-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-32B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-32b-instruct-awq",
            "knowledge": null,
            "lastUpdated": "2025-10-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-32B-Instruct-AWQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-32b-instruct-fp8",
            "knowledge": null,
            "lastUpdated": "2025-10-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-32B-Instruct-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-32b-instruct-gguf",
            "knowledge": null,
            "lastUpdated": "2025-11-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-32B-Instruct-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-vl-32b-thinking",
            "knowledge": null,
            "lastUpdated": "2025-10-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-32B-Thinking",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-10-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-vl-32b-thinking-fp8",
            "knowledge": null,
            "lastUpdated": "2025-11-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-32B-Thinking-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-10-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-vl-32b-thinking-gguf",
            "knowledge": null,
            "lastUpdated": "2025-11-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-32B-Thinking-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-10-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-4b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-10-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-4B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-4b-instruct-fp8",
            "knowledge": null,
            "lastUpdated": "2025-10-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-4B-Instruct-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-4b-instruct-gguf",
            "knowledge": null,
            "lastUpdated": "2025-11-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-4B-Instruct-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-vl-4b-thinking",
            "knowledge": null,
            "lastUpdated": "2025-10-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-4B-Thinking",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-10-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-vl-4b-thinking-gguf",
            "knowledge": null,
            "lastUpdated": "2025-11-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-4B-Thinking-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-10-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-8-b-instruct-abliterated-cv",
            "knowledge": null,
            "lastUpdated": "2025-12-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "qwen3-vl-8b-instruct-abliterated-CV",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00008,
                "inputCacheHit": null,
                "output": 0.0005
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-8b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-10-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-8B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-8b-instruct-4-bit-gptq",
            "knowledge": null,
            "lastUpdated": "2025-11-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-8B-Instruct-4bit-GPTQ",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-8b-instruct-abliterated",
            "knowledge": null,
            "lastUpdated": "2025-10-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-8B-Instruct-abliterated",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-8b-instruct-awq-4-bit",
            "knowledge": null,
            "lastUpdated": "2025-10-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-8B-Instruct-AWQ-4bit",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-8b-instruct-fp8",
            "knowledge": null,
            "lastUpdated": "2025-10-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-8B-Instruct-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-3-vl-8b-instruct-gguf",
            "knowledge": null,
            "lastUpdated": "2025-10-31",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-8B-Instruct-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00018,
                "inputCacheHit": null,
                "output": 0.0021
            },
            "extendedThinking": true,
            "id": "qwen-3-vl-8b-thinking",
            "knowledge": null,
            "lastUpdated": "2025-10-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-8B-Thinking",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-10-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-vl-8b-thinking-fp8",
            "knowledge": null,
            "lastUpdated": "2025-10-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-8B-Thinking-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-10-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "qwen-3-vl-8b-thinking-gguf",
            "knowledge": null,
            "lastUpdated": "2025-11-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen3-VL-8B-Thinking-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-10-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-72b-chat",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen-72B-Chat",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-11-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-7b",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen-7B",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-08-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-7b-chat",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen-7B-Chat",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-08-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-audio",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen-Audio",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-11-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-audio-chat",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen-Audio-Chat",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-11-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-breasts-edit-1-0",
            "knowledge": null,
            "lastUpdated": "2025-11-09",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-breastsEdit-1.0",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-edit-2509-multiple-angles",
            "knowledge": null,
            "lastUpdated": "2025-11-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Edit-2509-Multiple-angles",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-edit-anything-2-real-alpha",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "QwenEdit-Anything2Real_Alpha",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image",
            "knowledge": null,
            "lastUpdated": "2025-08-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-image",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-2512",
            "knowledge": null,
            "lastUpdated": "2025-12-31",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-2512",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-2512-6-bit",
            "knowledge": null,
            "lastUpdated": "2026-01-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-2512-6bit",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-2512-anime",
            "knowledge": null,
            "lastUpdated": "2026-01-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-image-2512-Anime",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-2512-fp8",
            "knowledge": null,
            "lastUpdated": "2026-01-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-2512-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-2512-fusion-lo-ra-by-remile",
            "knowledge": null,
            "lastUpdated": "2026-01-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-2512-FusionLoRA-ByRemile",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-2512-gguf",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-2512-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-2512-lightning",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-2512-Lightning",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-2512-pixel-art-lo-ra",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-2512-Pixel-Art-LoRA",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-2512-turbo-lo-ra",
            "knowledge": null,
            "lastUpdated": "2026-01-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-2512-Turbo-LoRA",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-blockwise-control-net-canny",
            "knowledge": null,
            "lastUpdated": "2025-08-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-Blockwise-ControlNet-Canny",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-blockwise-control-net-depth",
            "knowledge": null,
            "lastUpdated": "2025-08-13",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-Blockwise-ControlNet-Depth",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-blockwise-control-net-inpaint",
            "knowledge": null,
            "lastUpdated": "2025-08-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-Blockwise-ControlNet-Inpaint",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-comfy-ui",
            "knowledge": null,
            "lastUpdated": "2026-01-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image_ComfyUI",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-control-net-inpainting",
            "knowledge": null,
            "lastUpdated": "2025-09-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Image-ControlNet-Inpainting",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-control-net-union",
            "knowledge": null,
            "lastUpdated": "2025-08-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Image-ControlNet-Union",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-df11",
            "knowledge": null,
            "lastUpdated": "2025-08-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Image-DF11",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-distill-full",
            "knowledge": null,
            "lastUpdated": "2025-08-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-Distill-Full",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-distill-gguf",
            "knowledge": null,
            "lastUpdated": "2025-08-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-Distill-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-distill-lo-ra",
            "knowledge": null,
            "lastUpdated": "2025-08-18",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Image-Distill-LoRA",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-edit",
            "knowledge": null,
            "lastUpdated": "2025-09-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Image-Edit",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-edit-2509",
            "knowledge": null,
            "lastUpdated": "2025-09-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Image-Edit-2509",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-edit-2509-4-bit",
            "knowledge": null,
            "lastUpdated": "2025-12-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Image-Edit-2509-4bit",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-edit-2509-fp8",
            "knowledge": null,
            "lastUpdated": "2025-12-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen_Image_Edit_2509_FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-edit-2509-gguf",
            "knowledge": null,
            "lastUpdated": "2025-10-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Image-Edit-2509-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-edit-2509-lightning-8-steps-v1-0-bf-16",
            "knowledge": null,
            "lastUpdated": "2025-12-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Image-Edit-2509-Lightning-8steps-V1.0-bf16",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-edit-2511",
            "knowledge": null,
            "lastUpdated": "2025-12-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Image-Edit-2511",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-edit-2511-anime",
            "knowledge": null,
            "lastUpdated": "2026-01-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-Edit-2511-Anime",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-edit-2511-fp8",
            "knowledge": null,
            "lastUpdated": "2025-12-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Image-Edit-2511-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-edit-2511-gguf",
            "knowledge": null,
            "lastUpdated": "2025-12-31",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Image-Edit-2511-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-edit-2511-ic-edit-lo-ra",
            "knowledge": null,
            "lastUpdated": "2025-12-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-Edit-2511-ICEdit-LoRA",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-edit-2511-lightning",
            "knowledge": null,
            "lastUpdated": "2026-01-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-Edit-2511-Lightning",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-edit-2511-object-remover",
            "knowledge": null,
            "lastUpdated": "2026-01-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Image-Edit-2511-Object-Remover",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-edit-2511-sdnq-uint-4-svd-r-32",
            "knowledge": null,
            "lastUpdated": "2025-12-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Image-Edit-2511-SDNQ-uint4-svd-r32",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-edit-2511-upscale-2-k",
            "knowledge": null,
            "lastUpdated": "2025-12-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-Edit-2511-Upscale2K",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-edit-comfy-ui",
            "knowledge": null,
            "lastUpdated": "2025-12-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-Edit_ComfyUI",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-edit-comfy-ui-2511",
            "knowledge": null,
            "lastUpdated": "2025-12-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-Edit_ComfyUI_2511",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-edit-f2p",
            "knowledge": null,
            "lastUpdated": "2025-10-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-Edit-F2P",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-edit-gguf",
            "knowledge": null,
            "lastUpdated": "2025-08-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Image-Edit-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-edit-rapid-aio",
            "knowledge": null,
            "lastUpdated": "2025-10-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Image-Edit-Rapid-AIO",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-edit-remove-clothes",
            "knowledge": null,
            "lastUpdated": "2025-08-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-Edit-Remove-Clothes",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-eli-gen",
            "knowledge": null,
            "lastUpdated": "2025-08-13",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-EliGen",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-fp-8",
            "knowledge": null,
            "lastUpdated": "2025-08-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-image-fp8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-gguf",
            "knowledge": null,
            "lastUpdated": "2025-08-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-gguf",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-gufeng-lo-ra",
            "knowledge": null,
            "lastUpdated": "2025-08-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-Gufeng-LoRA",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-i-2-l",
            "knowledge": null,
            "lastUpdated": "2025-12-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-i2L",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-in-context-control-union",
            "knowledge": null,
            "lastUpdated": "2025-08-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-In-Context-Control-Union",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-instant-x-control-nets",
            "knowledge": null,
            "lastUpdated": "2025-09-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-InstantX-ControlNets",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-layered",
            "knowledge": null,
            "lastUpdated": "2025-12-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Image-Layered",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-layered-comfy-ui",
            "knowledge": null,
            "lastUpdated": "2025-12-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-Layered_ComfyUI",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-layered-fp8",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Image-Layered-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-layered-gguf",
            "knowledge": null,
            "lastUpdated": "2025-12-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Image-Layered-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-lightning",
            "knowledge": null,
            "lastUpdated": "2025-11-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-Lightning",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-lightning-8-steps-v1-1-bf-16",
            "knowledge": null,
            "lastUpdated": "2025-09-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Image-Lightning-8steps-V1.1-bf16",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-lightning-8-steps-v2-0-safetensors",
            "knowledge": null,
            "lastUpdated": "2025-09-13",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-Image-Lightning-8steps-V2.0.safetensors",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-liuyifei-lo-ra",
            "knowledge": null,
            "lastUpdated": "2025-08-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-Liuyifei-LoRA",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-lo-ra-art-aug-v-1",
            "knowledge": null,
            "lastUpdated": "2025-11-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-LoRA-ArtAug-v1",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-lora-3",
            "knowledge": null,
            "lastUpdated": "2025-08-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "qwen-image_lora-3",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-nude-pantyhose-lora",
            "knowledge": null,
            "lastUpdated": "2025-08-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen_image_nude_pantyhose_lora",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-realistic",
            "knowledge": null,
            "lastUpdated": "2025-12-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Image-Realistic",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-image-strapless-beauty-model-traffic-code-ins-douyin-xiaohongshu-kuaishou-portrait-photography-e-commerce",
            "knowledge": null,
            "lastUpdated": "2025-11-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen_Image_Strapless_Beauty_Model_Traffic_Code_INS_Douyin_Xiaohongshu_Kuaishou_Portrait_Photography_E_commerce",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-long-l1-32b",
            "knowledge": null,
            "lastUpdated": "2025-06-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "QwenLong-L1-32B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-05-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-long-l1-5-30b-a3b",
            "knowledge": null,
            "lastUpdated": "2025-12-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "QwenLong-L1.5-30B-A3B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-pretty-v-5",
            "knowledge": null,
            "lastUpdated": "2025-10-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "qwen.pretty.v5",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-rapid-aio",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Qwen-Rapid-AIO",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0008,
                "inputCacheHit": null,
                "output": 0.0032
            },
            "extendedThinking": false,
            "id": "qwen-vl",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-VL",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen-vl-chat",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen-VL-Chat",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "rapid-doc",
            "knowledge": null,
            "lastUpdated": "2025-12-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "RapidDoc",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "rapid-ocr",
            "knowledge": null,
            "lastUpdated": "2025-12-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "RapidOCR",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "rapid-table",
            "knowledge": null,
            "lastUpdated": "2025-06-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "RapidTable",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "real-esrgan-x-4-plus",
            "knowledge": null,
            "lastUpdated": "2024-08-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "RealESRGAN_x4plus",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-08-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "realistic-vision-v6-0-b1-sd-1-5",
            "knowledge": null,
            "lastUpdated": "2025-03-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Realistic_Vision_V6.0_B1_SD_1_5",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "red-craft-12-b-10-steps-fp16-aigc",
            "knowledge": null,
            "lastUpdated": "2025-03-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "RedCraft-12b-10steps-FP16-AIGC",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-11-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "redcraft-z-image",
            "knowledge": null,
            "lastUpdated": "2025-12-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "redcraft-z-image",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "rednote-sweet-girl",
            "knowledge": null,
            "lastUpdated": "2025-08-10",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Rednote_SweetGirl",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "rmbg-2-0",
            "knowledge": null,
            "lastUpdated": "2025-12-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "RMBG-2.0",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "robo-brain-2-0-7b",
            "knowledge": null,
            "lastUpdated": "2025-08-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "RoboBrain2.0-7B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "rvc-model",
            "knowledge": null,
            "lastUpdated": "2024-03-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "rvc-model",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-03-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "rvc-model-collection",
            "knowledge": null,
            "lastUpdated": "2025-05-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "RVC_Model_Collection",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "sadtalker",
            "knowledge": null,
            "lastUpdated": "2023-12-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "sadtalker",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-09-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "sam-3",
            "knowledge": null,
            "lastUpdated": "2025-11-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "sam3",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "sam-3-d-body-dinov-3",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "sam-3d-body-dinov3",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "sam-3-d-objects",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "sam-3d-objects",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "sam-audio-large",
            "knowledge": null,
            "lastUpdated": "2025-12-31",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "sam-audio-large",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "scail-preview",
            "knowledge": null,
            "lastUpdated": "2025-12-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "SCAIL-Preview",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "sd-35-clip-l",
            "knowledge": null,
            "lastUpdated": "2024-10-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "sd35_clip_l",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-10-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "sdxl-turbo",
            "knowledge": null,
            "lastUpdated": "2023-12-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "sdxl-turbo",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-11-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "sdxl-vae-fp-16-fix",
            "knowledge": null,
            "lastUpdated": "2025-05-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "sdxl-vae-fp16-fix",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-12-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "sec-gpt-14b",
            "knowledge": null,
            "lastUpdated": "2025-06-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "SecGPT-14B",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "see-see-21-z-image-turbo-aio",
            "knowledge": null,
            "lastUpdated": "2026-01-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "SeeSee21-Z-Image-Turbo-AIO",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "seed-oss-36b-instruct",
            "knowledge": null,
            "lastUpdated": "2025-08-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Seed-OSS-36B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "seed-vr-2-comfy-ui",
            "knowledge": null,
            "lastUpdated": "2025-08-14",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "SeedVR2_comfyUI",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "seed-vr-2-gguf",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "SeedVR2-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "seed-x-instruct-7b",
            "knowledge": null,
            "lastUpdated": "2025-07-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Seed-X-Instruct-7B",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "seed-x-ppo-7b",
            "knowledge": null,
            "lastUpdated": "2025-07-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Seed-X-PPO-7B",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "sense-voice-small",
            "knowledge": null,
            "lastUpdated": "2024-09-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "SenseVoiceSmall",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-06-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "sense-voice-small-hotword",
            "knowledge": null,
            "lastUpdated": "2024-12-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "SenseVoiceSmall_hotword",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-10-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "sense-voice-small-onnx",
            "knowledge": null,
            "lastUpdated": "2024-09-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "SenseVoiceSmall-onnx",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "sensevoice-small-onnx",
            "knowledge": null,
            "lastUpdated": "2025-08-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "sensevoice-small-onnx",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-07-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "sherpa",
            "knowledge": null,
            "lastUpdated": "2025-12-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "sherpa",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "sherpa-onnx-kws-zipformer-wenetspeech-3-3m-2024-01-01",
            "knowledge": null,
            "lastUpdated": "2024-01-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "sherpa-onnx-kws-zipformer-wenetspeech-3.3M-2024-01-01",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-01-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "sherpa-onnx-sense-voice-small",
            "knowledge": null,
            "lastUpdated": "2025-10-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "sherpa-onnx-sense-voice-small",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "siglip-2-base-patch-16-224",
            "knowledge": null,
            "lastUpdated": "2025-04-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "siglip2-base-patch16-224",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "siglip-2-so-400-m-patch-16-512",
            "knowledge": null,
            "lastUpdated": "2025-04-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "siglip2-so400m-patch16-512",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "silero-vad",
            "knowledge": null,
            "lastUpdated": "2025-02-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "silero-vad",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "silero-vad-onnx",
            "knowledge": null,
            "lastUpdated": "2025-09-14",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "silero-vad-onnx",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-04-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "simple-vl-8b",
            "knowledge": null,
            "lastUpdated": "2025-05-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Simple-VL-8B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "skill-examples",
            "knowledge": null,
            "lastUpdated": "2025-11-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "skill_examples",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "smart-resume",
            "knowledge": null,
            "lastUpdated": "2025-11-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "SmartResume",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "smolvla-base",
            "knowledge": null,
            "lastUpdated": "2025-10-10",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "smolvla_base",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "smooth-mix-wan-22",
            "knowledge": null,
            "lastUpdated": "2025-11-10",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "smoothMixWan22",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "smooth-mix-wan-2-2-i2v",
            "knowledge": null,
            "lastUpdated": "2025-10-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Smooth_Mix_Wan_2_2_I2V",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "song-generation",
            "knowledge": null,
            "lastUpdated": "2025-10-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "SongGeneration",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-06-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "soul-x-podcast-1-7b",
            "knowledge": null,
            "lastUpdated": "2025-12-18",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "SoulX-Podcast-1.7B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "spark-tts-0-5b",
            "knowledge": null,
            "lastUpdated": "2025-03-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Spark-TTS-0.5B",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-03-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speaker-diarization-3-1",
            "knowledge": null,
            "lastUpdated": "2025-11-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speaker-diarization-3.1",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-11-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-campplus-speaker-diarization-common",
            "knowledge": null,
            "lastUpdated": "2024-12-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_campplus_speaker-diarization_common",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-06-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-campplus-sv-zh-cn-16-k-common",
            "knowledge": null,
            "lastUpdated": "2024-06-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_campplus_sv_zh-cn_16k-common",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-04-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-campplus-sv-zh-cn-3-dspeaker-16-k",
            "knowledge": null,
            "lastUpdated": "2023-07-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_campplus_sv_zh-cn_3dspeaker_16k",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-07-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-campplus-transformer-scl-zh-cn-16-k-common",
            "knowledge": null,
            "lastUpdated": "2023-08-14",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_campplus-transformer_scl_zh-cn_16k-common",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-05-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-charctc-kws-phone-xiaoyun",
            "knowledge": null,
            "lastUpdated": "2025-06-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_charctc_kws_phone-xiaoyun",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-dfsmn-aec-psm-16-k",
            "knowledge": null,
            "lastUpdated": "2025-06-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_dfsmn_aec_psm_16k",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-dfsmn-ans-psm-48-k-causal",
            "knowledge": null,
            "lastUpdated": "2025-03-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_dfsmn_ans_psm_48k_causal",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-02-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-dfsmn-kws-char-farfield-16-k-nihaomiya",
            "knowledge": null,
            "lastUpdated": "2023-05-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_dfsmn_kws_char_farfield_16k_nihaomiya",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-ecapa-tdnn-sv-zh-cn-3-dspeaker-16-k",
            "knowledge": null,
            "lastUpdated": "2023-10-13",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_ecapa-tdnn_sv_zh-cn_3dspeaker_16k",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-10-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-eres-2-net-large-sv-zh-cn-3-dspeaker-16-k",
            "knowledge": null,
            "lastUpdated": "2023-08-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_eres2net_large_sv_zh-cn_3dspeaker_16k",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-07-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-eres-2-net-sv-zh-cn-16-k-common",
            "knowledge": null,
            "lastUpdated": "2024-07-10",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_eres2net_sv_zh-cn_16k-common",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-06-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-eres-2-netv-2-sv-zh-cn-16-k-common",
            "knowledge": null,
            "lastUpdated": "2024-07-10",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_eres2netv2_sv_zh-cn_16k-common",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-04-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-eres-2-netv-2-w-24-s-4-ep-4-sv-zh-cn-16-k-common",
            "knowledge": null,
            "lastUpdated": "2024-07-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_eres2netv2w24s4ep4_sv_zh-cn_16k-common",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-06-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-frcrn-ans-cirm-16-k",
            "knowledge": null,
            "lastUpdated": "2025-01-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_frcrn_ans_cirm_16k",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-fsmn-vad-zh-cn-16-k-common-onnx",
            "knowledge": null,
            "lastUpdated": "2024-06-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_fsmn_vad_zh-cn-16k-common-onnx",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-06-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-fsmn-vad-zh-cn-16-k-common-pytorch",
            "knowledge": null,
            "lastUpdated": "2024-02-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_fsmn_vad_zh-cn-16k-common-pytorch",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-01-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-mfcca-asr-zh-cn-16-k-alimeeting-vocab-4950",
            "knowledge": null,
            "lastUpdated": "2023-05-09",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_mfcca_asr-zh-cn-16k-alimeeting-vocab4950",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-02-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-mossformer-2-separation-temporal-16-k",
            "knowledge": null,
            "lastUpdated": "2024-12-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_mossformer2_separation_temporal_16k",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-07-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-mossformer-2-separation-temporal-8-k",
            "knowledge": null,
            "lastUpdated": "2024-12-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_mossformer2_separation_temporal_8k",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-08-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-mossformer-separation-temporal-8-k",
            "knowledge": null,
            "lastUpdated": "2025-01-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_mossformer_separation_temporal_8k",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-12-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-ngram-lm-zh-cn-ai-wesp-fst",
            "knowledge": null,
            "lastUpdated": "2023-12-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_ngram_lm_zh-cn-ai-wesp-fst",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-10-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-paraformer-asr-nat-zh-cn-16-k-common-vocab-8358-tensorflow-1",
            "knowledge": null,
            "lastUpdated": "2024-01-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_paraformer_asr_nat-zh-cn-16k-common-vocab8358-tensorflow1",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-paraformer-asr-nat-zh-cn-16-k-common-vocab-8404-online",
            "knowledge": null,
            "lastUpdated": "2024-01-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_paraformer_asr_nat-zh-cn-16k-common-vocab8404-online",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-03-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-paraformer-large-asr-nat-zh-cantonese-en-16-k-vocab-8501-online",
            "knowledge": null,
            "lastUpdated": "2024-02-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_paraformer-large_asr_nat-zh-cantonese-en-16k-vocab8501-online",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-01-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-paraformer-large-asr-nat-zh-cn-16-k-common-vocab-8358-tensorflow-1",
            "knowledge": null,
            "lastUpdated": "2024-01-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8358-tensorflow1",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-paraformer-large-asr-nat-zh-cn-16-k-common-vocab-8404-online",
            "knowledge": null,
            "lastUpdated": "2024-01-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-04-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-paraformer-large-asr-nat-zh-cn-16-k-common-vocab-8404-online-onnx",
            "knowledge": null,
            "lastUpdated": "2024-09-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online-onnx",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-08-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-paraformer-large-asr-nat-zh-cn-16-k-common-vocab-8404-onnx",
            "knowledge": null,
            "lastUpdated": "2024-09-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-onnx",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-06-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-paraformer-large-asr-nat-zh-cn-16-k-common-vocab-8404-pytorch",
            "knowledge": null,
            "lastUpdated": "2024-02-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-11-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-paraformer-large-contextual-asr-nat-zh-cn-16-k-common-vocab-8404",
            "knowledge": null,
            "lastUpdated": "2024-03-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_paraformer-large-contextual_asr_nat-zh-cn-16k-common-vocab8404",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-02-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-paraformer-large-vad-punc-asr-nat-en-16-k-common-vocab-10020",
            "knowledge": null,
            "lastUpdated": "2024-03-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_paraformer-large-vad-punc_asr_nat-en-16k-common-vocab10020",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-10-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-paraformer-large-vad-punc-asr-nat-zh-cn-16-k-common-vocab-8404-onnx",
            "knowledge": null,
            "lastUpdated": "2024-09-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-onnx",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-08-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-paraformer-large-vad-punc-asr-nat-zh-cn-16-k-common-vocab-8404-pytorch",
            "knowledge": null,
            "lastUpdated": "2024-02-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-01-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-paraformer-large-vad-punc-spk-asr-nat-zh-cn",
            "knowledge": null,
            "lastUpdated": "2024-01-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_paraformer-large-vad-punc-spk_asr_nat-zh-cn",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-10-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-res-2-net-sv-zh-cn-3-dspeaker-16-k",
            "knowledge": null,
            "lastUpdated": "2025-01-14",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_res2net_sv_zh-cn_3dspeaker_16k",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-02-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-sambert-hifigan-tts-zh-cn-16-k",
            "knowledge": null,
            "lastUpdated": "2023-04-10",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_sambert-hifigan_tts_zh-cn_16k",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-sanm-kws-phone-xiaoyun-commands-online",
            "knowledge": null,
            "lastUpdated": "2024-10-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_sanm_kws_phone-xiaoyun-commands-online",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-seaco-paraformer-large-asr-nat-zh-cn-16-k-common-vocab-8404-pytorch",
            "knowledge": null,
            "lastUpdated": "2024-09-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-12-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-timestamp-prediction-v-1-16-k-offline",
            "knowledge": null,
            "lastUpdated": "2024-01-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_timestamp_prediction-v1-16k-offline",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-03-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-uni-asr-asr-2-pass-cn-dialect-16-k-vocab-8358-tensorflow-1-offline",
            "knowledge": null,
            "lastUpdated": "2023-09-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_UniASR_asr_2pass-cn-dialect-16k-vocab8358-tensorflow1-offline",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-uni-asr-asr-2-pass-cn-dialect-16-k-vocab-8358-tensorflow-1-online",
            "knowledge": null,
            "lastUpdated": "2023-09-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_UniASR_asr_2pass-cn-dialect-16k-vocab8358-tensorflow1-online",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2022-08-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-whisper-large-lid-multilingual-pytorch",
            "knowledge": null,
            "lastUpdated": "2024-03-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_whisper-large_lid_multilingual_pytorch",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-02-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "speech-zipenhancer-ans-multiloss-16-k-base",
            "knowledge": null,
            "lastUpdated": "2025-09-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "speech_zipenhancer_ans_multiloss_16k_base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-10-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "stable-diffusion-2-1-base",
            "knowledge": null,
            "lastUpdated": "2024-12-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "stable-diffusion-2-1-base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-12-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "stable-diffusion-2-inpainting",
            "knowledge": null,
            "lastUpdated": "2024-12-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "stable-diffusion-2-inpainting",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-12-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "stable-diffusion-3-5-large-turbo",
            "knowledge": null,
            "lastUpdated": "2024-10-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "stable-diffusion-3.5-large-turbo",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-10-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "stable-diffusion-v-1-5",
            "knowledge": null,
            "lastUpdated": "2023-07-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "stable-diffusion-v1-5",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-04-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "stable-diffusion-v-1-5-archive",
            "knowledge": null,
            "lastUpdated": "2025-10-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "stable-diffusion-v1-5-archive",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-10-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "stable-diffusion-xl-base-1-0",
            "knowledge": null,
            "lastUpdated": "2023-10-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "stable-diffusion-xl-base-1.0",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-07-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "step-1-x-edit",
            "knowledge": null,
            "lastUpdated": "2025-07-09",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Step1X-Edit",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00057,
                "inputCacheHit": null,
                "output": 0.00142
            },
            "extendedThinking": false,
            "id": "step-3",
            "knowledge": null,
            "lastUpdated": "2025-08-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "step3",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "step-audio-2-mini",
            "knowledge": null,
            "lastUpdated": "2025-09-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Step-Audio-2-mini",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "step-audio-edit-x",
            "knowledge": null,
            "lastUpdated": "2025-11-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Step-Audio-EditX",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "step-audio-tts-3b",
            "knowledge": null,
            "lastUpdated": "2025-04-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Step-Audio-TTS-3B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "supertonic",
            "knowledge": null,
            "lastUpdated": "2025-12-10",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "supertonic",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "svi-model",
            "knowledge": null,
            "lastUpdated": "2025-12-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "svi-model",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "t-5-xxl-fp-16",
            "knowledge": null,
            "lastUpdated": "2024-08-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "t5xxl_fp16",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-08-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "t-5-xxl-fp-8-e-4-m-3-fn",
            "knowledge": null,
            "lastUpdated": "2025-04-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "t5xxl_fp8_e4m3fn",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "tele-chat-3-105b-a4-7b-thinking",
            "knowledge": null,
            "lastUpdated": "2025-12-25",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "TeleChat3-105B-A4.7B-Thinking",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-12-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "tele-chat-3-36b-thinking",
            "knowledge": null,
            "lastUpdated": "2025-12-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "TeleChat3-36B-Thinking",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-12-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "text-2-vec-base-chinese",
            "knowledge": null,
            "lastUpdated": "2023-11-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "text2vec-base-chinese",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-11-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "text-2-vec-word-2-vec-tencent-chinese",
            "knowledge": null,
            "lastUpdated": "2025-01-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "text2vec-word2vec-tencent-chinese",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-01-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "text-to-video-synthesis",
            "knowledge": null,
            "lastUpdated": "2024-10-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image"]
            },
            "name": "text-to-video-synthesis",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-02-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "think-sound",
            "knowledge": null,
            "lastUpdated": "2025-07-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ThinkSound",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00009,
                "inputCacheHit": null,
                "output": 0.0004
            },
            "extendedThinking": false,
            "id": "tongyi-deep-research-30b-a3b",
            "knowledge": null,
            "lastUpdated": "2025-10-10",
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Tongyi-DeepResearch-30B-A3B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "tongyi-finance-14b",
            "knowledge": null,
            "lastUpdated": "2023-11-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Tongyi-Finance-14B",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-10-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "tongyi-finance-14b-chat",
            "knowledge": null,
            "lastUpdated": "2023-11-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Tongyi-Finance-14B-Chat",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-10-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "trellis-2-4b",
            "knowledge": null,
            "lastUpdated": "2025-12-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "TRELLIS.2-4B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "tu-tus-hi-silk-z-image-turbo-8d-black-aurora-glossy-black-stockings-over-the-knee-stockings",
            "knowledge": null,
            "lastUpdated": "2025-11-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "TuTus-HiSilk-Z-Image-Turbo-8D-Black-Aurora-Glossy-Black-Stockings-Over-the-Knee-Stockings",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "turbo-wan-2-1-t2v-1-3b-480p",
            "knowledge": null,
            "lastUpdated": "2025-12-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image"]
            },
            "name": "TurboWan2.1-T2V-1.3B-480P",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "turbo-wan-2-2-i2v-a14b-720p",
            "knowledge": null,
            "lastUpdated": "2025-12-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "TurboWan2.2-I2V-A14B-720P",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "tutu-hi-silk-fishnet-z-image-turbo",
            "knowledge": null,
            "lastUpdated": "2025-11-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "TutuHiSilkFishnetZImageTurbo",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "twin-flow-z-image-turbo",
            "knowledge": null,
            "lastUpdated": "2025-12-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "TwinFlow-Z-Image-Turbo",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "twin-flow-z-image-turbo-comfy-ui",
            "knowledge": null,
            "lastUpdated": "2025-12-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "TwinFlow-Z-Image-Turbo-ComfyUI",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0001,
                "inputCacheHit": null,
                "output": 0.0002
            },
            "extendedThinking": false,
            "id": "ui-tars-1-5-7b",
            "knowledge": null,
            "lastUpdated": "2025-04-18",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "UI-TARS-1.5-7B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ultra-flux-vae-v-1",
            "knowledge": null,
            "lastUpdated": "2025-12-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "UltraFlux-vae_v1",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ultra-zimage-vae-v-1",
            "knowledge": null,
            "lastUpdated": "2025-12-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "UltraZimage-vae_v1",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "umt-5-xxl",
            "knowledge": null,
            "lastUpdated": "2025-04-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "umt5-xxl",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "umt-5-xxl-fp-8-e-4-m-3-fn-scaled-safetensors",
            "knowledge": null,
            "lastUpdated": "2025-09-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "unicorneyes",
            "knowledge": null,
            "lastUpdated": "2025-08-09",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "unicorneyes",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "unirec-0-1-b",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "unirec-0.1b",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "v-1-5-pruned-emaonly-fp-16",
            "knowledge": null,
            "lastUpdated": "2025-09-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "v1-5-pruned-emaonly-fp16",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "v-1-5-pruned-emaonly-safetensors",
            "knowledge": null,
            "lastUpdated": "2024-05-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "v1-5-pruned-emaonly.safetensors",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-05-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "vae-ft-mse-840000-ema-pruned",
            "knowledge": null,
            "lastUpdated": "2024-04-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "vae-ft-mse-840000-ema-pruned",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-03-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "vibe-thinker-1-5b",
            "knowledge": null,
            "lastUpdated": "2025-11-24",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "VibeThinker-1.5B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "vibe-voice-1-5b",
            "knowledge": null,
            "lastUpdated": "2025-09-02",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "VibeVoice-1.5B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "vibe-voice-large",
            "knowledge": null,
            "lastUpdated": "2025-09-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "VibeVoice-Large",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "vibe-voice-realtime-0-5b",
            "knowledge": null,
            "lastUpdated": "2025-12-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "VibeVoice-Realtime-0.5B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "video-to-video",
            "knowledge": null,
            "lastUpdated": "2023-12-15",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image"]
            },
            "name": "Video-to-Video",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-08-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "void",
            "knowledge": null,
            "lastUpdated": "2025-08-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "void",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "vox-cpm-0-5b",
            "knowledge": null,
            "lastUpdated": "2025-09-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "VoxCPM-0.5B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "vox-cpm-1-5",
            "knowledge": null,
            "lastUpdated": "2025-12-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "VoxCPM1.5",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wai-illustrious-sdxl",
            "knowledge": null,
            "lastUpdated": "2025-04-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "WAI-illustrious-SDXL",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wai-nsfw-illustrious-sdxl-v-12",
            "knowledge": null,
            "lastUpdated": "2025-05-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "WAI_NSFW-illustrious-SDXL_v12",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan2-2-14b-rapid-all-in-one",
            "knowledge": null,
            "lastUpdated": "2025-12-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "WAN2.2-14B-Rapid-AllInOne",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan2-2-dasiwa-i2v-14b-midnightflirt-model",
            "knowledge": null,
            "lastUpdated": "2025-12-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "WAN2.2-dasiwa-I2V-14B_midnightflirt_model",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-1-comfy-ui-repackaged",
            "knowledge": null,
            "lastUpdated": "2025-10-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image"]
            },
            "name": "Wan_2.1_ComfyUI_repackaged",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-1-distill-models",
            "knowledge": null,
            "lastUpdated": "2025-12-09",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image"]
            },
            "name": "Wan2.1-Distill-Models",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-1-flf2v-14b-720p",
            "knowledge": null,
            "lastUpdated": "2025-04-18",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Wan2.1-FLF2V-14B-720P",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-1-i2v-14b-480p",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Wan2.1-I2V-14B-480P",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-1-i2v-14b-480p-diffusers",
            "knowledge": null,
            "lastUpdated": "2025-04-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Wan2.1-I2V-14B-480P-Diffusers",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-03-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-1-i2v-14b-480p-gguf",
            "knowledge": null,
            "lastUpdated": "2025-02-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Wan2.1-I2V-14B-480P-gguf",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-1-i2v-14b-480p-step-distill-cfg-distill-lightx-2-v",
            "knowledge": null,
            "lastUpdated": "2025-10-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Wan2.1-I2V-14B-480P-StepDistill-CfgDistill-Lightx2v",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-1-i2v-14b-720p",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Wan2.1-I2V-14B-720P",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-1-t2v-14b",
            "knowledge": null,
            "lastUpdated": "2025-04-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Wan2.1-T2V-14B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-1-t2v-1-3b",
            "knowledge": null,
            "lastUpdated": "2025-02-26",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Wan2.1-T2V-1.3B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-1-t2v-1-3b-diffusers",
            "knowledge": null,
            "lastUpdated": "2025-04-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Wan2.1-T2V-1.3B-Diffusers",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-03-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-1-vace-14b",
            "knowledge": null,
            "lastUpdated": "2025-05-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Wan2.1-VACE-14B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-1-vace-1-3b",
            "knowledge": null,
            "lastUpdated": "2025-05-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Wan2.1-VACE-1.3B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-05-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-1-vae",
            "knowledge": null,
            "lastUpdated": "2025-07-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "wan2.1-vae",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-animate-14b",
            "knowledge": null,
            "lastUpdated": "2025-11-05",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Wan2.2-Animate-14B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-animate-14b-diffusers",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Wan2.2-Animate-14B-Diffusers",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-animate-14b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-09-21",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Wan2.2-Animate-14B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-comfy-ui-repackaged",
            "knowledge": null,
            "lastUpdated": "2025-12-09",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image"]
            },
            "name": "Wan_2.2_ComfyUI_Repackaged",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-distill-loras",
            "knowledge": null,
            "lastUpdated": "2025-12-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Wan2.2-Distill-Loras",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-distill-models",
            "knowledge": null,
            "lastUpdated": "2025-12-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image"]
            },
            "name": "Wan2.2-Distill-Models",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-fun-a14b-control",
            "knowledge": null,
            "lastUpdated": "2025-08-14",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Wan2.2-Fun-A14B-Control",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-fun-a14b-control-camera",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Wan2.2-Fun-A14B-Control-Camera",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-fun-a14b-in-p",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Wan2.2-Fun-A14B-InP",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-i2v-a14b",
            "knowledge": null,
            "lastUpdated": "2025-11-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Wan2.2-I2V-A14B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-i2v-a14b-bf16",
            "knowledge": null,
            "lastUpdated": "2025-11-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Wan2.2-I2V-A14B-BF16",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-i2v-a14b-diffusers",
            "knowledge": null,
            "lastUpdated": "2025-08-10",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Wan2.2-I2V-A14B-Diffusers",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-i2v-a14b-fp8",
            "knowledge": null,
            "lastUpdated": "2025-09-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Wan2.2-I2V-A14B-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-i2v-a14b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-07-28",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Wan2.2-I2V-A14B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-i2v-a14b-moe-distill-lightx-2-v",
            "knowledge": null,
            "lastUpdated": "2025-10-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Wan2.2-I2V-A14B-Moe-Distill-Lightx2v",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-i-2-v-a-14-b-high-noise-scaled-fp-8-e-4-m-3-lightx-2-v-4-step-comfyui",
            "knowledge": null,
            "lastUpdated": "2026-01-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "wan2.2_i2v_A14b_high_noise_scaled_fp8_e4m3_lightx2v_4step_comfyui",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-lightning",
            "knowledge": null,
            "lastUpdated": "2025-11-13",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Wan2.2-Lightning",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-official-models",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Wan2.2-Official-Models",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-10-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-s2v-14b",
            "knowledge": null,
            "lastUpdated": "2025-09-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Wan2.2-S2V-14B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-s2v-14b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-08-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Wan2.2-S2V-14B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-t2v-a14b",
            "knowledge": null,
            "lastUpdated": "2025-11-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Wan2.2-T2V-A14B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-t2v-a14b-bf16",
            "knowledge": null,
            "lastUpdated": "2025-11-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Wan2.2-T2V-A14B-BF16",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-t2v-a14b-diffusers",
            "knowledge": null,
            "lastUpdated": "2025-08-10",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Wan2.2-T2V-A14B-Diffusers",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-t2v-a14b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-07-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Wan2.2-T2V-A14B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-ti2v-5b",
            "knowledge": null,
            "lastUpdated": "2025-11-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Wan2.2-TI2V-5B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-ti2v-5b-bf16",
            "knowledge": null,
            "lastUpdated": "2025-11-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Wan2.2-TI2V-5B-BF16",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-ti2v-5b-diffusers",
            "knowledge": null,
            "lastUpdated": "2025-08-10",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Wan2.2-TI2V-5B-Diffusers",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-ti2v-5b-gguf",
            "knowledge": null,
            "lastUpdated": "2025-07-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Wan2.2-TI2V-5B-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-ti-2-v-5b-fp-16-safetensors",
            "knowledge": null,
            "lastUpdated": "2025-09-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "wan2.2_ti2v_5B_fp16.safetensors",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-vace-fun-a14b",
            "knowledge": null,
            "lastUpdated": "2025-12-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Wan2.2-VACE-Fun-A14B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-2-2-vae-safetensors",
            "knowledge": null,
            "lastUpdated": "2025-09-19",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "wan2.2_vae.safetensors",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-09-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-nvfp4",
            "knowledge": null,
            "lastUpdated": "2025-12-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image"]
            },
            "name": "Wan-NVFP4",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-video-comfy",
            "knowledge": null,
            "lastUpdated": "2025-12-10",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image"]
            },
            "name": "WanVideo_comfy",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-video-comfy-fp-8-scaled",
            "knowledge": null,
            "lastUpdated": "2025-12-14",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image"]
            },
            "name": "WanVideo_comfy_fp8_scaled",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-07-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wan-video-comfy-gguf",
            "knowledge": null,
            "lastUpdated": "2025-09-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["image"]
            },
            "name": "WanVideo_comfy_GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "we-dlm-8b-instruct",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "WeDLM-8B-Instruct",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "web-sailor-7b",
            "knowledge": null,
            "lastUpdated": "2026-01-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "WebSailor-7B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "white-base",
            "knowledge": null,
            "lastUpdated": "2025-12-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "white_base",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "wlop",
            "knowledge": null,
            "lastUpdated": "2025-08-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "wlop",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "x-bai-o-4",
            "knowledge": null,
            "lastUpdated": "2025-08-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "XBai-o4",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-08-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "xi-yan-sql-qwen-coder-32b-2412",
            "knowledge": null,
            "lastUpdated": "2025-07-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "XiYanSQL-QwenCoder-32B-2412",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-12-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "xi-yan-sql-qwen-coder-32b-2504",
            "knowledge": null,
            "lastUpdated": "2025-12-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "XiYanSQL-QwenCoder-32B-2504",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-04-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "xtts-v-2",
            "knowledge": null,
            "lastUpdated": "2023-11-14",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "XTTS-v2",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-11-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "xverse-ent-a4-2b",
            "knowledge": null,
            "lastUpdated": "2025-12-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "XVERSE-Ent-A4.2B",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "yol-ov-8",
            "knowledge": null,
            "lastUpdated": "2025-01-11",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "YOLOv8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.015,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "yolo11",
            "knowledge": null,
            "lastUpdated": "2024-09-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "YOLO11",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2024-09-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.015,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "yolo12",
            "knowledge": null,
            "lastUpdated": "2025-03-27",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "YOLO12",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-02-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "youtu-llm-2b",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Youtu-LLM-2B",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "youtu-llm-2b-gguf",
            "knowledge": null,
            "lastUpdated": "2026-01-07",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Youtu-LLM-2B-GGUF",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "yu-feng-x-guard-reason-8b",
            "knowledge": null,
            "lastUpdated": "2025-12-31",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "YuFeng-XGuard-Reason-8B",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "yuan-3-0-flash",
            "knowledge": null,
            "lastUpdated": "2026-01-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Yuan3.0-Flash",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "yuanfang-agent",
            "knowledge": null,
            "lastUpdated": "2023-07-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "yuanfang_agent",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2023-07-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "yuanyuan-cosplay-z-image-turbo-tongyi-mai-v-1-0",
            "knowledge": null,
            "lastUpdated": "2026-01-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "yuanyuan-cosplay-Z-Image-Turbo-Tongyi-MAI-v1.0",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2026-01-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-animimage-turbo-by-lau-alpha-v1",
            "knowledge": null,
            "lastUpdated": "2025-12-20",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "z_animimage_turbo_by_Lau_alpha_V1",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-image-anime-vae",
            "knowledge": null,
            "lastUpdated": "2025-12-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Z-Image_Anime_VAE",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-image-comfy-fp-8-scaled",
            "knowledge": null,
            "lastUpdated": "2025-11-30",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Z-Image_comfy_fp8_scaled",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-image-de-turbo",
            "knowledge": null,
            "lastUpdated": "2025-12-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Z-Image-De-Turbo",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-image-gguf",
            "knowledge": null,
            "lastUpdated": "2025-12-08",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "z-image-gguf",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-image-realistic-photography",
            "knowledge": null,
            "lastUpdated": "2025-12-03",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Z-image_Realistic_Photography",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-image-turbo",
            "knowledge": null,
            "lastUpdated": "2026-01-06",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "z_image_turbo",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": true,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-image-turbo-comfyui",
            "knowledge": null,
            "lastUpdated": "2025-11-29",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "z_image_turbo_comfyui",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-image-turbo-distill-patch",
            "knowledge": null,
            "lastUpdated": "2025-12-17",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Z-Image-Turbo-DistillPatch",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-image-turbo-fp8",
            "knowledge": null,
            "lastUpdated": "2025-12-10",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Z-Image-Turbo-FP8",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-image-turbo-fun-controlnet-union",
            "knowledge": null,
            "lastUpdated": "2025-12-12",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Z-Image-Turbo-Fun-Controlnet-Union",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-image-turbo-fun-controlnet-union-2-1",
            "knowledge": null,
            "lastUpdated": "2025-12-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Z-Image-Turbo-Fun-Controlnet-Union-2.1",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-image-turbo-fun-controlnet-union-2-1-8-steps-fp-8",
            "knowledge": null,
            "lastUpdated": "2026-01-04",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Z-Image-Turbo-Fun-Controlnet-Union-2.1-8steps-fp8",
            "openWeights": false,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-image-turbo-fun-unionunion-controlnet",
            "knowledge": null,
            "lastUpdated": "2025-12-23",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Z-image-turbo-fun-unionunion-controlnet",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-image-turbo-gguf",
            "knowledge": null,
            "lastUpdated": "2025-12-22",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Z-Image-Turbo-GGUF",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-image-turbo-realism-lo-ra",
            "knowledge": null,
            "lastUpdated": "2025-12-09",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "Z-Image-Turbo-Realism-LoRA",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-imagemeinvxiezhen",
            "knowledge": null,
            "lastUpdated": "2025-12-16",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Z-Imagemeinvxiezhen",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "zimage-turbo-lora",
            "knowledge": null,
            "lastUpdated": "2025-12-18",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "zimage-turbo-lora",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-12-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0004,
                "inputCacheHit": null,
                "output": 0.0004
            },
            "extendedThinking": false,
            "id": "zimage-turbo-training-adapter",
            "knowledge": null,
            "lastUpdated": "2025-12-01",
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "zimage_turbo_training_adapter",
            "openWeights": true,
            "provider": "ModelScope",
            "providerDoc": "https://modelscope.cn/docs/model-service/API-Inference/intro",
            "providerEnv": ["MODELSCOPE_API_KEY"],
            "providerId": "model-scope",
            "providerModelsDevId": "modelscope",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": "2025-11-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "modelscope"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "more-morph",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "moreMorph",
            "openWeights": false,
            "provider": "Morph",
            "providerDoc": "https://morph.ai/",
            "providerEnv": ["MORPH_API_KEY"],
            "providerId": "morph",
            "providerModelsDevId": "morph",
            "providerNpm": "@ai-sdk/morph",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "morph"
        },
        {
            "attachment": true,
            "cost": {
                "input": 1.5,
                "inputCacheHit": 0.375,
                "output": 6
            },
            "extendedThinking": true,
            "id": "codex-mini-latest",
            "knowledge": "2024-04",
            "lastUpdated": "2025-05-16",
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Codex Mini",
            "openWeights": false,
            "provider": "OpenAI",
            "providerDoc": "https://platform.openai.com/docs/models",
            "providerEnv": ["OPENAI_API_KEY"],
            "providerId": "open-ai",
            "providerModelsDevId": "openai",
            "providerNpm": "@ai-sdk/openai",
            "reasoning": true,
            "releaseDate": "2025-05-16",
            "streamingSupported": true,
            "temperature": false,
            "toolCall": true,
            "vision": false,
            "icon": "openai"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.5,
                "inputCacheHit": 1.25,
                "output": 1.5
            },
            "extendedThinking": false,
            "id": "gpt-3.5-turbo",
            "knowledge": "2021-09-01",
            "lastUpdated": "2023-11-06",
            "limit": {
                "context": 16385,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GPT-3.5-turbo",
            "openWeights": false,
            "provider": "OpenAI",
            "providerDoc": "https://platform.openai.com/docs/models",
            "providerEnv": ["OPENAI_API_KEY"],
            "providerId": "open-ai",
            "providerModelsDevId": "openai",
            "providerNpm": "@ai-sdk/openai",
            "reasoning": false,
            "releaseDate": "2023-03-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "openai"
        },
        {
            "attachment": true,
            "cost": {
                "input": 10,
                "inputCacheHit": null,
                "output": 30
            },
            "extendedThinking": false,
            "id": "gpt-4",
            "knowledge": "2023-11",
            "lastUpdated": "2024-04-09",
            "limit": {
                "context": 8192,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GPT-4",
            "openWeights": false,
            "provider": "OpenAI",
            "providerDoc": "https://platform.openai.com/docs/models",
            "providerEnv": ["OPENAI_API_KEY"],
            "providerId": "open-ai",
            "providerModelsDevId": "openai",
            "providerNpm": "@ai-sdk/openai",
            "reasoning": false,
            "releaseDate": "2023-11-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openai"
        },
        {
            "attachment": true,
            "cost": {
                "input": 2,
                "inputCacheHit": 0.5,
                "output": 8
            },
            "extendedThinking": false,
            "id": "gpt-4.1",
            "knowledge": "2024-05",
            "lastUpdated": "2025-04-14",
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "GPT-4.1",
            "openWeights": false,
            "provider": "OpenAI",
            "providerDoc": "https://platform.openai.com/docs/models",
            "providerEnv": ["OPENAI_API_KEY"],
            "providerId": "open-ai",
            "providerModelsDevId": "openai",
            "providerNpm": "@ai-sdk/openai",
            "reasoning": false,
            "releaseDate": "2025-04-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openai"
        },
        {
            "attachment": true,
            "cost": {
                "input": 0.4,
                "inputCacheHit": 0.1,
                "output": 1.6
            },
            "extendedThinking": false,
            "id": "gpt-4.1-mini",
            "knowledge": "2024-04",
            "lastUpdated": "2025-04-14",
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "GPT-4.1 mini",
            "openWeights": false,
            "provider": "OpenAI",
            "providerDoc": "https://platform.openai.com/docs/models",
            "providerEnv": ["OPENAI_API_KEY"],
            "providerId": "open-ai",
            "providerModelsDevId": "openai",
            "providerNpm": "@ai-sdk/openai",
            "reasoning": false,
            "releaseDate": "2025-04-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openai"
        },
        {
            "attachment": true,
            "cost": {
                "input": 0.1,
                "inputCacheHit": 0.03,
                "output": 0.4
            },
            "extendedThinking": false,
            "id": "gpt-4.1-nano",
            "knowledge": "2024-04",
            "lastUpdated": "2025-04-14",
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "GPT-4.1 nano",
            "openWeights": false,
            "provider": "OpenAI",
            "providerDoc": "https://platform.openai.com/docs/models",
            "providerEnv": ["OPENAI_API_KEY"],
            "providerId": "open-ai",
            "providerModelsDevId": "openai",
            "providerNpm": "@ai-sdk/openai",
            "reasoning": false,
            "releaseDate": "2025-04-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openai"
        },
        {
            "attachment": false,
            "cost": {
                "input": 60,
                "inputCacheHit": null,
                "output": 120
            },
            "extendedThinking": false,
            "id": "gpt-4-32k",
            "knowledge": "2023-11",
            "lastUpdated": "2023-03-14",
            "limit": {
                "context": 32768,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GPT-4 32K",
            "openWeights": false,
            "provider": "OpenAI",
            "providerDoc": "https://platform.openai.com/docs/models",
            "providerEnv": ["OPENAI_API_KEY"],
            "providerId": "open-ai",
            "providerModelsDevId": "openai",
            "providerNpm": "@ai-sdk/openai",
            "reasoning": false,
            "releaseDate": "2023-03-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openai"
        },
        {
            "attachment": true,
            "cost": {
                "input": 2.5,
                "inputCacheHit": 1.25,
                "output": 10
            },
            "extendedThinking": false,
            "id": "gpt-4o",
            "knowledge": "2023-09",
            "lastUpdated": "2024-05-13",
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "GPT-4o",
            "openWeights": false,
            "provider": "OpenAI",
            "providerDoc": "https://platform.openai.com/docs/models",
            "providerEnv": ["OPENAI_API_KEY"],
            "providerId": "open-ai",
            "providerModelsDevId": "openai",
            "providerNpm": "@ai-sdk/openai",
            "reasoning": false,
            "releaseDate": "2024-05-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openai"
        },
        {
            "attachment": true,
            "cost": {
                "input": 0.15,
                "inputCacheHit": 0.08,
                "output": 0.6
            },
            "extendedThinking": false,
            "id": "gpt-4o-mini",
            "knowledge": "2023-09",
            "lastUpdated": "2024-07-18",
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "GPT-4o mini",
            "openWeights": false,
            "provider": "OpenAI",
            "providerDoc": "https://platform.openai.com/docs/models",
            "providerEnv": ["OPENAI_API_KEY"],
            "providerId": "open-ai",
            "providerModelsDevId": "openai",
            "providerNpm": "@ai-sdk/openai",
            "reasoning": false,
            "releaseDate": "2024-07-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openai"
        },
        {
            "attachment": true,
            "cost": {
                "input": 10,
                "inputCacheHit": null,
                "output": 30
            },
            "extendedThinking": false,
            "id": "gpt-4-turbo",
            "knowledge": "2023-11",
            "lastUpdated": "2024-04-09",
            "limit": {
                "context": 128000,
                "output": 4096
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "GPT-4 Turbo",
            "openWeights": false,
            "provider": "OpenAI",
            "providerDoc": "https://platform.openai.com/docs/models",
            "providerEnv": ["OPENAI_API_KEY"],
            "providerId": "open-ai",
            "providerModelsDevId": "openai",
            "providerNpm": "@ai-sdk/openai",
            "reasoning": false,
            "releaseDate": "2023-11-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openai"
        },
        {
            "attachment": false,
            "cost": {
                "input": 15,
                "inputCacheHit": 7.5,
                "output": 60
            },
            "extendedThinking": true,
            "id": "o1",
            "knowledge": "2023-09",
            "lastUpdated": "2024-12-05",
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "o1",
            "openWeights": false,
            "provider": "OpenAI",
            "providerDoc": "https://platform.openai.com/docs/models",
            "providerEnv": ["OPENAI_API_KEY"],
            "providerId": "open-ai",
            "providerModelsDevId": "openai",
            "providerNpm": "@ai-sdk/openai",
            "reasoning": true,
            "releaseDate": "2024-12-05",
            "streamingSupported": true,
            "temperature": false,
            "toolCall": true,
            "vision": true,
            "icon": "openai"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.1,
                "inputCacheHit": 0.55,
                "output": 4.4
            },
            "extendedThinking": true,
            "id": "o1-mini",
            "knowledge": "2023-09",
            "lastUpdated": "2024-09-12",
            "limit": {
                "context": 128000,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "o1-mini",
            "openWeights": false,
            "provider": "OpenAI",
            "providerDoc": "https://platform.openai.com/docs/models",
            "providerEnv": ["OPENAI_API_KEY"],
            "providerId": "open-ai",
            "providerModelsDevId": "openai",
            "providerNpm": "@ai-sdk/openai",
            "reasoning": true,
            "releaseDate": "2024-09-12",
            "streamingSupported": true,
            "temperature": false,
            "toolCall": false,
            "vision": false,
            "icon": "openai"
        },
        {
            "attachment": false,
            "cost": {
                "input": 15,
                "inputCacheHit": 7.5,
                "output": 60
            },
            "extendedThinking": true,
            "id": "o1-preview",
            "knowledge": "2023-09",
            "lastUpdated": "2024-09-12",
            "limit": {
                "context": 128000,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "o1-preview",
            "openWeights": false,
            "provider": "OpenAI",
            "providerDoc": "https://platform.openai.com/docs/models",
            "providerEnv": ["OPENAI_API_KEY"],
            "providerId": "open-ai",
            "providerModelsDevId": "openai",
            "providerNpm": "@ai-sdk/openai",
            "reasoning": true,
            "releaseDate": "2024-09-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "openai"
        },
        {
            "attachment": true,
            "cost": {
                "input": 2,
                "inputCacheHit": 0.5,
                "output": 8
            },
            "extendedThinking": true,
            "id": "o3",
            "knowledge": "2024-05",
            "lastUpdated": "2025-04-16",
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "o3",
            "openWeights": false,
            "provider": "OpenAI",
            "providerDoc": "https://platform.openai.com/docs/models",
            "providerEnv": ["OPENAI_API_KEY"],
            "providerId": "open-ai",
            "providerModelsDevId": "openai",
            "providerNpm": "@ai-sdk/openai",
            "reasoning": true,
            "releaseDate": "2025-04-16",
            "streamingSupported": true,
            "temperature": false,
            "toolCall": true,
            "vision": true,
            "icon": "openai"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.1,
                "inputCacheHit": 0.55,
                "output": 4.4
            },
            "extendedThinking": true,
            "id": "o3-mini",
            "knowledge": "2024-05",
            "lastUpdated": "2025-01-29",
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "o3-mini",
            "openWeights": false,
            "provider": "OpenAI",
            "providerDoc": "https://platform.openai.com/docs/models",
            "providerEnv": ["OPENAI_API_KEY"],
            "providerId": "open-ai",
            "providerModelsDevId": "openai",
            "providerNpm": "@ai-sdk/openai",
            "reasoning": true,
            "releaseDate": "2024-12-20",
            "streamingSupported": true,
            "temperature": false,
            "toolCall": true,
            "vision": false,
            "icon": "openai"
        },
        {
            "attachment": true,
            "cost": {
                "input": 20,
                "inputCacheHit": null,
                "output": 80
            },
            "extendedThinking": true,
            "id": "o3-pro",
            "knowledge": "2024-05",
            "lastUpdated": "2025-06-10",
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "o3-pro",
            "openWeights": false,
            "provider": "OpenAI",
            "providerDoc": "https://platform.openai.com/docs/models",
            "providerEnv": ["OPENAI_API_KEY"],
            "providerId": "open-ai",
            "providerModelsDevId": "openai",
            "providerNpm": "@ai-sdk/openai",
            "reasoning": true,
            "releaseDate": "2025-06-10",
            "streamingSupported": true,
            "temperature": false,
            "toolCall": true,
            "vision": true,
            "icon": "openai"
        },
        {
            "attachment": true,
            "cost": {
                "input": 1.1,
                "inputCacheHit": 0.28,
                "output": 4.4
            },
            "extendedThinking": true,
            "id": "o4-mini",
            "knowledge": "2024-05",
            "lastUpdated": "2025-04-16",
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "o4-mini",
            "openWeights": false,
            "provider": "OpenAI",
            "providerDoc": "https://platform.openai.com/docs/models",
            "providerEnv": ["OPENAI_API_KEY"],
            "providerId": "open-ai",
            "providerModelsDevId": "openai",
            "providerNpm": "@ai-sdk/openai",
            "reasoning": true,
            "releaseDate": "2025-04-16",
            "streamingSupported": true,
            "temperature": false,
            "toolCall": true,
            "vision": true,
            "icon": "openai"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "agentica-org/deepcoder-14b-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 96000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Agentica: Deepcoder 14B Preview",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "agentica-org/deepcoder-14b-preview:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 96000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Agentica: Deepcoder 14B Preview (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ai21/jamba-large-1.7",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "AI21: Jamba Large 1.7",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ai21/jamba-mini-1.7",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "AI21: Jamba Mini 1.7",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "aion-labs/aion-1.0",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "AionLabs: Aion-1.0",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "aion-labs/aion-1.0-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "AionLabs: Aion-1.0-Mini",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "aion-labs/aion-rp-llama-3.1-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "AionLabs: Aion-RP 1.0 (8B)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "alfredpros/codellama-7b-instruct-solidity",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "AlfredPros: CodeLLaMa 7B Instruct Solidity",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "alibaba/tongyi-deepresearch-30b-a3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Tongyi DeepResearch 30B A3B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "allenai/olmo-2-0325-32b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "AllenAI: Olmo 2 32B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "allenai/olmo-3.1-32b-think",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "AllenAI: Olmo 3.1 32B Think",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "allenai/olmo-3-32b-think",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "AllenAI: Olmo 3 32B Think",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-11-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "allenai/olmo-3-7b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "AllenAI: Olmo 3 7B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-11-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "allenai/olmo-3-7b-think",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "AllenAI: Olmo 3 7B Think",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-11-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "alpindale/goliath-120b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 6144,
                "output": 1024
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Goliath 120B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2023-11-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "amazon/nova-2-lite-v1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1000000,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image", "video", "file"],
                "output": ["text"]
            },
            "name": "Amazon: Nova 2 Lite",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "amazon/nova-lite-v1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 300000,
                "output": 5120
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Amazon: Nova Lite 1.0",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-12-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "amazon/nova-micro-v1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 5120
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Amazon: Nova Micro 1.0",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-12-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "amazon/nova-premier-v1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1000000,
                "output": 32000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Amazon: Nova Premier 1.0",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "amazon/nova-pro-v1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 300000,
                "output": 5120
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Amazon: Nova Pro 1.0",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-12-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "anthracite-org/magnum-v2-72b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Magnum v2 72B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-09-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "anthracite-org/magnum-v4-72b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": 2048
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Magnum v4 72B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-10-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "anthropic/claude-3.5-haiku",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Anthropic: Claude 3.5 Haiku",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-11-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "anthropic/claude-3.5-haiku-20241022",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image", "file"],
                "output": ["text"]
            },
            "name": "Anthropic: Claude 3.5 Haiku (2024-10-22)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-11-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "anthropic/claude-3.5-sonnet",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image", "file"],
                "output": ["text"]
            },
            "name": "Anthropic: Claude 3.5 Sonnet",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-10-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "anthropic/claude-3.5-sonnet-20240620",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image", "file"],
                "output": ["text"]
            },
            "name": "Anthropic: Claude 3.5 Sonnet (2024-06-20)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-06-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "anthropic/claude-3.7-sonnet",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image", "file"],
                "output": ["text"]
            },
            "name": "Anthropic: Claude 3.7 Sonnet",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "anthropic/claude-3.7-sonnet:beta",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image", "file"],
                "output": ["text"]
            },
            "name": "Anthropic: Claude 3.7 Sonnet (self-moderated)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "anthropic/claude-3.7-sonnet:thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image", "file"],
                "output": ["text"]
            },
            "name": "Anthropic: Claude 3.7 Sonnet (thinking)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "anthropic/claude-3-haiku",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 4096
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Anthropic: Claude 3 Haiku",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-03-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "anthropic/claude-3-opus",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 4096
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Anthropic: Claude 3 Opus",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-03-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "anthropic/claude-haiku-4.5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["text"]
            },
            "name": "Anthropic: Claude Haiku 4.5",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "anthropic/claude-opus-4",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 32000
            },
            "modalities": {
                "input": ["image", "text", "file"],
                "output": ["text"]
            },
            "name": "Anthropic: Claude Opus 4",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-05-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "anthropic/claude-opus-4.1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": null
            },
            "modalities": {
                "input": ["image", "text", "file"],
                "output": ["text"]
            },
            "name": "Anthropic: Claude Opus 4.1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "anthropic/claude-opus-4.5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 32000
            },
            "modalities": {
                "input": ["file", "image", "text"],
                "output": ["text"]
            },
            "name": "Anthropic: Claude Opus 4.5",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-11-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "anthropic/claude-sonnet-4",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1000000,
                "output": 64000
            },
            "modalities": {
                "input": ["image", "text", "file"],
                "output": ["text"]
            },
            "name": "Anthropic: Claude Sonnet 4",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-05-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "anthropic/claude-sonnet-4.5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1000000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image", "file"],
                "output": ["text"]
            },
            "name": "Anthropic: Claude Sonnet 4.5",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "arcee-ai/coder-large",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Arcee AI: Coder Large",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-05-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "arcee-ai/maestro-reasoning",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 32000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Arcee AI: Maestro Reasoning",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-05-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "arcee-ai/spotlight",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 65537
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["text"]
            },
            "name": "Arcee AI: Spotlight",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-05-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "arcee-ai/trinity-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Arcee AI: Trinity Mini",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "arcee-ai/trinity-mini:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Arcee AI: Trinity Mini (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "arcee-ai/virtuoso-large",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 64000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Arcee AI: Virtuoso Large",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-05-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "arliai/qwq-32b-arliai-rpr-v1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ArliAI: QwQ 32B RpR v1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "arliai/qwq-32b-arliai-rpr-v1:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ArliAI: QwQ 32B RpR v1 (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "baidu/ernie-4.5-21b-a3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 120000,
                "output": 8000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Baidu: ERNIE 4.5 21B A3B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "baidu/ernie-4.5-21b-a3b-thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Baidu: ERNIE 4.5 21B A3B Thinking",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "baidu/ernie-4.5-300b-a47b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 123000,
                "output": 12000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Baidu: ERNIE 4.5 300B A47B ",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-06-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "baidu/ernie-4.5-vl-28b-a3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 30000,
                "output": 8000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Baidu: ERNIE 4.5 VL 28B A3B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "baidu/ernie-4.5-vl-424b-a47b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 123000,
                "output": 16000
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["text"]
            },
            "name": "Baidu: ERNIE 4.5 VL 424B A47B ",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-06-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bytedance-seed/seed-1.6",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 32768
            },
            "modalities": {
                "input": ["image", "text", "video"],
                "output": ["text"]
            },
            "name": "ByteDance Seed: Seed 1.6",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bytedance-seed/seed-1.6-flash",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 16384
            },
            "modalities": {
                "input": ["image", "text", "video"],
                "output": ["text"]
            },
            "name": "ByteDance Seed: Seed 1.6 Flash",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bytedance/ui-tars-1.5-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 2048
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["text"]
            },
            "name": "ByteDance: UI-TARS 7B ",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "cognitivecomputations/dolphin3.0-mistral-24b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Dolphin3.0 Mistral 24B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "cognitivecomputations/dolphin3.0-mistral-24b:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Dolphin3.0 Mistral 24B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "cognitivecomputations/dolphin3.0-r1-mistral-24b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Dolphin3.0 R1 Mistral 24B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "cognitivecomputations/dolphin3.0-r1-mistral-24b:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Dolphin3.0 R1 Mistral 24B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cognitivecomputations/dolphin-mistral-24b-venice-edition:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Venice: Uncensored (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cognitivecomputations/dolphin-mixtral-8x22b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16000,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Dolphin 2.9.2 Mixtral 8x22B ",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-06-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cohere/command",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": 4000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cohere: Command",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-03-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cohere/command-a",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cohere: Command A",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cohere/command-r",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cohere: Command R",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-03-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cohere/command-r-03-2024",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cohere: Command R (03-2024)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-03-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cohere/command-r-08-2024",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cohere: Command R (08-2024)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-08-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cohere/command-r7b-12-2024",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cohere: Command R7B (12-2024)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-12-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cohere/command-r-plus",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cohere: Command R+",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-04-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cohere/command-r-plus-04-2024",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cohere: Command R+ (04-2024)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-04-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cohere/command-r-plus-08-2024",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Cohere: Command R+ (08-2024)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-08-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepcogito/cogito-v2.1-671b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Deep Cogito: Cogito v2.1 671B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-11-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "deepcogito/cogito-v2-preview-llama-109b-moe",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32767,
                "output": null
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["text"]
            },
            "name": "Cogito V2 Preview Llama 109B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "deepcogito/cogito-v2-preview-llama-405b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Deep Cogito: Cogito V2 Preview Llama 405B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "deepcogito/cogito-v2-preview-llama-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Deep Cogito: Cogito V2 Preview Llama 70B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-chat",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": 163840
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: DeepSeek V3",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-12-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-chat-v3-0324",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: DeepSeek V3 0324",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-chat-v3-0324:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": 163840
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: DeepSeek V3 0324 (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-chat-v3.1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 7168
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: DeepSeek V3.1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-prover-v2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: DeepSeek Prover V2",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-r1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": 163840
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: R1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-01-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-r1-0528",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: R1 0528",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-05-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-r1-0528:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: R1 0528 (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-05-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-r1-0528-qwen3-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 32000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: DeepSeek R1 0528 Qwen3 8B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-05-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-r1-0528-qwen3-8b:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: Deepseek R1 0528 Qwen3 8B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-05-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-r1:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: R1 (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-01-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-r1-distill-llama-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: R1 Distill Llama 70B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-01-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-r1-distill-llama-70b:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: R1 Distill Llama 70B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-01-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-r1-distill-llama-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32000,
                "output": 32000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: R1 Distill Llama 8B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-r1-distill-qwen-14b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: R1 Distill Qwen 14B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-01-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-r1-distill-qwen-14b:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 64000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: R1 Distill Qwen 14B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-01-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-r1-distill-qwen-1.5b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: R1 Distill Qwen 1.5B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-01-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-r1-distill-qwen-32b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: R1 Distill Qwen 32B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-01-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-v3.1-terminus",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: DeepSeek V3.1 Terminus",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-v3.1-terminus:exacto",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: DeepSeek V3.1 Terminus (exacto)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-v3.2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: DeepSeek V3.2",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-v3.2-exp",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: DeepSeek V3.2 Exp",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-v3.2-speciale",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: DeepSeek V3.2 Speciale",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-v3-base",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek: DeepSeek V3 Base",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "eleutherai/llemma_7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "EleutherAI: Llemma 7b",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "essentialai/rnj-1-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "EssentialAI: Rnj 1 Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "featherless/qwerky-72b:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qrwkv 72B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-2.0-flash-001",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image", "file", "audio", "video"],
                "output": ["text"]
            },
            "name": "Google: Gemini 2.0 Flash",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-2.0-flash-exp:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Google: Gemini 2.0 Flash Experimental (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-12-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-2.0-flash-lite-001",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image", "file", "audio", "video"],
                "output": ["text"]
            },
            "name": "Google: Gemini 2.0 Flash Lite",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-2.5-flash-image",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 32768
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["image", "text"]
            },
            "name": "Google: Gemini 2.5 Flash Image (Nano Banana)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-2.5-flash-image-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 32768
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["image", "text"]
            },
            "name": "Google: Gemini 2.5 Flash Image Preview (Nano Banana)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-2.5-flash-lite",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image", "file", "audio", "video"],
                "output": ["text"]
            },
            "name": "Google: Gemini 2.5 Flash Lite",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-2.5-flash-lite-preview-06-17",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["file", "image", "text"],
                "output": ["text"]
            },
            "name": "Google: Gemini 2.5 Flash Lite Preview 06-17",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-06-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-2.5-flash-lite-preview-09-2025",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image", "file", "audio", "video"],
                "output": ["text"]
            },
            "name": "Google: Gemini 2.5 Flash Lite Preview 09-2025",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-2.5-flash-preview-09-2025",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65536
            },
            "modalities": {
                "input": ["image", "file", "text", "audio", "video"],
                "output": ["text"]
            },
            "name": "Google: Gemini 2.5 Flash Preview 09-2025",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-2.5-pro-exp-03-25",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image", "file"],
                "output": ["text"]
            },
            "name": "Google: Gemini 2.5 Pro Experimental",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-2.5-pro-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65536
            },
            "modalities": {
                "input": ["file", "image", "text", "audio"],
                "output": ["text"]
            },
            "name": "Google: Gemini 2.5 Pro Preview 06-05",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-06-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-2.5-pro-preview-05-06",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image", "file", "audio", "video"],
                "output": ["text"]
            },
            "name": "Google: Gemini 2.5 Pro Preview 05-06",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-05-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-3-flash-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image", "file", "audio", "video"],
                "output": ["text"]
            },
            "name": "Google: Gemini 3 Flash Preview",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-3-pro-image-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": 32768
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["image", "text"]
            },
            "name": "Google: Nano Banana Pro (Gemini 3 Pro Image Preview)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-11-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-3-pro-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image", "file", "audio", "video"],
                "output": ["text"]
            },
            "name": "Google: Gemini 3 Pro Preview",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-11-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-flash-1.5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1000000,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Google: Gemini 1.5 Flash ",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-05-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-flash-1.5-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1000000,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Google: Gemini 1.5 Flash 8B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-10-03",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-pro-1.5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2000000,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Google: Gemini 1.5 Pro",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-04-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemma-2-27b-it",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Google: Gemma 2 27B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-07-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemma-2-9b-it",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Google: Gemma 2 9B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-06-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemma-2-9b-it:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Google: Gemma 2 9B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-06-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemma-3-12b-it:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Google: Gemma 3 12B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemma-3-27b-it:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Google: Gemma 3 27B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemma-3-4b-it:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Google: Gemma 3 4B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemma-3n-e2b-it:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": 2048
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Google: Gemma 3n 2B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemma-3n-e4b-it",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Google: Gemma 3n 4B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-05-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemma-3n-e4b-it:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": 2048
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Google: Gemma 3n 4B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-05-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "gryphe/mythomax-l2-13b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MythoMax 13B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2023-07-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ibm-granite/granite-4.0-h-micro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "IBM: Granite 4.0 Micro",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "inception/mercury",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Inception: Mercury",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-06-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "inception/mercury-coder",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Inception: Mercury Coder",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "infermatic/mn-inferor-12b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Infermatic: Mistral Nemo Inferor 12B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-11-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "inflection/inflection-3-pi",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8000,
                "output": 1024
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Inflection: Inflection 3 Pi",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-10-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "inflection/inflection-3-productivity",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8000,
                "output": 1024
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Inflection: Inflection 3 Productivity",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-10-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "kwaipilot/kat-coder-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 128000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kwaipilot: KAT-Coder-Pro V1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-11-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "kwaipilot/kat-coder-pro:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 128000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kwaipilot: KAT-Coder-Pro V1 (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-11-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "liquid/lfm-2.2-6b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "LiquidAI/LFM2-2.6B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "liquid/lfm2-8b-a1b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "LiquidAI/LFM2-8B-A1B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "liquid/lfm-3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Liquid: LFM 3B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-01-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "liquid/lfm-40b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Liquid: LFM 40B MoE",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-09-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "liquid/lfm-7b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Liquid: LFM 7B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-01-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mancer/weaver",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8000,
                "output": 2000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mancer: Weaver (alpha)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2023-08-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "meituan/longcat-flash-chat",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meituan: LongCat Flash Chat",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-3.1-405b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta: Llama 3.1 405B (base)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-08-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-3.1-405b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 10000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta: Llama 3.1 405B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-07-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-3.1-405b-instruct:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta: Llama 3.1 405B Instruct (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-07-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-3.1-70b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta: Llama 3.1 70B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-07-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-3.1-8b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta: Llama 3.1 8B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-07-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-3.2-11b-vision-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Meta: Llama 3.2 11B Vision Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-09-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-3.2-11b-vision-instruct:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 2048
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Meta: Llama 3.2 11B Vision Instruct (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-09-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-3.2-1b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 60000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta: Llama 3.2 1B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-09-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-3.2-3b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta: Llama 3.2 3B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-09-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-3.2-3b-instruct:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta: Llama 3.2 3B Instruct (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-09-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-3.2-90b-vision-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Meta: Llama 3.2 90B Vision Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-09-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-3.3-70b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta: Llama 3.3 70B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-12-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-3.3-70b-instruct:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta: Llama 3.3 70B Instruct (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-12-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-3-70b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta: Llama 3 70B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-04-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-3-8b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta: Llama 3 8B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-04-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-4-maverick",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Meta: Llama 4 Maverick",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-4-scout",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 327680,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Meta: Llama 4 Scout",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-guard-2-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta: LlamaGuard 2 8B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-05-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-guard-3-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama Guard 3 8B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta-llama/llama-guard-4-12b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["text"]
            },
            "name": "Meta: Llama Guard 4 12B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "microsoft/mai-ds-r1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Microsoft: MAI DS R1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "microsoft/mai-ds-r1:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Microsoft: MAI DS R1 (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "microsoft/phi-3.5-mini-128k-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Microsoft: Phi-3.5 Mini 128K Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "microsoft/phi-3-medium-128k-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Microsoft: Phi-3 Medium 128K Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-05-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "microsoft/phi-3-mini-128k-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Microsoft: Phi-3 Mini 128K Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-05-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "microsoft/phi-4-multimodal-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Microsoft: Phi 4 Multimodal Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "microsoft/phi-4-reasoning-plus",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Microsoft: Phi 4 Reasoning Plus",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-05-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "microsoft/wizardlm-2-8x22b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "WizardLM-2 8x22B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-04-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "minimax/minimax-01",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1000192,
                "output": 1000192
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "MiniMax: MiniMax-01",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-01-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "minimax/minimax-m1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1000000,
                "output": 40000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniMax: MiniMax M1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-06-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "minimax/minimax-m2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 196608,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniMax: MiniMax M2",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "minimax/minimax-m2.1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 196608,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniMax: MiniMax M2.1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.3,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "mistralai/codestral-2501",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Codestral 2501",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-01-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.3,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "mistralai/codestral-2508",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Codestral 2508",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/devstral-2512",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Devstral 2 2512",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/devstral-2512:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Devstral 2 2512 (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/devstral-medium",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Devstral Medium",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/devstral-small",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Devstral Small 1.1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/devstral-small-2505",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Devstral Small 2505",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-05-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/devstral-small-2505:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Devstral Small 2505 (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-05-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/magistral-medium-2506",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": 40000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Magistral Medium 2506",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-06-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/magistral-medium-2506:thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": 40000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Magistral Medium 2506 (thinking)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-06-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/magistral-small-2506",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40000,
                "output": 40000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Magistral Small 2506",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-06-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/ministral-14b-2512",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Mistral: Ministral 3 14B 2512",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/ministral-3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Ministral 3B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-10-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/ministral-3b-2512",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Mistral: Ministral 3 3B 2512",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/ministral-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Ministral 8B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-10-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/ministral-8b-2512",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Mistral: Ministral 3 8B 2512",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-7b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Mistral 7B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-05-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-7b-instruct:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Mistral 7B Instruct (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-05-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-7b-instruct-v0.1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2824,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Mistral 7B Instruct v0.1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2023-09-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-7b-instruct-v0.2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Mistral 7B Instruct v0.2",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2023-12-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-7b-instruct-v0.3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Mistral 7B Instruct v0.3",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-05-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-large",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Large",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-02-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-large-2407",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Large 2407",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-11-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-large-2411",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Large 2411",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-11-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-large-2512",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Mistral: Mistral Large 3 2512",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-medium-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Mistral: Mistral Medium 3",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-05-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-medium-3.1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Mistral: Mistral Medium 3.1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-nemo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Mistral Nemo",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-07-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-nemo:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 128000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Mistral Nemo (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-07-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-saba",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Saba",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-small",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Small",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-01-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-small-24b-instruct-2501",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Mistral Small 3",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-01-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-small-24b-instruct-2501:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Mistral Small 3 (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-01-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-small-3.1-24b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Mistral: Mistral Small 3.1 24B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-small-3.1-24b-instruct:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Mistral: Mistral Small 3.1 24B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-small-3.2-24b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["text"]
            },
            "name": "Mistral: Mistral Small 3.2 24B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-06-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-small-3.2-24b-instruct:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["text"]
            },
            "name": "Mistral: Mistral Small 3.2 24B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-06-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-small-creative",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Mistral Small Creative",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mistral-tiny",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Tiny",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-01-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mixtral-8x22b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Mixtral 8x22B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-04-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/mixtral-8x7b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral: Mixtral 8x7B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2023-12-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/pixtral-12b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Mistral: Pixtral 12B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-09-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/pixtral-large-2411",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Mistral: Pixtral Large 2411",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-11-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistralai/voxtral-small-24b-2507",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32000,
                "output": null
            },
            "modalities": {
                "input": ["text", "audio"],
                "output": ["text"]
            },
            "name": "Mistral: Voxtral Small 24B 2507",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "moonshotai/kimi-dev-72b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MoonshotAI: Kimi Dev 72B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-06-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "moonshotai/kimi-dev-72b:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MoonshotAI: Kimi Dev 72B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-06-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "moonshotai/kimi-k2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MoonshotAI: Kimi K2 0711",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "moonshotai/kimi-k2-0905",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 262144
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MoonshotAI: Kimi K2 0905",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "moonshotai/kimi-k2-0905:exacto",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MoonshotAI: Kimi K2 0905 (exacto)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "moonshotai/kimi-k2:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MoonshotAI: Kimi K2 0711 (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "moonshotai/kimi-k2-thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 65535
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MoonshotAI: Kimi K2 Thinking",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-11-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "moonshotai/kimi-vl-a3b-thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["text"]
            },
            "name": "MoonshotAI: Kimi VL A3B Thinking",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "moonshotai/kimi-vl-a3b-thinking:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["text"]
            },
            "name": "MoonshotAI: Kimi VL A3B Thinking (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "morph/morph-v3-fast",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 81920,
                "output": 38000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Morph: Morph V3 Fast",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "morph/morph-v3-large",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Morph: Morph V3 Large",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "neversleep/llama-3.1-lumimaid-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "NeverSleep: Lumimaid v0.2 8B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-09-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "neversleep/llama-3-lumimaid-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "NeverSleep: Llama 3 Lumimaid 70B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-05-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "neversleep/noromaid-20b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Noromaid 20B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2023-11-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nex-agi/deepseek-v3.1-nex-n1:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 163840
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nex AGI: DeepSeek V3.1 Nex N1 (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "nousresearch/deephermes-3-llama-3-8b-preview:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nous: DeepHermes 3 Llama 3 8B Preview (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "nousresearch/deephermes-3-mistral-24b-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nous: DeepHermes 3 Mistral 24B Preview",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-05-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "nousresearch/hermes-2-pro-llama-3-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": 2048
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "NousResearch: Hermes 2 Pro - Llama-3 8B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-05-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nousresearch/hermes-3-llama-3.1-405b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nous: Hermes 3 405B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-08-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nousresearch/hermes-3-llama-3.1-405b:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nous: Hermes 3 405B Instruct (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-08-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nousresearch/hermes-3-llama-3.1-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nous: Hermes 3 70B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-08-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nousresearch/hermes-4-405b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nous: Hermes 4 405B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nousresearch/hermes-4-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nous: Hermes 4 70B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nousresearch/nous-hermes-2-mixtral-8x7b-dpo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 2048
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nous: Hermes 2 Mixtral 8x7B DPO",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-01-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "nvidia/llama-3.1-nemotron-70b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "NVIDIA: Llama 3.1 Nemotron 70B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-10-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "nvidia/llama-3.1-nemotron-ultra-253b-v1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "NVIDIA: Llama 3.1 Nemotron Ultra 253B v1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "nvidia/llama-3.1-nemotron-ultra-253b-v1:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "NVIDIA: Llama 3.1 Nemotron Ultra 253B v1 (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "nvidia/llama-3.3-nemotron-super-49b-v1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "NVIDIA: Llama 3.3 Nemotron Super 49B v1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "nvidia/llama-3.3-nemotron-super-49b-v1.5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "NVIDIA: Llama 3.3 Nemotron Super 49B V1.5",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nvidia/nemotron-3-nano-30b-a3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 262144
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "NVIDIA: Nemotron 3 Nano 30B A3B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nvidia/nemotron-3-nano-30b-a3b:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "NVIDIA: Nemotron 3 Nano 30B A3B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nvidia/nemotron-nano-12b-v2-vl",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["image", "text", "video"],
                "output": ["text"]
            },
            "name": "NVIDIA: Nemotron Nano 12B 2 VL",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nvidia/nemotron-nano-12b-v2-vl:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 128000
            },
            "modalities": {
                "input": ["image", "text", "video"],
                "output": ["text"]
            },
            "name": "NVIDIA: Nemotron Nano 12B 2 VL (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nvidia/nemotron-nano-9b-v2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "NVIDIA: Nemotron Nano 9B V2",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "nvidia/nemotron-nano-9b-v2:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "NVIDIA: Nemotron Nano 9B V2 (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/chatgpt-4o-latest",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "OpenAI: ChatGPT-4o",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-08-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai/codex-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["text"]
            },
            "name": "OpenAI: Codex Mini",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-05-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai/gpt-3.5-turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16385,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-3.5 Turbo",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2023-05-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai/gpt-3.5-turbo-0613",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4095,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-3.5 Turbo (older v0613)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-01-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai/gpt-3.5-turbo-16k",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16385,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-3.5 Turbo 16k",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2023-08-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai/gpt-3.5-turbo-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4095,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-3.5 Turbo Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2023-09-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/gpt-4",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8191,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-4",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2023-05-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/gpt-4-0314",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8191,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-4 (older v0314)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2023-05-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/gpt-4.1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["image", "text", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-4.1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/gpt-4-1106-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-4 Turbo (older v1106)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2023-11-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/gpt-4.1-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["image", "text", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-4.1 Mini",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/gpt-4.1-nano",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["image", "text", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-4.1 Nano",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/gpt-4o",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-4o",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-05-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/gpt-4o:extended",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-4o (extended)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-05-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/gpt-4o-2024-05-13",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4096
            },
            "modalities": {
                "input": ["text", "image", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-4o (2024-05-13)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-05-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/gpt-4o-2024-08-06",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-4o (2024-08-06)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-08-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/gpt-4o-2024-11-20",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-4o (2024-11-20)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-11-20",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/gpt-4o-audio-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["audio", "text"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-4o Audio",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/gpt-4o-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-4o-mini",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-07-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/gpt-4o-mini-2024-07-18",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-4o-mini (2024-07-18)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-07-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/gpt-4o-mini-search-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-4o-mini Search Preview",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/gpt-4o-search-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-4o Search Preview",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/gpt-4-turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4096
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-4 Turbo",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-04-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.03,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/gpt-4-turbo-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-4 Turbo Preview",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-01-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "openai/gpt-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-5",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "openai/gpt-5.1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["image", "text", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-5.1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-11-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "openai/gpt-5.1-chat",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["file", "image", "text"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-5.1 Chat",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-11-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "openai/gpt-5.1-codex",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-5.1-Codex",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-11-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "openai/gpt-5.1-codex-max",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-5.1-Codex-Max",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-04",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "openai/gpt-5.1-codex-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 100000
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-5.1-Codex-Mini",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-11-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "openai/gpt-5.2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["file", "image", "text"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-5.2",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "openai/gpt-5.2-chat",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["file", "image", "text"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-5.2 Chat",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "openai/gpt-5.2-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["image", "text", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-5.2 Pro",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "openai/gpt-5-chat",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["file", "image", "text"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-5 Chat",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "openai/gpt-5-codex",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-5 Codex",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "openai/gpt-5-image",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["image", "text", "file"],
                "output": ["image", "text"]
            },
            "name": "OpenAI: GPT-5 Image",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "openai/gpt-5-image-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["file", "image", "text"],
                "output": ["image", "text"]
            },
            "name": "OpenAI: GPT-5 Image Mini",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "openai/gpt-5-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-5 Mini",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "openai/gpt-5-nano",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-5 Nano",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "openai/gpt-5-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["image", "text", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: GPT-5 Pro",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai/gpt-oss-120b:exacto",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI: gpt-oss-120b (exacto)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai/gpt-oss-120b:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI: gpt-oss-120b (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai/gpt-oss-20b:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI: gpt-oss-20b (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai/gpt-oss-safeguard-20b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI: gpt-oss-safeguard-20b",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.015,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/o1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text", "image", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: o1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-12-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.015,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/o1-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI: o1-mini",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-09-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.015,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/o1-mini-2024-09-12",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenAI: o1-mini (2024-09-12)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-09-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.015,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "openai/o1-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text", "image", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: o1-pro",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai/o3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["image", "text", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: o3",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai/o3-deep-research",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["image", "text", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: o3 Deep Research",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai/o3-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: o3 Mini",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-01-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai/o3-mini-high",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: o3 Mini High",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai/o3-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text", "file", "image"],
                "output": ["text"]
            },
            "name": "OpenAI: o3 Pro",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-06-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai/o4-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["image", "text", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: o4 Mini",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai/o4-mini-deep-research",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["file", "image", "text"],
                "output": ["text"]
            },
            "name": "OpenAI: o4 Mini Deep Research",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai/o4-mini-high",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["image", "text", "file"],
                "output": ["text"]
            },
            "name": "OpenAI: o4 Mini High",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "opengvlab/internvl3-14b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 12288,
                "output": null
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["text"]
            },
            "name": "OpenGVLab: InternVL3 14B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "opengvlab/internvl3-78b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 32768
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["text"]
            },
            "name": "OpenGVLab: InternVL3 78B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openrouter/auto",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2000000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Auto Router",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2023-11-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openrouter/bodybuilder",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Body Builder (beta)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "perplexity/r1-1776",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Perplexity: R1 1776",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.001,
                "inputCacheHit": null,
                "output": 0.001
            },
            "extendedThinking": false,
            "id": "perplexity/sonar",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 127072,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Perplexity: Sonar",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-01-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.001,
                "inputCacheHit": null,
                "output": 0.001
            },
            "extendedThinking": false,
            "id": "perplexity/sonar-deep-research",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Perplexity: Sonar Deep Research",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.001,
                "inputCacheHit": null,
                "output": 0.001
            },
            "extendedThinking": false,
            "id": "perplexity/sonar-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 8000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Perplexity: Sonar Pro",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.001,
                "inputCacheHit": null,
                "output": 0.001
            },
            "extendedThinking": false,
            "id": "perplexity/sonar-pro-search",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 8000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Perplexity: Sonar Pro Search",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.001,
                "inputCacheHit": null,
                "output": 0.001
            },
            "extendedThinking": false,
            "id": "perplexity/sonar-reasoning",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 127000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Perplexity: Sonar Reasoning",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-01-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.001,
                "inputCacheHit": null,
                "output": 0.001
            },
            "extendedThinking": false,
            "id": "perplexity/sonar-reasoning-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Perplexity: Sonar Reasoning Pro",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "prime-intellect/intellect-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Prime Intellect: INTELLECT-3",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-11-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "pygmalionai/mythalion-13b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Pygmalion: Mythalion 13B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2023-09-02",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen-2.5-72b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5 72B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-09-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen-2.5-72b-instruct:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5 72B Instruct (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-09-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen-2.5-7b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen2.5 7B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-10-16",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen-2.5-coder-32b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5 Coder 32B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-11-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen-2.5-coder-32b-instruct:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen2.5 Coder 32B Instruct (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-11-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen2.5-coder-7b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen2.5 Coder 7B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen2.5-vl-32b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen2.5 VL 32B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen2.5-vl-32b-instruct:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen2.5 VL 32B Instruct (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen2.5-vl-72b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen2.5 VL 72B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen2.5-vl-72b-instruct:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen2.5 VL 72B Instruct (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen-2.5-vl-7b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen2.5-VL 7B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-08-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen-2.5-vl-7b-instruct:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen2.5-VL 7B Instruct (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-08-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen-2-72b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen 2 72B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-06-07",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-14b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": 40960
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 14B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-14b:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 14B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-235b-a22b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": 40960
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 235B A22B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-235b-a22b:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 235B A22B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-235b-a22b-2507",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 235B A22B Instruct 2507",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-235b-a22b-thinking-2507",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 262144
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 235B A22B Thinking 2507",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-30b-a3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": 40960
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 30B A3B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-30b-a3b:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 30B A3B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-30b-a3b-instruct-2507",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 262144
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 30B A3B Instruct 2507",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-30b-a3b-thinking-2507",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 30B A3B Thinking 2507",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-32b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": 40960
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 32B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-4b:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 4B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 20000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 8B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-8b:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": 40960
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 8B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-coder",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 262144
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 Coder 480B A35B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-coder:exacto",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 Coder 480B A35B (exacto)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-coder:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262000,
                "output": 262000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 Coder 480B A35B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-coder-30b-a3b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 160000,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 Coder 30B A3B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-31",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-coder-flash",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 Coder Flash",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-coder-plus",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 Coder Plus",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-max",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 Max",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-next-80b-a3b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 Next 80B A3B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-next-80b-a3b-thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 262144
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 Next 80B A3B Thinking",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-vl-235b-a22b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 VL 235B A22B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-vl-235b-a22b-thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 262144
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 VL 235B A22B Thinking",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-vl-30b-a3b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 VL 30B A3B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-vl-30b-a3b-thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 VL 30B A3B Thinking",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-06",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-vl-32b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 VL 32B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-23",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-vl-8b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 32768
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 VL 8B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen3-vl-8b-thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 32768
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen3 VL 8B Thinking",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-10-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen-max",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen-Max ",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen-plus",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen-Plus",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen-plus-2025-07-28",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1000000,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen Plus 0728",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen-plus-2025-07-28:thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1000000,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen Plus 0728 (thinking)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen-turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1000000,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen-Turbo",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen-vl-max",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen VL Max",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-01",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwen-vl-plus",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 7500,
                "output": 1500
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Qwen: Qwen VL Plus",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-02-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwq-32b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: QwQ 32B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwq-32b:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: QwQ 32B (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-05",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "qwen/qwq-32b-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen: QwQ 32B Preview",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-11-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "raifle/sorcererlm-8x22b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "SorcererLM 8x22B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-11-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "rekaai/reka-flash-3:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Reka: Flash 3 (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-12",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "relace/relace-apply-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 128000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Relace: Relace Apply 3",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "relace/relace-search",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 128000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Relace: Relace Search",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.015,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "sao10k/l3.1-70b-hanami-x1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Sao10K: Llama 3.1 70B Hanami x1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-01-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.015,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "sao10k/l3.1-euryale-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Sao10K: Llama 3.1 Euryale 70B v2.2",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-08-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.015,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "sao10k/l3.3-euryale-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Sao10K: Llama 3.3 Euryale 70B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-12-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.015,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "sao10k/l3-euryale-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Sao10k: Llama 3 Euryale 70B v2.1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-06-18",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.015,
                "inputCacheHit": null,
                "output": 0.06
            },
            "extendedThinking": false,
            "id": "sao10k/l3-lunaris-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Sao10K: Llama 3 8B Lunaris",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-08-13",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "sarvamai/sarvam-m:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Sarvam AI: Sarvam-M (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-05-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "scb10x/llama3.1-typhoon2-70b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Typhoon2 70B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "shisa-ai/shisa-v2-llama3.3-70b:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Shisa AI: Shisa V2 Llama 3.3 70B  (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "sophosympatheia/midnight-rose-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": 2048
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Midnight Rose 70B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-03-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "switchpoint/router",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Switchpoint Router",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "tencent/hunyuan-a13b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Tencent: Hunyuan A13B Instruct",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "tencent/hunyuan-a13b-instruct:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Tencent: Hunyuan A13B Instruct (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "thedrummer/anubis-70b-v1.1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "TheDrummer: Anubis 70B V1.1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-06-29",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "thedrummer/anubis-pro-105b-v1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "TheDrummer: Anubis Pro 105B V1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "thedrummer/cydonia-24b-v4.1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "TheDrummer: Cydonia 24B V4.1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "thedrummer/rocinante-12b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "TheDrummer: Rocinante 12B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-09-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "thedrummer/skyfall-36b-v2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "TheDrummer: Skyfall 36B V2",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-03-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "thedrummer/unslopnemo-12b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "TheDrummer: UnslopNemo 12B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-11-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "thudm/glm-4.1v-9b-thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": 8000
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["text"]
            },
            "name": "THUDM: GLM 4.1V 9B Thinking",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "thudm/glm-4-32b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32000,
                "output": 32000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "THUDM: GLM 4 32B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "thudm/glm-z1-32b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "THUDM: GLM Z1 32B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-17",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "tngtech/deepseek-r1t2-chimera",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": 163840
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "TNG: DeepSeek R1T2 Chimera",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "tngtech/deepseek-r1t2-chimera:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "TNG: DeepSeek R1T2 Chimera (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "tngtech/deepseek-r1t-chimera",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": 163840
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "TNG: DeepSeek R1T Chimera",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "tngtech/deepseek-r1t-chimera:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "TNG: DeepSeek R1T Chimera (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-27",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "tngtech/tng-r1t-chimera",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "TNG: R1T Chimera",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-11-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "tngtech/tng-r1t-chimera:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "TNG: R1T Chimera (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-11-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "undi95/remm-slerp-l2-13b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 6144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ReMM SLERP 13B",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2023-07-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "x-ai/grok-2-1212",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "xAI: Grok 2 1212",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "x-ai/grok-2-vision-1212",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "xAI: Grok 2 Vision 1212",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "x-ai/grok-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "xAI: Grok 3",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-06-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "x-ai/grok-3-beta",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "xAI: Grok 3 Beta",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "x-ai/grok-3-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "xAI: Grok 3 Mini",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-06-10",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "x-ai/grok-3-mini-beta",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "xAI: Grok 3 Mini Beta",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-04-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "x-ai/grok-4",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": null
            },
            "modalities": {
                "input": ["image", "text"],
                "output": ["text"]
            },
            "name": "xAI: Grok 4",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-09",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "x-ai/grok-4.1-fast",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2000000,
                "output": 30000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "xAI: Grok 4.1 Fast",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-11-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "x-ai/grok-4-fast",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2000000,
                "output": 30000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "xAI: Grok 4 Fast",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "x-ai/grok-code-fast-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 10000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "xAI: Grok Code Fast 1",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-26",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "x-ai/grok-vision-beta",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "xAI: Grok Vision Beta",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2024-11-19",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "xiaomi/mimo-v2-flash:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Xiaomi: MiMo-V2-Flash (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-ai/glm-4-32b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Z.AI: GLM 4 32B ",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-24",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-ai/glm-4.5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Z.AI: GLM 4.5",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-ai/glm-4.5-air",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Z.AI: GLM 4.5 Air",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-ai/glm-4.5-air:free",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 96000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Z.AI: GLM 4.5 Air (free)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-07-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-ai/glm-4.5v",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "Z.AI: GLM 4.5V",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-08-11",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-ai/glm-4.6",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 202752,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Z.AI: GLM 4.6",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-ai/glm-4.6:exacto",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 204800,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Z.AI: GLM 4.6 (exacto)",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-09-30",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-ai/glm-4.6v",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["image", "text", "video"],
                "output": ["text"]
            },
            "name": "Z.AI: GLM 4.6V",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-08",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "z-ai/glm-4.7",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 202752,
                "output": 65535
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Z.AI: GLM 4.7",
            "openWeights": false,
            "provider": "OpenRouter",
            "providerDoc": "https://openrouter.ai/docs",
            "providerEnv": ["OPENROUTER_API_KEY"],
            "providerId": "open-router",
            "providerModelsDevId": "openrouter",
            "providerNpm": "@ai-sdk/openrouter",
            "reasoning": false,
            "releaseDate": "2025-12-22",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "openrouter"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "252-frequesty",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "252Frequesty",
            "openWeights": false,
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "2-b-requesty",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "2BRequesty",
            "openWeights": false,
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "content-requesty",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "contentRequesty",
            "openWeights": false,
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "page-requesty",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "pageRequesty",
            "openWeights": false,
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "u-003-c-requesty-api-key",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "u003cREQUESTY_API_KEY",
            "openWeights": false,
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "why-choose-requesty",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "why-choose-requesty",
            "openWeights": false,
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "your-requesty-api-key",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "YOUR_REQUESTY_API_KEY",
            "openWeights": false,
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2e-7,
                "inputCacheHit": 2e-7,
                "output": 8e-7
            },
            "description": "Qwen3-30B-A3B-Instruct-2507 is a 30.5B-parameter mixture-of-experts language model from Qwen, with 3.3B active parameters per inference. It operates in non-thinking mode and is designed for high-quality instruction following, multilingual understanding, and agentic tool use. Post-trained on instruction data, it demonstrates competitive performance across reasoning (AIME, ZebraLogic), coding (MultiPL-E, LiveCodeBench), and alignment (IFEval, WritingBench) benchmarks. It outperforms its non-instruct variant on subjective and open-ended tasks while retaining strong factual and coding performance.",
            "extendedThinking": false,
            "id": "alibaba-qwen-3-30-b-a-3-b-instruct-2507",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "alibaba/qwen3-30b-a3b-instruct-2507",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-07-31T09:17:43.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 8e-8,
                "output": 0.0000015
            },
            "extendedThinking": false,
            "id": "alibaba-qwen-3-coder-flash",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "alibaba/qwen3-coder-flash",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-07-24T09:17:43.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000001,
                "inputCacheHit": null,
                "output": 0.000005
            },
            "extendedThinking": false,
            "id": "alibaba-qwen-3-coder-plus",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "alibaba/qwen3-coder-plus",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-07-24T09:17:43.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 8.61e-7,
                "inputCacheHit": null,
                "output": 0.000003441
            },
            "description": "This is the best-performing model in the Qwen series. It is ideal for complex, multi-step tasks.",
            "extendedThinking": false,
            "id": "alibaba-qwen-3-max",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 65536
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "alibaba/qwen3-max",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-09-10T17:22:09.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000016,
                "inputCacheHit": 0.0000016,
                "output": 0.0000064
            },
            "description": "Qwen3, the latest generation in the Qwen large language model series, features both dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual support, and advanced agent tasks. Its unique ability to switch seamlessly between a thinking mode for complex reasoning and a non-thinking mode for efficient dialogue ensures versatile, high-quality performance.\n\nSignificantly outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics, coding, commonsense reasoning, creative writing, and interactive dialogue capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3 billion activated), 48 layers, 128 experts (8 activated per task), and supports up to 131K token contexts with YaRN, setting a new standard among open-source models.",
            "extendedThinking": false,
            "id": "alibaba-qwen-max",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "alibaba/qwen-max",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-28T23:16:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4e-7,
                "inputCacheHit": 4e-7,
                "output": 0.0000012
            },
            "description": "Qwen3, the latest generation in the Qwen large language model series, features both dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual support, and advanced agent tasks. Its unique ability to switch seamlessly between a thinking mode for complex reasoning and a non-thinking mode for efficient dialogue ensures versatile, high-quality performance.\n\nSignificantly outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics, coding, commonsense reasoning, creative writing, and interactive dialogue capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3 billion activated), 48 layers, 128 experts (8 activated per task), and supports up to 131K token contexts with YaRN, setting a new standard among open-source models.",
            "extendedThinking": false,
            "id": "alibaba-qwen-plus",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "alibaba/qwen-plus",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-28T23:16:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 5e-8,
                "inputCacheHit": 5e-8,
                "output": 2e-7
            },
            "description": "Qwen3, the latest generation in the Qwen large language model series, features both dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual support, and advanced agent tasks. Its unique ability to switch seamlessly between a thinking mode for complex reasoning and a non-thinking mode for efficient dialogue ensures versatile, high-quality performance.\n\nSignificantly outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics, coding, commonsense reasoning, creative writing, and interactive dialogue capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3 billion activated), 48 layers, 128 experts (8 activated per task), and supports up to 131K token contexts with YaRN, setting a new standard among open-source models.",
            "extendedThinking": false,
            "id": "alibaba-qwen-turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1000000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "alibaba/qwen-turbo",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-28T23:16:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 8e-7,
                "inputCacheHit": 8e-8,
                "output": 0.000004
            },
            "description": "Anthropic's fastest model. Intelligence at blazing speeds.",
            "extendedThinking": false,
            "id": "anthropic-claude-3-5-haiku",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "anthropic/claude-3-5-haiku",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-11-04T00:00:00.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "anthropic-claude-3-7-sonnet",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "anthropic/claude-3-7-sonnet",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2024-06-20T01:00:00.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2.5e-7,
                "inputCacheHit": 3e-8,
                "output": 0.00000125
            },
            "description": "Fastest and most compact model for near-instant responsiveness. Quick and accurate targeted performance.",
            "extendedThinking": false,
            "id": "anthropic-claude-3-haiku",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 4096
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "anthropic/claude-3-haiku",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-11-04T00:00:00.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000001,
                "inputCacheHit": 1e-7,
                "output": 0.000005
            },
            "description": "Anthropic Haiku 4.5",
            "extendedThinking": false,
            "id": "anthropic-claude-haiku-4-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "anthropic/claude-haiku-4-5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-11-24T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000015,
                "inputCacheHit": 0.0000015,
                "output": 0.000075
            },
            "description": "Claude Opus 4 is Anthropic's most powerful model yet and the best coding model in the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers sustained performance on long-running tasks that require focused effort and thousands of steps, with the ability to work continuously for several hoursdramatically outperforming all Sonnet models and significantly expanding what AI agents can accomplish.",
            "extendedThinking": true,
            "id": "anthropic-claude-opus-4",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 32000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "anthropic/claude-opus-4",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:27:25.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000015,
                "inputCacheHit": 0.0000015,
                "output": 0.000075
            },
            "description": "Claude Opus 4 is Anthropic's most powerful model yet and the best coding model in the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers sustained performance on long-running tasks that require focused effort and thousands of steps, with the ability to work continuously for several hoursdramatically outperforming all Sonnet models and significantly expanding what AI agents can accomplish.",
            "extendedThinking": true,
            "id": "anthropic-claude-opus-4-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 32000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "anthropic/claude-opus-4-1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-08-05T17:27:25.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000005,
                "inputCacheHit": 5e-7,
                "output": 0.000025
            },
            "description": "Claude Opus 4 is Anthropic's most powerful model yet and the best coding model in the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers sustained performance on long-running tasks that require focused effort and thousands of steps, with the ability to work continuously for several hoursdramatically outperforming all Sonnet models and significantly expanding what AI agents can accomplish.",
            "extendedThinking": true,
            "id": "anthropic-claude-opus-4-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "anthropic/claude-opus-4-5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-08-05T17:27:25.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Claude Sonnet 4 significantly improves on Sonnet 3.7's industry-leading capabilities, excelling in coding with a state-of-the-art 72.7% on SWE-bench. The model balances performance and efficiency for internal and external use cases, with enhanced steerability for greater control over implementations.",
            "extendedThinking": true,
            "id": "anthropic-claude-sonnet-4",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1000000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "anthropic/claude-sonnet-4",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Claude Sonnet 4.5 is Anthropic's best coding model in the world, leading on SWE-bench Verified (77.2%) and OSWorld (61.4%). It delivers sustained autonomous performance on complex tasks for over 30 hoursup from seven hours for Opus 4maintaining focus and reliability throughout the entire software development lifecycle, with enhanced capabilities in tool handling, memory management, and context processing that make it the strongest model for building complex agents.",
            "extendedThinking": true,
            "id": "anthropic-claude-sonnet-4-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1000000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "anthropic/claude-sonnet-4-5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-09-29T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 5e-7,
                "output": 0.000008
            },
            "description": "GPT-4.1 is a flagship large language model optimized for advanced instruction following, real-world software engineering, and long-context reasoning. It supports a 1 million token context window and outperforms GPT-4o and GPT-4.5 across coding (54.6% SWE-bench Verified), instruction compliance (87.4% IFEval), and multimodal understanding benchmarks. It is tuned for precise code diffs, agent reliability, and high recall in large document contexts, making it ideal for agents, IDE tooling, and enterprise knowledge retrieval.",
            "extendedThinking": false,
            "id": "azure-gpt-4-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/gpt-4.1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:05.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 5e-7,
                "output": 0.000008
            },
            "description": "GPT-4.1 is a flagship large language model optimized for advanced instruction following, real-world software engineering, and long-context reasoning. It supports a 1 million token context window and outperforms GPT-4o and GPT-4.5 across coding (54.6% SWE-bench Verified), instruction compliance (87.4% IFEval), and multimodal understanding benchmarks. It is tuned for precise code diffs, agent reliability, and high recall in large document contexts, making it ideal for agents, IDE tooling, and enterprise knowledge retrieval.",
            "extendedThinking": false,
            "id": "azure-gpt-4-1-@eastus-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/gpt-4.1@eastus2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:05.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 5e-7,
                "output": 0.000008
            },
            "description": "GPT-4.1 is a flagship large language model optimized for advanced instruction following, real-world software engineering, and long-context reasoning. It supports a 1 million token context window and outperforms GPT-4o and GPT-4.5 across coding (54.6% SWE-bench Verified), instruction compliance (87.4% IFEval), and multimodal understanding benchmarks. It is tuned for precise code diffs, agent reliability, and high recall in large document contexts, making it ideal for agents, IDE tooling, and enterprise knowledge retrieval.",
            "extendedThinking": false,
            "id": "azure-gpt-4-1-@francecentral",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/gpt-4.1@francecentral",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:05.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 5e-7,
                "output": 0.000008
            },
            "description": "GPT-4.1 is a flagship large language model optimized for advanced instruction following, real-world software engineering, and long-context reasoning. It supports a 1 million token context window and outperforms GPT-4o and GPT-4.5 across coding (54.6% SWE-bench Verified), instruction compliance (87.4% IFEval), and multimodal understanding benchmarks. It is tuned for precise code diffs, agent reliability, and high recall in large document contexts, making it ideal for agents, IDE tooling, and enterprise knowledge retrieval.",
            "extendedThinking": false,
            "id": "azure-gpt-4-1-@swedencentral",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/gpt-4.1@swedencentral",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:05.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 5e-7,
                "output": 0.000008
            },
            "description": "GPT-4.1 is a flagship large language model optimized for advanced instruction following, real-world software engineering, and long-context reasoning. It supports a 1 million token context window and outperforms GPT-4o and GPT-4.5 across coding (54.6% SWE-bench Verified), instruction compliance (87.4% IFEval), and multimodal understanding benchmarks. It is tuned for precise code diffs, agent reliability, and high recall in large document contexts, making it ideal for agents, IDE tooling, and enterprise knowledge retrieval.",
            "extendedThinking": false,
            "id": "azure-gpt-4-1-@uksouth",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/gpt-4.1@uksouth",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:05.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 5e-7,
                "output": 0.000008
            },
            "description": "GPT-4.1 is a flagship large language model optimized for advanced instruction following, real-world software engineering, and long-context reasoning. It supports a 1 million token context window and outperforms GPT-4o and GPT-4.5 across coding (54.6% SWE-bench Verified), instruction compliance (87.4% IFEval), and multimodal understanding benchmarks. It is tuned for precise code diffs, agent reliability, and high recall in large document contexts, making it ideal for agents, IDE tooling, and enterprise knowledge retrieval.",
            "extendedThinking": false,
            "id": "azure-gpt-4-1-@westus-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/gpt-4.1@westus3",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:05.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4e-7,
                "inputCacheHit": 1e-7,
                "output": 0.0000016
            },
            "description": "GPT-4.1 Mini is a mid-sized model delivering performance competitive with GPT-4o at substantially lower latency and cost. It retains a 1 million token context window and scores 45.1% on hard instruction evals, 35.8% on MultiChallenge, and 84.1% on IFEval. Mini also shows strong coding ability (e.g., 31.6% on Aiders polyglot diff benchmark) and vision understanding, making it suitable for interactive applications with tight performance constraints.",
            "extendedThinking": false,
            "id": "azure-gpt-4-1-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/gpt-4.1-mini",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:01.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4e-7,
                "inputCacheHit": 1e-7,
                "output": 0.0000016
            },
            "description": "GPT-4.1 Mini is a mid-sized model delivering performance competitive with GPT-4o at substantially lower latency and cost. It retains a 1 million token context window and scores 45.1% on hard instruction evals, 35.8% on MultiChallenge, and 84.1% on IFEval. Mini also shows strong coding ability (e.g., 31.6% on Aiders polyglot diff benchmark) and vision understanding, making it suitable for interactive applications with tight performance constraints.",
            "extendedThinking": false,
            "id": "azure-gpt-4-1-mini@eastus-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/gpt-4.1-mini@eastus2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:01.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4e-7,
                "inputCacheHit": 1e-7,
                "output": 0.0000016
            },
            "description": "GPT-4.1 Mini is a mid-sized model delivering performance competitive with GPT-4o at substantially lower latency and cost. It retains a 1 million token context window and scores 45.1% on hard instruction evals, 35.8% on MultiChallenge, and 84.1% on IFEval. Mini also shows strong coding ability (e.g., 31.6% on Aiders polyglot diff benchmark) and vision understanding, making it suitable for interactive applications with tight performance constraints.",
            "extendedThinking": false,
            "id": "azure-gpt-4-1-mini@francecentral",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/gpt-4.1-mini@francecentral",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:01.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4e-7,
                "inputCacheHit": 1e-7,
                "output": 0.0000016
            },
            "description": "GPT-4.1 Mini is a mid-sized model delivering performance competitive with GPT-4o at substantially lower latency and cost. It retains a 1 million token context window and scores 45.1% on hard instruction evals, 35.8% on MultiChallenge, and 84.1% on IFEval. Mini also shows strong coding ability (e.g., 31.6% on Aiders polyglot diff benchmark) and vision understanding, making it suitable for interactive applications with tight performance constraints.",
            "extendedThinking": false,
            "id": "azure-gpt-4-1-mini@swedencentral",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/gpt-4.1-mini@swedencentral",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:01.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4e-7,
                "inputCacheHit": 1e-7,
                "output": 0.0000016
            },
            "description": "GPT-4.1 Mini is a mid-sized model delivering performance competitive with GPT-4o at substantially lower latency and cost. It retains a 1 million token context window and scores 45.1% on hard instruction evals, 35.8% on MultiChallenge, and 84.1% on IFEval. Mini also shows strong coding ability (e.g., 31.6% on Aiders polyglot diff benchmark) and vision understanding, making it suitable for interactive applications with tight performance constraints.",
            "extendedThinking": false,
            "id": "azure-gpt-4-1-mini@uksouth",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/gpt-4.1-mini@uksouth",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:01.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4e-7,
                "inputCacheHit": 1e-7,
                "output": 0.0000016
            },
            "description": "GPT-4.1 Mini is a mid-sized model delivering performance competitive with GPT-4o at substantially lower latency and cost. It retains a 1 million token context window and scores 45.1% on hard instruction evals, 35.8% on MultiChallenge, and 84.1% on IFEval. Mini also shows strong coding ability (e.g., 31.6% on Aiders polyglot diff benchmark) and vision understanding, making it suitable for interactive applications with tight performance constraints.",
            "extendedThinking": false,
            "id": "azure-gpt-4-1-mini@westus-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/gpt-4.1-mini@westus3",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:01.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 2.5e-8,
                "output": 4e-7
            },
            "description": "For tasks that demand low latency, GPT4.1 nano is the fastest and cheapest model in the GPT-4.1 series. It delivers exceptional performance at a small size with its 1 million token context window, and scores 80.1% on MMLU, 50.3% on GPQA, and 9.8% on Aider polyglot coding  even higher than GPT4o mini. Its ideal for tasks like classification or autocompletion.",
            "extendedThinking": false,
            "id": "azure-gpt-4-1-nano",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/gpt-4.1-nano",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:22:49.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 2.5e-8,
                "output": 4e-7
            },
            "description": "For tasks that demand low latency, GPT4.1 nano is the fastest and cheapest model in the GPT-4.1 series. It delivers exceptional performance at a small size with its 1 million token context window, and scores 80.1% on MMLU, 50.3% on GPQA, and 9.8% on Aider polyglot coding  even higher than GPT4o mini. Its ideal for tasks like classification or autocompletion.",
            "extendedThinking": false,
            "id": "azure-gpt-4-1-nano@eastus-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/gpt-4.1-nano@eastus2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:22:49.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 2.5e-8,
                "output": 4e-7
            },
            "description": "For tasks that demand low latency, GPT4.1 nano is the fastest and cheapest model in the GPT-4.1 series. It delivers exceptional performance at a small size with its 1 million token context window, and scores 80.1% on MMLU, 50.3% on GPQA, and 9.8% on Aider polyglot coding  even higher than GPT4o mini. Its ideal for tasks like classification or autocompletion.",
            "extendedThinking": false,
            "id": "azure-gpt-4-1-nano@francecentral",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/gpt-4.1-nano@francecentral",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:22:49.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 2.5e-8,
                "output": 4e-7
            },
            "description": "For tasks that demand low latency, GPT4.1 nano is the fastest and cheapest model in the GPT-4.1 series. It delivers exceptional performance at a small size with its 1 million token context window, and scores 80.1% on MMLU, 50.3% on GPQA, and 9.8% on Aider polyglot coding  even higher than GPT4o mini. Its ideal for tasks like classification or autocompletion.",
            "extendedThinking": false,
            "id": "azure-gpt-4-1-nano@swedencentral",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/gpt-4.1-nano@swedencentral",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:22:49.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 2.5e-8,
                "output": 4e-7
            },
            "description": "For tasks that demand low latency, GPT4.1 nano is the fastest and cheapest model in the GPT-4.1 series. It delivers exceptional performance at a small size with its 1 million token context window, and scores 80.1% on MMLU, 50.3% on GPQA, and 9.8% on Aider polyglot coding  even higher than GPT4o mini. Its ideal for tasks like classification or autocompletion.",
            "extendedThinking": false,
            "id": "azure-gpt-4-1-nano@uksouth",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/gpt-4.1-nano@uksouth",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:22:49.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 2.5e-8,
                "output": 4e-7
            },
            "description": "For tasks that demand low latency, GPT4.1 nano is the fastest and cheapest model in the GPT-4.1 series. It delivers exceptional performance at a small size with its 1 million token context window, and scores 80.1% on MMLU, 50.3% on GPQA, and 9.8% on Aider polyglot coding  even higher than GPT4o mini. Its ideal for tasks like classification or autocompletion.",
            "extendedThinking": false,
            "id": "azure-gpt-4-1-nano@westus-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/gpt-4.1-nano@westus3",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:22:49.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 1.25e-7,
                "output": 0.00001
            },
            "extendedThinking": true,
            "id": "azure-gpt-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "azure/gpt-5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 1.25e-7,
                "output": 0.00001
            },
            "extendedThinking": true,
            "id": "azure-gpt-5-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "azure/gpt-5.1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-11-26T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 1.25e-7,
                "output": 0.00001
            },
            "extendedThinking": true,
            "id": "azure-gpt-5-1-@swedencentral",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "azure/gpt-5.1@swedencentral",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-11-26T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 1.25e-7,
                "output": 0.00001
            },
            "extendedThinking": true,
            "id": "azure-gpt-5-@eastus-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "azure/gpt-5@eastus2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 1.25e-7,
                "output": 0.00001
            },
            "extendedThinking": true,
            "id": "azure-gpt-5-@swedencentral",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "azure/gpt-5@swedencentral",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 1.25e-7,
                "output": 0.00001
            },
            "extendedThinking": true,
            "id": "azure-gpt-5-@uksouth",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "azure/gpt-5@uksouth",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2.5e-7,
                "inputCacheHit": 2.5e-8,
                "output": 0.000002
            },
            "extendedThinking": true,
            "id": "azure-gpt-5-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "azure/gpt-5-mini",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2.5e-7,
                "inputCacheHit": 2.5e-8,
                "output": 0.000002
            },
            "extendedThinking": true,
            "id": "azure-gpt-5-mini@eastus-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "azure/gpt-5-mini@eastus2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2.5e-7,
                "inputCacheHit": 2.5e-8,
                "output": 0.000002
            },
            "extendedThinking": true,
            "id": "azure-gpt-5-mini@swedencentral",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "azure/gpt-5-mini@swedencentral",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2.5e-7,
                "inputCacheHit": 2.5e-8,
                "output": 0.000002
            },
            "extendedThinking": true,
            "id": "azure-gpt-5-mini@uksouth",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "azure/gpt-5-mini@uksouth",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 5e-8,
                "inputCacheHit": 5e-9,
                "output": 4e-7
            },
            "extendedThinking": true,
            "id": "azure-gpt-5-nano",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "azure/gpt-5-nano",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 5e-8,
                "inputCacheHit": 5e-9,
                "output": 4e-7
            },
            "extendedThinking": true,
            "id": "azure-gpt-5-nano@eastus-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "azure/gpt-5-nano@eastus2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 5e-8,
                "inputCacheHit": 5e-9,
                "output": 4e-7
            },
            "extendedThinking": true,
            "id": "azure-gpt-5-nano@swedencentral",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "azure/gpt-5-nano@swedencentral",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 2.75e-7,
                "output": 0.0000044
            },
            "description": "o3-mini is OpenAI's most recent small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. o3-mini also supports key developer features, like Structured Outputs, function calling, Batch API, and more. Like other models in the o-series, it is designed to excel at science, math, and coding tasks.",
            "extendedThinking": true,
            "id": "azure-o-4-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "azure/o4-mini",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 2.75e-7,
                "output": 0.0000044
            },
            "description": "o3-mini is OpenAI's most recent small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. o3-mini also supports key developer features, like Structured Outputs, function calling, Batch API, and more. Like other models in the o-series, it is designed to excel at science, math, and coding tasks.",
            "extendedThinking": true,
            "id": "azure-o-4-mini@eastus-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "azure/o4-mini@eastus2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 2.75e-7,
                "output": 0.0000044
            },
            "description": "o3-mini is OpenAI's most recent small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. o3-mini also supports key developer features, like Structured Outputs, function calling, Batch API, and more. Like other models in the o-series, it is designed to excel at science, math, and coding tasks.",
            "extendedThinking": true,
            "id": "azure-o-4-mini@francecentral",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "azure/o4-mini@francecentral",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 2.75e-7,
                "output": 0.0000044
            },
            "description": "o3-mini is OpenAI's most recent small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. o3-mini also supports key developer features, like Structured Outputs, function calling, Batch API, and more. Like other models in the o-series, it is designed to excel at science, math, and coding tasks.",
            "extendedThinking": true,
            "id": "azure-o-4-mini@swedencentral",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "azure/o4-mini@swedencentral",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 2.75e-7,
                "output": 0.0000044
            },
            "description": "o3-mini is OpenAI's most recent small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. o3-mini also supports key developer features, like Structured Outputs, function calling, Batch API, and more. Like other models in the o-series, it is designed to excel at science, math, and coding tasks.",
            "extendedThinking": true,
            "id": "azure-o-4-mini@uksouth",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "azure/o4-mini@uksouth",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 2.75e-7,
                "output": 0.0000044
            },
            "description": "o3-mini is OpenAI's most recent small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. o3-mini also supports key developer features, like Structured Outputs, function calling, Batch API, and more. Like other models in the o-series, it is designed to excel at science, math, and coding tasks.",
            "extendedThinking": true,
            "id": "azure-o-4-mini@westus-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "azure/o4-mini@westus3",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 5e-7,
                "output": 0.000008
            },
            "description": "GPT-4.1 is a flagship large language model optimized for advanced instruction following, real-world software engineering, and long-context reasoning. It supports a 1 million token context window and outperforms GPT-4o and GPT-4.5 across coding (54.6% SWE-bench Verified), instruction compliance (87.4% IFEval), and multimodal understanding benchmarks. It is tuned for precise code diffs, agent reliability, and high recall in large document contexts, making it ideal for agents, IDE tooling, and enterprise knowledge retrieval.",
            "extendedThinking": false,
            "id": "azure-openai-responses-gpt-4-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/openai-responses/gpt-4.1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:05.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 5e-7,
                "output": 0.000008
            },
            "description": "GPT-4.1 is a flagship large language model optimized for advanced instruction following, real-world software engineering, and long-context reasoning. It supports a 1 million token context window and outperforms GPT-4o and GPT-4.5 across coding (54.6% SWE-bench Verified), instruction compliance (87.4% IFEval), and multimodal understanding benchmarks. It is tuned for precise code diffs, agent reliability, and high recall in large document contexts, making it ideal for agents, IDE tooling, and enterprise knowledge retrieval.",
            "extendedThinking": false,
            "id": "azure-openai-responses-gpt-4-1-@eastus-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/openai-responses/gpt-4.1@eastus2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:05.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 5e-7,
                "output": 0.000008
            },
            "description": "GPT-4.1 is a flagship large language model optimized for advanced instruction following, real-world software engineering, and long-context reasoning. It supports a 1 million token context window and outperforms GPT-4o and GPT-4.5 across coding (54.6% SWE-bench Verified), instruction compliance (87.4% IFEval), and multimodal understanding benchmarks. It is tuned for precise code diffs, agent reliability, and high recall in large document contexts, making it ideal for agents, IDE tooling, and enterprise knowledge retrieval.",
            "extendedThinking": false,
            "id": "azure-openai-responses-gpt-4-1-@francecentral",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/openai-responses/gpt-4.1@francecentral",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:05.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 5e-7,
                "output": 0.000008
            },
            "description": "GPT-4.1 is a flagship large language model optimized for advanced instruction following, real-world software engineering, and long-context reasoning. It supports a 1 million token context window and outperforms GPT-4o and GPT-4.5 across coding (54.6% SWE-bench Verified), instruction compliance (87.4% IFEval), and multimodal understanding benchmarks. It is tuned for precise code diffs, agent reliability, and high recall in large document contexts, making it ideal for agents, IDE tooling, and enterprise knowledge retrieval.",
            "extendedThinking": false,
            "id": "azure-openai-responses-gpt-4-1-@swedencentral",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/openai-responses/gpt-4.1@swedencentral",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:05.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 5e-7,
                "output": 0.000008
            },
            "description": "GPT-4.1 is a flagship large language model optimized for advanced instruction following, real-world software engineering, and long-context reasoning. It supports a 1 million token context window and outperforms GPT-4o and GPT-4.5 across coding (54.6% SWE-bench Verified), instruction compliance (87.4% IFEval), and multimodal understanding benchmarks. It is tuned for precise code diffs, agent reliability, and high recall in large document contexts, making it ideal for agents, IDE tooling, and enterprise knowledge retrieval.",
            "extendedThinking": false,
            "id": "azure-openai-responses-gpt-4-1-@westus-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/openai-responses/gpt-4.1@westus3",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:05.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4e-7,
                "inputCacheHit": 1e-7,
                "output": 0.0000016
            },
            "description": "GPT-4.1 Mini is a mid-sized model delivering performance competitive with GPT-4o at substantially lower latency and cost. It retains a 1 million token context window and scores 45.1% on hard instruction evals, 35.8% on MultiChallenge, and 84.1% on IFEval. Mini also shows strong coding ability (e.g., 31.6% on Aiders polyglot diff benchmark) and vision understanding, making it suitable for interactive applications with tight performance constraints.",
            "extendedThinking": false,
            "id": "azure-openai-responses-gpt-4-1-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/openai-responses/gpt-4.1-mini",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:01.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4e-7,
                "inputCacheHit": 1e-7,
                "output": 0.0000016
            },
            "description": "GPT-4.1 Mini is a mid-sized model delivering performance competitive with GPT-4o at substantially lower latency and cost. It retains a 1 million token context window and scores 45.1% on hard instruction evals, 35.8% on MultiChallenge, and 84.1% on IFEval. Mini also shows strong coding ability (e.g., 31.6% on Aiders polyglot diff benchmark) and vision understanding, making it suitable for interactive applications with tight performance constraints.",
            "extendedThinking": false,
            "id": "azure-openai-responses-gpt-4-1-mini@eastus-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/openai-responses/gpt-4.1-mini@eastus2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:01.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4e-7,
                "inputCacheHit": 1e-7,
                "output": 0.0000016
            },
            "description": "GPT-4.1 Mini is a mid-sized model delivering performance competitive with GPT-4o at substantially lower latency and cost. It retains a 1 million token context window and scores 45.1% on hard instruction evals, 35.8% on MultiChallenge, and 84.1% on IFEval. Mini also shows strong coding ability (e.g., 31.6% on Aiders polyglot diff benchmark) and vision understanding, making it suitable for interactive applications with tight performance constraints.",
            "extendedThinking": false,
            "id": "azure-openai-responses-gpt-4-1-mini@francecentral",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/openai-responses/gpt-4.1-mini@francecentral",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:01.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4e-7,
                "inputCacheHit": 1e-7,
                "output": 0.0000016
            },
            "description": "GPT-4.1 Mini is a mid-sized model delivering performance competitive with GPT-4o at substantially lower latency and cost. It retains a 1 million token context window and scores 45.1% on hard instruction evals, 35.8% on MultiChallenge, and 84.1% on IFEval. Mini also shows strong coding ability (e.g., 31.6% on Aiders polyglot diff benchmark) and vision understanding, making it suitable for interactive applications with tight performance constraints.",
            "extendedThinking": false,
            "id": "azure-openai-responses-gpt-4-1-mini@swedencentral",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/openai-responses/gpt-4.1-mini@swedencentral",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:01.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4e-7,
                "inputCacheHit": 1e-7,
                "output": 0.0000016
            },
            "description": "GPT-4.1 Mini is a mid-sized model delivering performance competitive with GPT-4o at substantially lower latency and cost. It retains a 1 million token context window and scores 45.1% on hard instruction evals, 35.8% on MultiChallenge, and 84.1% on IFEval. Mini also shows strong coding ability (e.g., 31.6% on Aiders polyglot diff benchmark) and vision understanding, making it suitable for interactive applications with tight performance constraints.",
            "extendedThinking": false,
            "id": "azure-openai-responses-gpt-4-1-mini@westus-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/openai-responses/gpt-4.1-mini@westus3",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:01.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 2.5e-8,
                "output": 4e-7
            },
            "description": "For tasks that demand low latency, GPT4.1 nano is the fastest and cheapest model in the GPT-4.1 series. It delivers exceptional performance at a small size with its 1 million token context window, and scores 80.1% on MMLU, 50.3% on GPQA, and 9.8% on Aider polyglot coding  even higher than GPT4o mini. Its ideal for tasks like classification or autocompletion.",
            "extendedThinking": false,
            "id": "azure-openai-responses-gpt-4-1-nano",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/openai-responses/gpt-4.1-nano",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:22:49.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 2.5e-8,
                "output": 4e-7
            },
            "description": "For tasks that demand low latency, GPT4.1 nano is the fastest and cheapest model in the GPT-4.1 series. It delivers exceptional performance at a small size with its 1 million token context window, and scores 80.1% on MMLU, 50.3% on GPQA, and 9.8% on Aider polyglot coding  even higher than GPT4o mini. Its ideal for tasks like classification or autocompletion.",
            "extendedThinking": false,
            "id": "azure-openai-responses-gpt-4-1-nano@eastus-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/openai-responses/gpt-4.1-nano@eastus2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:22:49.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 2.5e-8,
                "output": 4e-7
            },
            "description": "For tasks that demand low latency, GPT4.1 nano is the fastest and cheapest model in the GPT-4.1 series. It delivers exceptional performance at a small size with its 1 million token context window, and scores 80.1% on MMLU, 50.3% on GPQA, and 9.8% on Aider polyglot coding  even higher than GPT4o mini. Its ideal for tasks like classification or autocompletion.",
            "extendedThinking": false,
            "id": "azure-openai-responses-gpt-4-1-nano@francecentral",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/openai-responses/gpt-4.1-nano@francecentral",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:22:49.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 2.5e-8,
                "output": 4e-7
            },
            "description": "For tasks that demand low latency, GPT4.1 nano is the fastest and cheapest model in the GPT-4.1 series. It delivers exceptional performance at a small size with its 1 million token context window, and scores 80.1% on MMLU, 50.3% on GPQA, and 9.8% on Aider polyglot coding  even higher than GPT4o mini. Its ideal for tasks like classification or autocompletion.",
            "extendedThinking": false,
            "id": "azure-openai-responses-gpt-4-1-nano@swedencentral",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/openai-responses/gpt-4.1-nano@swedencentral",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:22:49.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 2.5e-8,
                "output": 4e-7
            },
            "description": "For tasks that demand low latency, GPT4.1 nano is the fastest and cheapest model in the GPT-4.1 series. It delivers exceptional performance at a small size with its 1 million token context window, and scores 80.1% on MMLU, 50.3% on GPQA, and 9.8% on Aider polyglot coding  even higher than GPT4o mini. Its ideal for tasks like classification or autocompletion.",
            "extendedThinking": false,
            "id": "azure-openai-responses-gpt-4-1-nano@westus-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "azure/openai-responses/gpt-4.1-nano@westus3",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:22:49.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-3-7-sonnet",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-3-7-sonnet",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2024-06-20T01:00:00.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-3-7-sonnet@eu-central-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-3-7-sonnet@eu-central-1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2024-06-20T01:00:00.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-3-7-sonnet@eu-north-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-3-7-sonnet@eu-north-1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2024-06-20T01:00:00.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-3-7-sonnet@eu-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-3-7-sonnet@eu-west-1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2024-06-20T01:00:00.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-3-7-sonnet@eu-west-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-3-7-sonnet@eu-west-3",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2024-06-20T01:00:00.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-3-7-sonnet@us-east-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-3-7-sonnet@us-east-1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2024-06-20T01:00:00.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-3-7-sonnet@us-east-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-3-7-sonnet@us-east-2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2024-06-20T01:00:00.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-3-7-sonnet@us-west-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-3-7-sonnet@us-west-2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2024-06-20T01:00:00.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000001,
                "inputCacheHit": 1e-7,
                "output": 0.000005
            },
            "description": "Anthropic Haiku 4.5",
            "extendedThinking": false,
            "id": "bedrock-claude-haiku-4-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-haiku-4-5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-10-23T10:45:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 1.1e-7,
                "output": 0.0000055
            },
            "description": "Anthropic Haiku 4.5",
            "extendedThinking": false,
            "id": "bedrock-claude-haiku-4-5-@eu-central-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-haiku-4-5@eu-central-1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-10-23T10:45:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 1.1e-7,
                "output": 0.0000055
            },
            "description": "Anthropic Haiku 4.5",
            "extendedThinking": false,
            "id": "bedrock-claude-haiku-4-5-@eu-north-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-haiku-4-5@eu-north-1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-10-23T10:45:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 1.1e-7,
                "output": 0.0000055
            },
            "description": "Anthropic Haiku 4.5",
            "extendedThinking": false,
            "id": "bedrock-claude-haiku-4-5-@eu-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-haiku-4-5@eu-west-1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-10-23T10:45:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 1.1e-7,
                "output": 0.0000055
            },
            "description": "Anthropic Haiku 4.5",
            "extendedThinking": false,
            "id": "bedrock-claude-haiku-4-5-@eu-west-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-haiku-4-5@eu-west-3",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-10-23T10:45:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 1.1e-7,
                "output": 0.0000055
            },
            "description": "Anthropic Haiku 4.5",
            "extendedThinking": false,
            "id": "bedrock-claude-haiku-4-5-@us-east-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-haiku-4-5@us-east-1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-10-23T10:45:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 1.1e-7,
                "output": 0.0000055
            },
            "description": "Anthropic Haiku 4.5",
            "extendedThinking": false,
            "id": "bedrock-claude-haiku-4-5-@us-east-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-haiku-4-5@us-east-2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-10-23T10:45:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 1.1e-7,
                "output": 0.0000055
            },
            "description": "Anthropic Haiku 4.5",
            "extendedThinking": false,
            "id": "bedrock-claude-haiku-4-5-@us-west-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-haiku-4-5@us-west-2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-10-23T10:45:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000015,
                "inputCacheHit": 0.0000015,
                "output": 0.000075
            },
            "description": "Claude Opus 4 is Anthropic's most powerful model yet and the best coding model in the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers sustained performance on long-running tasks that require focused effort and thousands of steps, with the ability to work continuously for several hoursdramatically outperforming all Sonnet models and significantly expanding what AI agents can accomplish.",
            "extendedThinking": true,
            "id": "bedrock-claude-opus-4",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 32000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-opus-4",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:27:25.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000005,
                "inputCacheHit": 5e-7,
                "output": 0.000025
            },
            "description": "Premium model combining maximum intelligence with practical performance",
            "extendedThinking": true,
            "id": "bedrock-claude-opus-4-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-opus-4-5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-12-01T22:17:16.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000015,
                "inputCacheHit": 0.0000015,
                "output": 0.000075
            },
            "description": "Claude Opus 4 is Anthropic's most powerful model yet and the best coding model in the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers sustained performance on long-running tasks that require focused effort and thousands of steps, with the ability to work continuously for several hoursdramatically outperforming all Sonnet models and significantly expanding what AI agents can accomplish.",
            "extendedThinking": true,
            "id": "bedrock-claude-opus-4-@us-east-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 32000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-opus-4@us-east-1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:27:25.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000015,
                "inputCacheHit": 0.0000015,
                "output": 0.000075
            },
            "description": "Claude Opus 4 is Anthropic's most powerful model yet and the best coding model in the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers sustained performance on long-running tasks that require focused effort and thousands of steps, with the ability to work continuously for several hoursdramatically outperforming all Sonnet models and significantly expanding what AI agents can accomplish.",
            "extendedThinking": true,
            "id": "bedrock-claude-opus-4-@us-east-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 32000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-opus-4@us-east-2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:27:25.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000015,
                "inputCacheHit": 0.0000015,
                "output": 0.000075
            },
            "description": "Claude Opus 4 is Anthropic's most powerful model yet and the best coding model in the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers sustained performance on long-running tasks that require focused effort and thousands of steps, with the ability to work continuously for several hoursdramatically outperforming all Sonnet models and significantly expanding what AI agents can accomplish.",
            "extendedThinking": true,
            "id": "bedrock-claude-opus-4-@us-west-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 32000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-opus-4@us-west-2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:27:25.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-sonnet-4",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-sonnet-4",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-sonnet-4-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-sonnet-4-5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000033,
                "inputCacheHit": 3e-7,
                "output": 0.0000165
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-sonnet-4-5-@eu-central-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-sonnet-4-5@eu-central-1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000033,
                "inputCacheHit": 3e-7,
                "output": 0.0000165
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-sonnet-4-5-@eu-north-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-sonnet-4-5@eu-north-1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000033,
                "inputCacheHit": 3e-7,
                "output": 0.0000165
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-sonnet-4-5-@eu-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-sonnet-4-5@eu-west-1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000033,
                "inputCacheHit": 3e-7,
                "output": 0.0000165
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-sonnet-4-5-@eu-west-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-sonnet-4-5@eu-west-3",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000033,
                "inputCacheHit": 3e-7,
                "output": 0.0000165
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-sonnet-4-5-@us-east-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-sonnet-4-5@us-east-1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000033,
                "inputCacheHit": 3e-7,
                "output": 0.0000165
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-sonnet-4-5-@us-east-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-sonnet-4-5@us-east-2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000033,
                "inputCacheHit": 3e-7,
                "output": 0.0000165
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-sonnet-4-5-@us-west-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-sonnet-4-5@us-west-2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-sonnet-4-@eu-central-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-sonnet-4@eu-central-1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-sonnet-4-@eu-north-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-sonnet-4@eu-north-1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-sonnet-4-@eu-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-sonnet-4@eu-west-1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-sonnet-4-@eu-west-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-sonnet-4@eu-west-3",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-sonnet-4-@us-east-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-sonnet-4@us-east-1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-sonnet-4-@us-east-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-sonnet-4@us-east-2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "bedrock-claude-sonnet-4-@us-west-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "bedrock/claude-sonnet-4@us-west-2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "coding-claude-3-7-sonnet-20250219",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/claude-3-7-sonnet-20250219",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-02-24T18:35:10.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "coding-claude-3-7-sonnet-20250219:1024",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/claude-3-7-sonnet-20250219:1024",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-02-24T18:35:10.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "coding-claude-3-7-sonnet-20250219:16384",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/claude-3-7-sonnet-20250219:16384",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-02-24T18:35:10.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "coding-claude-3-7-sonnet-20250219:64000",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/claude-3-7-sonnet-20250219:64000",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-02-24T18:35:10.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "coding-claude-3-7-sonnet-20250219:8192",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/claude-3-7-sonnet-20250219:8192",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-02-24T18:35:10.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "coding-claude-3-7-sonnet-20250219-:high",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/claude-3-7-sonnet-20250219:high",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-02-24T18:35:10.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "coding-claude-3-7-sonnet-20250219-:low",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/claude-3-7-sonnet-20250219:low",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-02-24T18:35:10.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "coding-claude-3-7-sonnet-20250219-:max",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/claude-3-7-sonnet-20250219:max",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-02-24T18:35:10.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "coding-claude-3-7-sonnet-20250219-:medium",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/claude-3-7-sonnet-20250219:medium",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-02-24T18:35:10.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000015,
                "inputCacheHit": 0.0000015,
                "output": 0.000075
            },
            "description": "Claude Opus 4 is Anthropic's most powerful model yet and the best coding model in the world, leading on SWE-bench (72.5%) and Terminal-bench (43.2%). It delivers sustained performance on long-running tasks that require focused effort and thousands of steps, with the ability to work continuously for several hoursdramatically outperforming all Sonnet models and significantly expanding what AI agents can accomplish.",
            "extendedThinking": true,
            "id": "coding-claude-opus-4-20250514",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 32000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/claude-opus-4-20250514",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:27:25.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Claude Sonnet 4 significantly improves on Sonnet 3.7's industry-leading capabilities, excelling in coding with a state-of-the-art 72.7% on SWE-bench. The model balances performance and efficiency for internal and external use cases, with enhanced steerability for greater control over implementations.",
            "extendedThinking": true,
            "id": "coding-claude-sonnet-4-20250514",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/claude-sonnet-4-20250514",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-flash",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-flash",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-flash@europe-central-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-flash@europe-central2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-flash@europe-north-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-flash@europe-north1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-flash@europe-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-flash@europe-west1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-flash@europe-west-4",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-flash@europe-west4",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-flash@europe-west-8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-flash@europe-west8",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-flash@us-central-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-flash@us-central1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-flash@us-east-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-flash@us-east1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-flash@us-east-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-flash@us-east5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-flash@us-south-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-flash@us-south1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-flash@us-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-flash@us-west1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-pro",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-pro@europe-central-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-pro@europe-central2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-pro@europe-north-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-pro@europe-north1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-pro@europe-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-pro@europe-west1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-pro@europe-west-4",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-pro@europe-west4",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-pro@europe-west-8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-pro@europe-west8",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-pro@us-central-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-pro@us-central1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-pro@us-east-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-pro@us-east1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-pro@us-east-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-pro@us-east5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-pro@us-south-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-pro@us-south1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "coding-gemini-2-5-pro@us-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "coding/gemini-2.5-pro@us-west1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 8.5e-7,
                "inputCacheHit": 8.5e-7,
                "output": 0.0000025
            },
            "description": "DeepSeek-R1-Distill-Qwen-7B is a 7 billion parameter dense language model distilled from DeepSeek-R1, leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's larger models. The distillation process transfers advanced reasoning, math, and code capabilities into a smaller, more efficient model architecture based on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189), and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive accuracy relative to larger models while maintaining smaller inference costs.",
            "extendedThinking": false,
            "id": "deepinfra-deepseek-ai-deep-seek-r1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 64000,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra/deepseek-ai/DeepSeek-R1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-01-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2.3e-7,
                "inputCacheHit": 2.3e-7,
                "output": 6.9e-7
            },
            "description": "DeepSeek-R1-Distill-Qwen-7B is a 7 billion parameter dense language model distilled from DeepSeek-R1, leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's larger models. The distillation process transfers advanced reasoning, math, and code capabilities into a smaller, more efficient model architecture based on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189), and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive accuracy relative to larger models while maintaining smaller inference costs.",
            "extendedThinking": false,
            "id": "deepinfra-deepseek-ai-deep-seek-r1-distill-llama-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 64000,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra/deepseek-ai/DeepSeek-R1-Distill-Llama-70B",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-01-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 8.5e-7,
                "inputCacheHit": 8.5e-7,
                "output": 9e-7
            },
            "description": "DeepSeek-R1-Distill-Qwen-7B is a 7 billion parameter dense language model distilled from DeepSeek-R1, leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's larger models. The distillation process transfers advanced reasoning, math, and code capabilities into a smaller, more efficient model architecture based on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189), and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive accuracy relative to larger models while maintaining smaller inference costs.",
            "extendedThinking": false,
            "id": "deepinfra-deepseek-ai-deep-seek-v3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra/deepseek-ai/DeepSeek-V3",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-01-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 3e-7,
                "output": 0.000001
            },
            "extendedThinking": false,
            "id": "deepinfra-deepseek-ai-deep-seek-v3-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra/deepseek-ai/DeepSeek-V3.1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-08-26T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3.5e-7,
                "inputCacheHit": 3.5e-7,
                "output": 4e-7
            },
            "description": "A lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response times are needed most.",
            "extendedThinking": false,
            "id": "deepinfra-meta-llama-llama-3-2-90b-vision-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra/meta-llama/Llama-3.2-90B-Vision-Instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-02-06T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2.3e-7,
                "inputCacheHit": 2.3e-7,
                "output": 4e-7
            },
            "description": "A lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response times are needed most.",
            "extendedThinking": false,
            "id": "deepinfra-meta-llama-llama-3-3-70b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra/meta-llama/Llama-3.3-70B-Instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-02-06T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.2e-7,
                "inputCacheHit": 1.2e-7,
                "output": 3e-7
            },
            "description": "A lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response times are needed most.",
            "extendedThinking": false,
            "id": "deepinfra-meta-llama-llama-3-3-70b-instruct-turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra/meta-llama/Llama-3.3-70B-Instruct-Turbo",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-02-06T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 8e-7,
                "inputCacheHit": 8e-7,
                "output": 8e-7
            },
            "description": "A lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response times are needed most.",
            "extendedThinking": false,
            "id": "deepinfra-meta-llama-meta-llama-3-1-405b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 130815,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra/meta-llama/Meta-Llama-3.1-405B-Instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-02-06T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2.3e-7,
                "inputCacheHit": 2.3e-7,
                "output": 4e-7
            },
            "description": "A lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response times are needed most.",
            "extendedThinking": false,
            "id": "deepinfra-meta-llama-meta-llama-3-1-70b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 130815,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra/meta-llama/Meta-Llama-3.1-70B-Instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-02-06T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2e-8,
                "inputCacheHit": 2e-8,
                "output": 5e-8
            },
            "description": "A lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response times are needed most.",
            "extendedThinking": false,
            "id": "deepinfra-meta-llama-meta-llama-3-1-8b-instruct-turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-05-14T14:42:34.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 7e-8,
                "inputCacheHit": 7e-8,
                "output": 1.4e-7
            },
            "description": "Phi-4-reasoning-plus is an enhanced 14B parameter model from Microsoft, fine-tuned from Phi-4 with additional reinforcement learning to boost accuracy on math, science, and code reasoning tasks. It uses the same dense decoder-only transformer architecture as Phi-4, but generates longer, more comprehensive outputs structured into a step-by-step reasoning trace and final answer.\n\nWhile it offers improved benchmark scores over Phi-4-reasoning across tasks like AIME, OmniMath, and HumanEvalPlus, its responses are typically ~50% longer, resulting in higher latency. Designed for English-only applications, it is well-suited for structured reasoning workflows where output quality takes priority over response speed.",
            "extendedThinking": false,
            "id": "deepinfra-microsoft-phi-4",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra/microsoft/phi-4",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-05-01T21:22:41.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2.3e-7,
                "inputCacheHit": 2.3e-7,
                "output": 4e-7
            },
            "description": "Qwen3, the latest generation in the Qwen large language model series, features both dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual support, and advanced agent tasks. Its unique ability to switch seamlessly between a thinking mode for complex reasoning and a non-thinking mode for efficient dialogue ensures versatile, high-quality performance.\n\nSignificantly outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics, coding, commonsense reasoning, creative writing, and interactive dialogue capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3 billion activated), 48 layers, 128 experts (8 activated per task), and supports up to 131K token contexts with YaRN, setting a new standard among open-source models.",
            "extendedThinking": false,
            "id": "deepinfra-qwen-qwen-2-5-72b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra/Qwen/Qwen2.5-72B-Instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-28T23:16:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 7e-8,
                "inputCacheHit": 7e-8,
                "output": 1.6e-7
            },
            "description": "Qwen3, the latest generation in the Qwen large language model series, features both dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual support, and advanced agent tasks. Its unique ability to switch seamlessly between a thinking mode for complex reasoning and a non-thinking mode for efficient dialogue ensures versatile, high-quality performance.\n\nSignificantly outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics, coding, commonsense reasoning, creative writing, and interactive dialogue capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3 billion activated), 48 layers, 128 experts (8 activated per task), and supports up to 131K token contexts with YaRN, setting a new standard among open-source models.",
            "extendedThinking": false,
            "id": "deepinfra-qwen-qwen-2-5-coder-32b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra/Qwen/Qwen2.5-Coder-32B-Instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-28T23:16:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2e-7,
                "inputCacheHit": 2e-7,
                "output": 6e-7
            },
            "description": "Qwen3, the latest generation in the Qwen large language model series, features both dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual support, and advanced agent tasks. Its unique ability to switch seamlessly between a thinking mode for complex reasoning and a non-thinking mode for efficient dialogue ensures versatile, high-quality performance.\n\nSignificantly outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics, coding, commonsense reasoning, creative writing, and interactive dialogue capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3 billion activated), 48 layers, 128 experts (8 activated per task), and supports up to 131K token contexts with YaRN, setting a new standard among open-source models.",
            "extendedThinking": false,
            "id": "deepinfra-qwen-qwen-3-235b-a22b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40000,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra/Qwen/Qwen3-235B-A22B",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-28T23:16:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 1e-7,
                "output": 3e-7
            },
            "description": "Qwen3, the latest generation in the Qwen large language model series, features both dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual support, and advanced agent tasks. Its unique ability to switch seamlessly between a thinking mode for complex reasoning and a non-thinking mode for efficient dialogue ensures versatile, high-quality performance.\n\nSignificantly outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics, coding, commonsense reasoning, creative writing, and interactive dialogue capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3 billion activated), 48 layers, 128 experts (8 activated per task), and supports up to 131K token contexts with YaRN, setting a new standard among open-source models.",
            "extendedThinking": false,
            "id": "deepinfra-qwen-qwen-3-32b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra/Qwen/Qwen3-32B",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-28T23:16:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4e-7,
                "inputCacheHit": 4e-7,
                "output": 0.0000016
            },
            "extendedThinking": false,
            "id": "deepinfra-qwen-qwen-3-coder-480b-a35b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra/Qwen/Qwen3-Coder-480B-A35B-Instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-07-25T14:38:14.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 6e-7,
                "inputCacheHit": 6e-7,
                "output": 0.0000022
            },
            "description": "The GLM-4.5 series models are foundation models designed for intelligent agents. GLM-4.5 has 355 billion total parameters with 32 billion active parameters, while GLM-4.5-Air adopts a more compact design with 106 billion total parameters and 12 billion active parameters. GLM-4.5 models unify reasoning, coding, and intelligent agent capabilities to meet the complex demands of intelligent agent applications.",
            "extendedThinking": false,
            "id": "deepinfra-zai-org-glm-4-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra/zai-org/GLM-4.5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-07-30T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2e-7,
                "inputCacheHit": 2e-7,
                "output": 0.0000011
            },
            "description": "The GLM-4.5 series models are foundation models designed for intelligent agents. GLM-4.5 has 355 billion total parameters with 32 billion active parameters, while GLM-4.5-Air adopts a more compact design with 106 billion total parameters and 12 billion active parameters. GLM-4.5 models unify reasoning, coding, and intelligent agent capabilities to meet the complex demands of intelligent agent applications.",
            "extendedThinking": false,
            "id": "deepinfra-zai-org-glm-4-5-air",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 4096
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepinfra/zai-org/GLM-4.5-Air",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-07-30T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2.8e-7,
                "inputCacheHit": 2.8e-8,
                "output": 4.2e-7
            },
            "description": "DeepSeek-V3 achieves a significant breakthrough in inference speed over previous models.\n\nIt tops the leaderboard among open-source models and rivals the most advanced closed-source models globally.",
            "extendedThinking": false,
            "id": "deepseek-deepseek-chat",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 8000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek/deepseek-chat",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-01-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2.8e-7,
                "inputCacheHit": 2.8e-8,
                "output": 4.2e-7
            },
            "description": "Fully open-source model & technical report. Performance on par with OpenAI-o1.",
            "extendedThinking": false,
            "id": "deepseek-deepseek-reasoner",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 64000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "deepseek/deepseek-reasoner",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-01-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 1e-7,
                "output": 4e-7
            },
            "description": "Gemini Flash 2.0 offers a significantly faster time to first token (TTFT) compared to [Gemini Flash 1.5](/google/gemini-flash-1.5), while maintaining quality on par with larger models like [Gemini Pro 1.5](/google/gemini-pro-1.5). It introduces notable enhancements in multimodal understanding, coding capabilities, complex instruction following, and function calling. These advancements come together to deliver more seamless and robust agentic experiences.",
            "extendedThinking": false,
            "id": "google-gemini-2-0-flash-001",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "google/gemini-2.0-flash-001",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-02-05T15:30:13.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "google-gemini-2-5-flash",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "google/gemini-2.5-flash",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 1e-8,
                "output": 4e-7
            },
            "description": "Google's smallest and most cost effective model, built for at scale usage.",
            "extendedThinking": true,
            "id": "google-gemini-2-5-flash-lite",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "google/gemini-2.5-flash-lite",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "google-gemini-2-5-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "google/gemini-2.5-pro",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 5e-7,
                "inputCacheHit": 5e-8,
                "output": 0.000003
            },
            "description": "Gemini 3 Flash Preview is designed to deliver strong agentic capabilities (near-Pro level) at substantial speed and value. Making it perfect for engaging multi-turn chats, and collaborating back and forth with your coding agent without getting out of flow. Compared to 2.5 Flash it delivers significant improvements across the board.",
            "extendedThinking": true,
            "id": "google-gemini-3-flash-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "google/gemini-3-flash-preview",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-12-18T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 2e-7,
                "output": 0.000012
            },
            "description": "Gemini 3 Pro is designed to tackle the most challenging agentic problems with strong coding and state-of-the-art reasoning capabilities. It is the best model for complex multimodal understanding. Compared to Gemini 2.5 Pro, it improves significantly on complex instruction following and delivers outcomes with better output efficiency.",
            "extendedThinking": true,
            "id": "google-gemini-3-pro-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "google/gemini-3-pro-preview",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000001,
                "inputCacheHit": 0.000001,
                "output": 0.000003
            },
            "extendedThinking": false,
            "id": "groq-moonshotai-kimi-k-2-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "groq/moonshotai/kimi-k2-instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-07-14T23:16:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000001,
                "inputCacheHit": 0.000001,
                "output": 0.000003
            },
            "description": "MoonshotAIs cuttingedge model, moonshotai/Kimi-K2-Instruct-0905, is now live on GroqCloud.",
            "extendedThinking": false,
            "id": "groq-moonshotai-kimi-k2-instruct-0905",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "groq/moonshotai/Kimi-K2-Instruct-0905",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-09-10T17:16:37.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.5e-7,
                "inputCacheHit": 1.5e-7,
                "output": 7.5e-7
            },
            "extendedThinking": false,
            "id": "groq-openai-gpt-oss-120-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "groq/openai/gpt-oss-120b",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-08-05T17:16:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 1e-7,
                "output": 5e-7
            },
            "extendedThinking": false,
            "id": "groq-openai-gpt-oss-20-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "groq/openai/gpt-oss-20b",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-08-05T17:16:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 3e-7,
                "output": 0.0000012
            },
            "description": "MiniMax-M2 is a compact, high-efficiency large language model optimized for end-to-end coding and agentic workflows. With 10 billion activated parameters (230 billion total), it delivers near-frontier intelligence across general reasoning, tool use, and multi-step task execution while maintaining low latency and deployment efficiency.",
            "extendedThinking": false,
            "id": "minimaxi-mini-max-m2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 128000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "minimaxi/MiniMax-M2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-10-28T10:16:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 3e-7,
                "output": 9e-7
            },
            "extendedThinking": false,
            "id": "mistral-codestral-latest",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mistral/codestral-latest",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-08-12T16:32:41.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "description": "An enterprise grade text model, that excels at using tools to explore codebases, editing multiple files and power software engineering agents.",
            "extendedThinking": false,
            "id": "mistral-devstral-latest",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mistral/devstral-latest",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-12-10T00:00:00.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4e-7,
                "inputCacheHit": 4e-7,
                "output": 0.000002
            },
            "extendedThinking": false,
            "id": "mistral-devstral-medium-2507",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mistral/devstral-medium-2507",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-08-12T16:32:41.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 1e-7,
                "output": 3e-7
            },
            "extendedThinking": false,
            "id": "mistral-devstral-small-2507",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mistral/devstral-small-2507",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-08-12T16:32:41.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 1e-7,
                "output": 3e-7
            },
            "extendedThinking": false,
            "id": "mistral-devstral-small-latest",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mistral/devstral-small-latest",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-01-15T18:03:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 0.000002,
                "output": 0.000006
            },
            "extendedThinking": false,
            "id": "mistral-mistral-large-latest",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mistral/mistral-large-latest",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-02-24T16:32:41.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4e-7,
                "inputCacheHit": 4e-7,
                "output": 0.000002
            },
            "extendedThinking": false,
            "id": "mistral-mistral-medium-latest",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mistral/mistral-medium-latest",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-08-12T16:32:41.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 1e-7,
                "output": 3e-7
            },
            "extendedThinking": false,
            "id": "mistral-mistral-small-latest",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mistral/mistral-small-latest",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-02-24T16:32:41.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2.5e-7,
                "inputCacheHit": 2.5e-7,
                "output": 2.5e-7
            },
            "extendedThinking": false,
            "id": "mistral-open-mistral-7-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mistral/open-mistral-7b",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-02-24T16:32:41.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 0.000002,
                "output": 0.000005
            },
            "extendedThinking": false,
            "id": "mistral-pixtral-large-latest",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "mistral/pixtral-large-latest",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-08-12T16:32:41.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 6e-7,
                "inputCacheHit": 1.5e-7,
                "output": 0.0000025
            },
            "description": "A Mixture-of-Experts (MoE) foundation model with exceptional coding and agent capabilities, featuring 1 trillion total parameters and 32 billion activated parameters. In benchmark evaluations covering general knowledge reasoning, programming, mathematics, and agent-related tasks, the K2 model outperforms other leading open-source models.",
            "extendedThinking": false,
            "id": "moonshot-kimi-k-2-0711-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "moonshot/kimi-k2-0711-preview",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-07-14T23:16:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 6e-7,
                "inputCacheHit": 1.5e-7,
                "output": 0.0000025
            },
            "description": "Based on kimi-k2-0711-preview, with enhanced agentic coding abilities, improved frontend code quality and practicality, and better context understanding",
            "extendedThinking": false,
            "id": "moonshot-kimi-k-2-0905-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "moonshot/kimi-k2-0905-preview",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-08-06T23:16:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 6e-7,
                "inputCacheHit": 1.5e-7,
                "output": 0.0000025
            },
            "description": "A thinking model with general agentic and reasoning capabilities, specializing in deep reasoning tasks.",
            "extendedThinking": false,
            "id": "moonshot-kimi-k-2-thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "moonshot/kimi-k2-thinking",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-08-06T23:16:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 6e-7,
                "inputCacheHit": 1.5e-7,
                "output": 0.0000025
            },
            "description": "High-speed version of kimi-k2-thinking, suitable for scenarios requiring both deep reasoning and extremely fast responses",
            "extendedThinking": false,
            "id": "moonshot-kimi-k-2-thinking-turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "moonshot/kimi-k2-thinking-turbo",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-08-06T23:16:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000012,
                "inputCacheHit": 3e-7,
                "output": 0.000005
            },
            "description": "A Mixture-of-Experts (MoE) foundation model with exceptional coding and agent capabilities, featuring 1 trillion total parameters and 32 billion activated parameters. In benchmark evaluations covering general knowledge reasoning, programming, mathematics, and agent-related tasks, the K2 model outperforms other leading open-source models.",
            "extendedThinking": false,
            "id": "moonshot-kimi-k-2-turbo-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "moonshot/kimi-k2-turbo-preview",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-08-06T23:16:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 8e-7,
                "inputCacheHit": 8e-7,
                "output": 0.0000024
            },
            "description": "DeepSeek-R1-Distill-Qwen-7B is a 7 billion parameter dense language model distilled from DeepSeek-R1, leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's larger models. The distillation process transfers advanced reasoning, math, and code capabilities into a smaller, more efficient model architecture based on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189), and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive accuracy relative to larger models while maintaining smaller inference costs.",
            "extendedThinking": false,
            "id": "nebius-deepseek-ai-deep-seek-r1-0528",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 164000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nebius/deepseek-ai/DeepSeek-R1-0528",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-01-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 5e-7,
                "inputCacheHit": 5e-7,
                "output": 0.0000015
            },
            "description": "DeepSeek-R1-Distill-Qwen-7B is a 7 billion parameter dense language model distilled from DeepSeek-R1, leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's larger models. The distillation process transfers advanced reasoning, math, and code capabilities into a smaller, more efficient model architecture based on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189), and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive accuracy relative to larger models while maintaining smaller inference costs.",
            "extendedThinking": false,
            "id": "nebius-deepseek-ai-deep-seek-v3-0324",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nebius/deepseek-ai/DeepSeek-V3-0324",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-01-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 0.000002,
                "output": 0.000006
            },
            "description": "DeepSeek-R1-Distill-Qwen-7B is a 7 billion parameter dense language model distilled from DeepSeek-R1, leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's larger models. The distillation process transfers advanced reasoning, math, and code capabilities into a smaller, more efficient model architecture based on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189), and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive accuracy relative to larger models while maintaining smaller inference costs.",
            "extendedThinking": false,
            "id": "nebius-deepseek-ai-deep-seek-v3-0324-fast",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nebius/deepseek-ai/DeepSeek-V3-0324-fast",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-05-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.3e-7,
                "inputCacheHit": 1.3e-7,
                "output": 4e-7
            },
            "description": "A lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response times are needed most.",
            "extendedThinking": false,
            "id": "nebius-meta-llama-llama-3-3-70b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nebius/meta-llama/Llama-3.3-70B-Instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-05-14T14:42:34.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 5e-7,
                "inputCacheHit": 5e-7,
                "output": 0.0000024
            },
            "extendedThinking": false,
            "id": "nebius-moonshotai-kimi-k2-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nebius/moonshotai/Kimi-K2-Instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-07-10T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4e-7,
                "inputCacheHit": 4e-7,
                "output": 0.0000018
            },
            "extendedThinking": false,
            "id": "nebius-qwen-qwen-3-coder-480b-a35b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nebius/Qwen/Qwen3-Coder-480B-A35B-Instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-07-10T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 6e-7,
                "inputCacheHit": 6e-7,
                "output": 0.0000022
            },
            "extendedThinking": false,
            "id": "nebius-zai-org-glm-4-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "nebius/zai-org/GLM-4.5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-07-10T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 7e-7,
                "inputCacheHit": 7e-7,
                "output": 0.0000025
            },
            "description": "DeepSeek-R1-Distill-Qwen-7B is a 7 billion parameter dense language model distilled from DeepSeek-R1, leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's larger models. The distillation process transfers advanced reasoning, math, and code capabilities into a smaller, more efficient model architecture based on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189), and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive accuracy relative to larger models while maintaining smaller inference costs.",
            "extendedThinking": false,
            "id": "novita-deepseek-deepseek-prover-v-2-671-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 160000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/deepseek/deepseek-prover-v2-671b",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-01-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000004,
                "inputCacheHit": 0.000004,
                "output": 0.000004
            },
            "description": "DeepSeek R1 is the latest open-source model released by the DeepSeek team, featuring impressive reasoning capabilities, particularly achieving performance comparable to OpenAI's o1 model in mathematics, coding, and reasoning tasks.",
            "extendedThinking": false,
            "id": "novita-deepseek-deepseek-r-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 64000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/deepseek/deepseek-r1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-01-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 8e-7,
                "inputCacheHit": 8e-7,
                "output": 8e-7
            },
            "description": "DeepSeek R1 Distill LLama 70B",
            "extendedThinking": false,
            "id": "novita-deepseek-deepseek-r-1-distill-llama-70-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/deepseek/deepseek-r1-distill-llama-70b",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-01-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.5e-7,
                "inputCacheHit": 1.5e-7,
                "output": 1.5e-7
            },
            "description": "DeepSeek R1 Distill Qwen 14B is a distilled large language model based on Qwen 2.5 14B, using outputs from DeepSeek R1. It outperforms OpenAI's o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.\n\nOther benchmark results include:\n\nAIME 2024 pass@1: 69.7\nMATH-500 pass@1: 93.9\nCodeForces Rating: 1481\nThe model leverages fine-tuning from DeepSeek R1's outputs, enabling competitive performance comparable to larger frontier models.",
            "extendedThinking": false,
            "id": "novita-deepseek-deepseek-r-1-distill-qwen-14-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/deepseek/deepseek-r1-distill-qwen-14b",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-01-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 3e-7,
                "output": 3e-7
            },
            "description": "DeepSeek R1 Distill Qwen 32B is a distilled large language model based on Qwen 2.5 32B, using outputs from DeepSeek R1. It outperforms OpenAI's o1-mini across various benchmarks, achieving new state-of-the-art results for dense models.\n\nOther benchmark results include:\nAIME 2024 pass@1: 72.6\nMATH-500 pass@1: 94.3\nCodeForces Rating: 1691\nThe model leverages fine-tuning from DeepSeek R1's outputs, enabling competitive performance comparable to larger frontier models.",
            "extendedThinking": false,
            "id": "novita-deepseek-deepseek-r-1-distill-qwen-32-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 12800,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/deepseek/deepseek-r1-distill-qwen-32b",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-01-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 7e-7,
                "inputCacheHit": 7e-7,
                "output": 0.0000025
            },
            "description": "DeepSeek R1 is the latest open-source model released by the DeepSeek team, featuring impressive reasoning capabilities, particularly achieving performance comparable to OpenAI's o1 model in mathematics, coding, and reasoning tasks.",
            "extendedThinking": false,
            "id": "novita-deepseek-deepseek-r-1-turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 64000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/deepseek/deepseek-r1-turbo",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-01-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 8.9e-7,
                "inputCacheHit": 8.9e-7,
                "output": 8.9e-7
            },
            "description": "DeepSeek-V3 is the latest model from the DeepSeek team, building upon the instruction following and coding abilities of the previous versions. Pre-trained on nearly 15 trillion tokens, the reported evaluations reveal that the model outperforms other open-source models and rivals leading closed-source models.",
            "extendedThinking": false,
            "id": "novita-deepseek-deepseek-v-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 64000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/deepseek/deepseek_v3",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-05-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4e-7,
                "inputCacheHit": 4e-7,
                "output": 0.0000013
            },
            "description": "DeepSeek R1 is the latest open-source model released by the DeepSeek team, featuring impressive reasoning capabilities, particularly achieving performance comparable to OpenAI's o1 model in mathematics, coding, and reasoning tasks.",
            "extendedThinking": false,
            "id": "novita-deepseek-deepseek-v-3-0324",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/deepseek/deepseek-v3-0324",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-05-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4e-7,
                "inputCacheHit": 4e-7,
                "output": 0.0000013
            },
            "description": "DeepSeek R1 is the latest open-source model released by the DeepSeek team, featuring impressive reasoning capabilities, particularly achieving performance comparable to OpenAI's o1 model in mathematics, coding, and reasoning tasks.",
            "extendedThinking": false,
            "id": "novita-deepseek-deepseek-v-3-turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/deepseek/deepseek-v3-turbo",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-05-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 9e-8,
                "inputCacheHit": 9e-8,
                "output": 9e-8
            },
            "description": "The idea behind this merge is that each layer is composed of several tensors, which are in turn responsible for specific functions. Using MythoLogic-L2's robust understanding as its input and Huginn's extensive writing capability as its output seems to have resulted in a model that exceeds at both, confirming my theory. (More details to be released at a later time).",
            "extendedThinking": false,
            "id": "novita-gryphe-mythomax-l-2-13-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 4096,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/gryphe/mythomax-l2-13b",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2023-07-02T01:00:00.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 5e-8,
                "inputCacheHit": 5e-8,
                "output": 5e-8
            },
            "description": "Meta's latest class of models, Llama 3.1, launched with a variety of sizes and configurations. The 8B instruct-tuned version is particularly fast and efficient. It has demonstrated strong performance in human evaluations, outperforming several leading closed-source models.",
            "extendedThinking": false,
            "id": "novita-meta-llama-llama-3-1-8-b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16384,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/meta-llama/llama-3.1-8b-instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-02-06T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2e-8,
                "inputCacheHit": 2e-8,
                "output": 2e-8
            },
            "description": "The Meta Llama 3.2 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction-tuned generative models in 1B and 3B sizes (text in/text out).",
            "extendedThinking": false,
            "id": "novita-meta-llama-llama-3-2-1-b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/meta-llama/llama-3.2-1b-instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-02-06T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-8,
                "inputCacheHit": 3e-8,
                "output": 5e-8
            },
            "description": "The Meta Llama 3.2 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction-tuned generative models in 1B and 3B sizes (text in/text out)",
            "extendedThinking": false,
            "id": "novita-meta-llama-llama-3-2-3-b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/meta-llama/llama-3.2-3b-instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-02-06T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3.9e-7,
                "inputCacheHit": 3.9e-7,
                "output": 3.9e-7
            },
            "description": "The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out). The Llama 3.3 instruction tuned text only model is optimized for multilingual dialogue use cases and outperforms many of the available open source and closed chat models on common industry benchmarks.\n\nSupported languages: English, German, French, Italian, Portuguese, Hindi, Spanish, and Thai.",
            "extendedThinking": false,
            "id": "novita-meta-llama-llama-3-3-70-b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/meta-llama/llama-3.3-70b-instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-02-06T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 5.1e-7,
                "inputCacheHit": 5.1e-7,
                "output": 7.4e-7
            },
            "description": "Meta's latest class of model (Llama 3) launched with a variety of sizes & flavors. This 70B instruct-tuned version was optimized for high quality dialogue usecases. It has demonstrated strong performance compared to leading closed-source models in human evaluations.",
            "extendedThinking": false,
            "id": "novita-meta-llama-llama-3-70-b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/meta-llama/llama-3-70b-instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-02-06T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4e-8,
                "inputCacheHit": 4e-8,
                "output": 4e-8
            },
            "description": "Meta's latest class of model (Llama 3) launched with a variety of sizes & flavors. This 8B instruct-tuned version was optimized for high quality dialogue usecases. It has demonstrated strong performance compared to leading closed-source models in human evaluations.",
            "extendedThinking": false,
            "id": "novita-meta-llama-llama-3-8-b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/meta-llama/llama-3-8b-instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-02-06T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2e-7,
                "inputCacheHit": 2e-7,
                "output": 8.5e-7
            },
            "description": "A lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response times are needed most.",
            "extendedThinking": false,
            "id": "novita-meta-llama-llama-4-maverick-17-b-128-e-instruct-fp-8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 1048576
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/meta-llama/llama-4-maverick-17b-128e-instruct-fp8",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-01-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 6.2e-7,
                "inputCacheHit": 6.2e-7,
                "output": 6.2e-7
            },
            "description": "WizardLM-2 8x22B is Microsoft AI's most advanced Wizard model. It demonstrates highly competitive performance compared to leading proprietary models, and it consistently outperforms all existing state-of-the-art opensource models.",
            "extendedThinking": false,
            "id": "novita-microsoft-wizardlm-2-8-x-22-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65535,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/microsoft/wizardlm-2-8x22b",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-02-06T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.7e-7,
                "inputCacheHit": 1.7e-7,
                "output": 1.7e-7
            },
            "description": "A 12B parameter model with a 128k token context length built by Mistral in collaboration with NVIDIA. The model is multilingual, supporting English, French, German, Spanish, Italian, Portuguese, Chinese, Japanese, Korean, Arabic, and Hindi. It supports function calling and is released under the Apache 2.0 license.",
            "extendedThinking": false,
            "id": "novita-mistralai-mistral-nemo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/mistralai/mistral-nemo",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-06-10T16:32:41.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 5.7e-7,
                "inputCacheHit": 5.7e-7,
                "output": 0.0000023
            },
            "extendedThinking": false,
            "id": "novita-moonshotai-kimi-k-2-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/moonshotai/kimi-k2-instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-07-11T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.4e-7,
                "inputCacheHit": 1.4e-7,
                "output": 1.4e-7
            },
            "description": "Hermes 2 Pro is an upgraded, retrained version of Nous Hermes 2, consisting of an updated and cleaned version of the OpenHermes 2.5 Dataset, as well as a newly introduced Function Calling and JSON Mode dataset developed in-house.",
            "extendedThinking": false,
            "id": "novita-nousresearch-hermes-2-pro-llama-3-8-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/nousresearch/hermes-2-pro-llama-3-8b",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-02-06T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3.8e-7,
                "inputCacheHit": 3.8e-7,
                "output": 4e-7
            },
            "description": "Qwen2.5 is the latest series of Qwen large language models. For Qwen2.5, we release a number of base language models and instruction-tuned language models ranging from 0.5 to 72 billion parameters.",
            "extendedThinking": false,
            "id": "novita-qwen-qwen-2-5-72-b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/qwen/qwen-2.5-72b-instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-28T23:16:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 8e-7,
                "inputCacheHit": 8e-7,
                "output": 8e-7
            },
            "description": "Qwen2 VL 72B is a multimodal LLM from the Qwen Team with the following key enhancements:\n\nSoTA understanding of images of various resolution & ratio: Qwen2-VL achieves state-of-the-art performance on visual understanding benchmarks, including MathVista, DocVQA, RealWorldQA, MTVQA, etc.\n\nUnderstanding videos of 20min+: Qwen2-VL can understand videos over 20 minutes for high-quality video-based question answering, dialog, content creation, etc.\n\nAgent that can operate your mobiles, robots, etc.: with the abilities of complex reasoning and decision making, Qwen2-VL can be integrated with devices like mobile phones, robots, etc., for automatic operation based on visual environment and text instructions.\n\nMultilingual Support: to serve global users, besides English and Chinese, Qwen2-VL now supports the understanding of texts in different languages inside images, including most European languages, Japanese, Korean, Arabic, Vietnamese, etc.",
            "extendedThinking": false,
            "id": "novita-qwen-qwen-2-5-vl-72-b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 96000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/qwen/qwen2.5-vl-72b-instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-28T23:16:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2e-7,
                "inputCacheHit": 2e-7,
                "output": 8e-7
            },
            "description": "Qwen3, the latest generation in the Qwen large language model series, features both dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual support, and advanced agent tasks. Its unique ability to switch seamlessly between a thinking mode for complex reasoning and a non-thinking mode for efficient dialogue ensures versatile, high-quality performance.\n\nSignificantly outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics, coding, commonsense reasoning, creative writing, and interactive dialogue capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3 billion activated), 48 layers, 128 experts (8 activated per task), and supports up to 131K token contexts with YaRN, setting a new standard among open-source models.",
            "extendedThinking": false,
            "id": "novita-qwen-qwen-3-235-b-a-22-b-fp-8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/qwen/qwen3-235b-a22b-fp8",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-28T23:16:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000148,
                "inputCacheHit": 0.00000148,
                "output": 0.00000148
            },
            "description": "Euryale L3.1 70B v2.2 is a model focused on creative roleplay from Sao10k. It is the successor of Euryale L3 70B v2.1.",
            "extendedThinking": false,
            "id": "novita-sao-10-k-l-31-70-b-euryale-v-2-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/sao10k/l31-70b-euryale-v2.2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-12-18T15:32:08.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000148,
                "inputCacheHit": 0.00000148,
                "output": 0.00000148
            },
            "description": "The uncensored llama3 model is a powerhouse of creativity, excelling in both roleplay and story writing. It offers a liberating experience during roleplays, free from any restrictions. This model stands out for its immense creativity, boasting a vast array of unique ideas and plots, truly a treasure trove for those seeking originality. Its unrestricted nature during roleplays allows for the full breadth of imagination to unfold, akin to an enhanced, big-brained version of Stheno. Perfect for creative minds seeking a boundless platform for their imaginative expressions, the uncensored llama3 model is an ideal choice",
            "extendedThinking": false,
            "id": "novita-sao-10-k-l-3-70-b-euryale-v-2-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 16000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/sao10k/l3-70b-euryale-v2.1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-12-18T15:32:08.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 5e-8,
                "inputCacheHit": 5e-8,
                "output": 5e-8
            },
            "description": "A generalist / roleplaying model merge based on Llama 3.",
            "extendedThinking": false,
            "id": "novita-sao-10-k-l-3-8-b-lunaris",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/sao10k/l3-8b-lunaris",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-12-18T15:32:08.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 5e-8,
                "inputCacheHit": 5e-8,
                "output": 5e-8
            },
            "description": "Sao10K/L3-8B-Stheno-v3.2 is a highly skilled actor that excels at fully immersing itself in any role assigned.",
            "extendedThinking": false,
            "id": "novita-sao-10-k-l3-8b-stheno-v-3-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/Sao10K/L3-8B-Stheno-v3.2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-12-18T15:32:08.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 6e-7,
                "inputCacheHit": 6e-7,
                "output": 0.0000022
            },
            "extendedThinking": false,
            "id": "novita-zai-org-glm-4-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/zai-org/glm-4.5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-07-30T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 6e-7,
                "inputCacheHit": 6e-7,
                "output": 0.0000022
            },
            "description": "GLM-4.6 is Z AIs latest flagship model, designed to push agentic and coding performance further. It expands the context window from 128K to 200K tokens, improves reasoning and tool-use capabilities, and delivers stronger results in coding benchmarks and real-world development workflows. GLM-4.6 demonstrates refined writing quality, more capable agent behavior, and higher token efficiency (15% fewer tokens vs. GLM-4.5).\n\nEvaluations show clear gains over GLM-4.5 across reasoning, agents, and coding, reaching near parity with Claude Sonnet 4 in practical tasks while outperforming other open-source baselines. GLM-4.6 is available through the Z.ai API platform, OpenRouter, coding agents (Claude Code, Roo Code, Cline, Kilo Code), and soon as downloadable weights on HuggingFace and ModelScope.",
            "extendedThinking": false,
            "id": "novita-zai-org-glm-4-6",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 204800,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "novita/zai-org/glm-4.6",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-07-30T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000005,
                "inputCacheHit": 0.000005,
                "output": 0.000015
            },
            "description": "OpenAI ChatGPT 4o is continually updated by OpenAI to point to the current version of GPT-4o used by ChatGPT. It therefore differs slightly from the API version of [GPT-4o](/models/openai/gpt-4o) in that it has additional RLHF. It is intended for research and evaluation.\n\nOpenAI notes that this model is not suited for production use-cases as it may be removed or redirected to another model in the future.",
            "extendedThinking": false,
            "id": "openai-chatgpt-4-o",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/chatgpt-4o",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-08-14T01:00:00.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 5e-7,
                "output": 0.000008
            },
            "description": "GPT-4.1 is a flagship large language model optimized for advanced instruction following, real-world software engineering, and long-context reasoning. It supports a 1 million token context window and outperforms GPT-4o and GPT-4.5 across coding (54.6% SWE-bench Verified), instruction compliance (87.4% IFEval), and multimodal understanding benchmarks. It is tuned for precise code diffs, agent reliability, and high recall in large document contexts, making it ideal for agents, IDE tooling, and enterprise knowledge retrieval.",
            "extendedThinking": false,
            "id": "openai-gpt-4-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/gpt-4.1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:05.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4e-7,
                "inputCacheHit": 1e-7,
                "output": 0.0000016
            },
            "description": "GPT-4.1 Mini is a mid-sized model delivering performance competitive with GPT-4o at substantially lower latency and cost. It retains a 1 million token context window and scores 45.1% on hard instruction evals, 35.8% on MultiChallenge, and 84.1% on IFEval. Mini also shows strong coding ability (e.g., 31.6% on Aiders polyglot diff benchmark) and vision understanding, making it suitable for interactive applications with tight performance constraints.",
            "extendedThinking": false,
            "id": "openai-gpt-4-1-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/gpt-4.1-mini",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:01.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 2.5e-8,
                "output": 4e-7
            },
            "description": "For tasks that demand low latency, GPT4.1 nano is the fastest and cheapest model in the GPT-4.1 series. It delivers exceptional performance at a small size with its 1 million token context window, and scores 80.1% on MMLU, 50.3% on GPQA, and 9.8% on Aider polyglot coding  even higher than GPT4o mini. Its ideal for tasks like classification or autocompletion.",
            "extendedThinking": false,
            "id": "openai-gpt-4-1-nano",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/gpt-4.1-nano",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:22:49.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000025,
                "inputCacheHit": 0.00000125,
                "output": 0.00001
            },
            "description": "The 2024-11-20 version of GPT-4o offers a leveled-up creative writing ability with more natural, engaging, and tailored writing to improve relevance & readability. Its also better at working with uploaded files, providing deeper insights & more thorough responses.\n\nGPT-4o (\"o\" for \"omni\") is OpenAI's latest AI model, supporting both text and image inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective. GPT-4o also offers improved performance in processing non-English languages and enhanced visual capabilities.",
            "extendedThinking": false,
            "id": "openai-gpt-4-o",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/gpt-4o",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-11-20T18:33:14.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000025,
                "inputCacheHit": 0.0000025,
                "output": 0.00001
            },
            "description": "The 2024-11-20 version of GPT-4o offers a leveled-up creative writing ability with more natural, engaging, and tailored writing to improve relevance & readability. Its also better at working with uploaded files, providing deeper insights & more thorough responses.\n\nGPT-4o (\"o\" for \"omni\") is OpenAI's latest AI model, supporting both text and image inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective. GPT-4o also offers improved performance in processing non-English languages and enhanced visual capabilities.",
            "extendedThinking": false,
            "id": "openai-gpt-4-o-2024-05-13",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4096
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/gpt-4o-2024-05-13",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-11-20T18:33:14.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000025,
                "inputCacheHit": 0.00000125,
                "output": 0.00001
            },
            "description": "The 2024-11-20 version of GPT-4o offers a leveled-up creative writing ability with more natural, engaging, and tailored writing to improve relevance & readability. Its also better at working with uploaded files, providing deeper insights & more thorough responses.\n\nGPT-4o (\"o\" for \"omni\") is OpenAI's latest AI model, supporting both text and image inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective. GPT-4o also offers improved performance in processing non-English languages and enhanced visual capabilities.",
            "extendedThinking": false,
            "id": "openai-gpt-4-o-2024-08-06",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/gpt-4o-2024-08-06",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-11-20T18:33:14.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000025,
                "inputCacheHit": 0.00000125,
                "output": 0.00001
            },
            "description": "The 2024-11-20 version of GPT-4o offers a leveled-up creative writing ability with more natural, engaging, and tailored writing to improve relevance & readability. Its also better at working with uploaded files, providing deeper insights & more thorough responses.\n\nGPT-4o (\"o\" for \"omni\") is OpenAI's latest AI model, supporting both text and image inputs with text outputs. It maintains the intelligence level of [GPT-4 Turbo](/models/openai/gpt-4-turbo) while being twice as fast and 50% more cost-effective. GPT-4o also offers improved performance in processing non-English languages and enhanced visual capabilities.",
            "extendedThinking": false,
            "id": "openai-gpt-4-o-2024-11-20",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/gpt-4o-2024-11-20",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-11-20T18:33:14.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.5e-7,
                "inputCacheHit": 7.5e-8,
                "output": 6e-7
            },
            "description": "GPT-4o mini is OpenAI's newest model after [GPT-4 Omni](/models/openai/gpt-4o), supporting both text and image inputs with text outputs.\n\nAs their most advanced small model, it is many multiples more affordable than other recent frontier models, and more than 60% cheaper than [GPT-3.5 Turbo](/models/openai/gpt-3.5-turbo). It maintains SOTA intelligence, while being significantly more cost-effective.\n\nGPT-4o mini achieves an 82% score on MMLU and presently ranks higher than GPT-4 on chat preferences [common leaderboards](https://arena.lmsys.org/).\n\nCheck out the [launch announcement](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/) to learn more.\n\n#multimodal",
            "extendedThinking": false,
            "id": "openai-gpt-4-o-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/gpt-4o-mini",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-07-18T01:00:00.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 1.25e-7,
                "output": 0.00001
            },
            "description": "GPT-5 is OpenAI's flagship model for coding, reasoning, and agentic tasks across domains.",
            "extendedThinking": true,
            "id": "openai-gpt-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/gpt-5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-08-07T17:08:26.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 1.25e-7,
                "output": 0.00001
            },
            "description": "GPT-5 is OpenAI's flagship model for coding, reasoning, and agentic tasks across domains.",
            "extendedThinking": true,
            "id": "openai-gpt-5-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/gpt-5.1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-08-07T17:08:26.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 1.25e-7,
                "output": 0.00001
            },
            "description": "GPT-5.1 Chat points to the GPT-5.1 snapshot currently used in ChatGPT. We recommend GPT-5.1 for most API usage, but feel free to use this GPT-5.1 Chat model to test our latest improvements for chat use cases.",
            "extendedThinking": true,
            "id": "openai-gpt-5-1-chat",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/gpt-5.1-chat",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-12-01T17:28:11.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000175,
                "inputCacheHit": 1.75e-7,
                "output": 0.000014
            },
            "description": "The best model for coding and agentic tasks across industries",
            "extendedThinking": true,
            "id": "openai-gpt-5-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/gpt-5.2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-12-11T17:08:26.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000175,
                "inputCacheHit": 1.75e-7,
                "output": 0.000014
            },
            "description": "GPT5.2 sets a new state of the art across many benchmarks, including GDPval, where it outperforms industry professionals at well-specified knowledge work tasks spanning 44 occupations.",
            "extendedThinking": true,
            "id": "openai-gpt-5-2-chat",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/gpt-5.2-chat",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-12-19T17:08:26.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 6.25e-7,
                "inputCacheHit": 6.25e-8,
                "output": 0.000005
            },
            "description": "GPT-5 is OpenAI's flagship model for coding, reasoning, and agentic tasks across domains.",
            "extendedThinking": true,
            "id": "openai-gpt-5-:flex",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/gpt-5:flex",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-08-07T17:08:26.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000025,
                "inputCacheHit": 2.5e-7,
                "output": 0.00002
            },
            "description": "GPT-5 is OpenAI's flagship model for coding, reasoning, and agentic tasks across domains.",
            "extendedThinking": true,
            "id": "openai-gpt-5-:priority",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/gpt-5:priority",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-08-07T17:08:26.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 1.25e-7,
                "output": 0.00001
            },
            "description": "GPT-5 is OpenAI's flagship model for coding, reasoning, and agentic tasks across domains.",
            "extendedThinking": true,
            "id": "openai-gpt-5-chat",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/gpt-5-chat",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-08-07T17:08:26.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2.5e-7,
                "inputCacheHit": 2.5e-8,
                "output": 0.000002
            },
            "description": "GPT-5 mini is a faster, more cost-efficient version of GPT-5. It's great for well-defined tasks and precise prompts.",
            "extendedThinking": true,
            "id": "openai-gpt-5-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/gpt-5-mini",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-08-07T17:05:19.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.25e-7,
                "inputCacheHit": 1.25e-8,
                "output": 0.000001
            },
            "description": "GPT-5 mini is a faster, more cost-efficient version of GPT-5. It's great for well-defined tasks and precise prompts.",
            "extendedThinking": true,
            "id": "openai-gpt-5-mini:flex",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/gpt-5-mini:flex",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-08-07T17:05:19.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4.5e-7,
                "inputCacheHit": 4.5e-8,
                "output": 0.0000036
            },
            "description": "GPT-5 is OpenAI's flagship model for coding, reasoning, and agentic tasks across domains.",
            "extendedThinking": true,
            "id": "openai-gpt-5-mini:priority",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/gpt-5-mini:priority",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-08-07T17:08:26.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 5e-8,
                "inputCacheHit": 5e-9,
                "output": 4e-7
            },
            "description": "GPT-5 nano is OpenAI's fastest, cheapest version of GPT-5. It's great for summarization and classification tasks.",
            "extendedThinking": true,
            "id": "openai-gpt-5-nano",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/gpt-5-nano",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-08-07T17:07:35.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2.5e-8,
                "inputCacheHit": 2.5e-9,
                "output": 2e-7
            },
            "description": "GPT-5 nano is OpenAI's fastest, cheapest version of GPT-5. It's great for summarization and classification tasks.",
            "extendedThinking": true,
            "id": "openai-gpt-5-nano:flex",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/gpt-5-nano:flex",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-08-07T17:07:35.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000015,
                "inputCacheHit": 0.0000075,
                "output": 0.00006
            },
            "description": "The o1 series of models are trained with reinforcement learning to perform complex reasoning. o1 models think before they answer, producing a long internal chain of thought before responding to the user. The o1 reasoning model is designed to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini models is October, 2023.",
            "extendedThinking": true,
            "id": "openai-o-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/o1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2024-12-17T18:26:39.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000015,
                "inputCacheHit": 0.0000075,
                "output": 0.00006
            },
            "description": "The o1 series of models are trained with reinforcement learning to perform complex reasoning. o1 models think before they answer, producing a long internal chain of thought before responding to the user. The o1 reasoning model is designed to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini models is October, 2023.",
            "extendedThinking": true,
            "id": "openai-o-1-:high",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/o1:high",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2024-12-17T18:26:39.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000015,
                "inputCacheHit": 0.0000075,
                "output": 0.00006
            },
            "description": "The o1 series of models are trained with reinforcement learning to perform complex reasoning. o1 models think before they answer, producing a long internal chain of thought before responding to the user. The o1 reasoning model is designed to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini models is October, 2023.",
            "extendedThinking": true,
            "id": "openai-o-1-:low",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/o1:low",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2024-12-17T18:26:39.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000015,
                "inputCacheHit": 0.0000075,
                "output": 0.00006
            },
            "description": "The o1 series of models are trained with reinforcement learning to perform complex reasoning. o1 models think before they answer, producing a long internal chain of thought before responding to the user. The o1 reasoning model is designed to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini models is October, 2023.",
            "extendedThinking": true,
            "id": "openai-o-1-:medium",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/o1:medium",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2024-12-17T18:26:39.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00015,
                "inputCacheHit": 0.00015,
                "output": 0.0006
            },
            "description": "The o1 series of models are trained with reinforcement learning to perform complex reasoning. o1 models think before they answer, producing a long internal chain of thought before responding to the user. The o1 reasoning model is designed to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini models is October, 2023.",
            "extendedThinking": true,
            "id": "openai-o-1-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/o1-pro",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-02-06T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 5e-7,
                "output": 0.000008
            },
            "description": "The o1 series of models are trained with reinforcement learning to perform complex reasoning. o1 models think before they answer, producing a long internal chain of thought before responding to the user. The o1 reasoning model is designed to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini models is October, 2023.",
            "extendedThinking": true,
            "id": "openai-o-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/o3",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T18:10:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000001,
                "inputCacheHit": 2.5e-7,
                "output": 0.000004
            },
            "description": "O3 Flex is a cheaper version of the o3 model",
            "extendedThinking": true,
            "id": "openai-o-3-:flex",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/o3:flex",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T18:10:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00001,
                "inputCacheHit": 0.0000025,
                "output": 0.00004
            },
            "description": "O3 Deep Research is a premium OpenAI model tuned for long-context research and high-recall reasoning tasks, optimized for analytical depth.",
            "extendedThinking": true,
            "id": "openai-o-3-deep-research",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 100000,
                "output": 200000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/o3-deep-research",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-07-17T17:01:06.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 5.5e-7,
                "output": 0.0000044
            },
            "description": "o3-mini is OpenAI's most recent small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. o3-mini also supports key developer features, like Structured Outputs, function calling, Batch API, and more. Like other models in the o-series, it is designed to excel at science, math, and coding tasks.",
            "extendedThinking": true,
            "id": "openai-o-3-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "openai/o3-mini",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-01-31T19:28:41.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 5.5e-7,
                "output": 0.0000044
            },
            "description": "o3-mini is OpenAI's most recent small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. o3-mini also supports key developer features, like Structured Outputs, function calling, Batch API, and more. Like other models in the o-series, it is designed to excel at science, math, and coding tasks.",
            "extendedThinking": true,
            "id": "openai-o-3-mini:high",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "openai/o3-mini:high",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-01-31T19:28:41.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 5.5e-7,
                "output": 0.0000044
            },
            "description": "o3-mini is OpenAI's most recent small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. o3-mini also supports key developer features, like Structured Outputs, function calling, Batch API, and more. Like other models in the o-series, it is designed to excel at science, math, and coding tasks.",
            "extendedThinking": true,
            "id": "openai-o-3-mini:low",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "openai/o3-mini:low",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-01-31T19:28:41.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 5.5e-7,
                "output": 0.0000044
            },
            "description": "o3-mini is OpenAI's most recent small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. o3-mini also supports key developer features, like Structured Outputs, function calling, Batch API, and more. Like other models in the o-series, it is designed to excel at science, math, and coding tasks.",
            "extendedThinking": true,
            "id": "openai-o-3-mini:medium",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "openai/o3-mini:medium",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-01-31T19:28:41.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 2.75e-7,
                "output": 0.0000044
            },
            "description": "o3-mini is OpenAI's most recent small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. o3-mini also supports key developer features, like Structured Outputs, function calling, Batch API, and more. Like other models in the o-series, it is designed to excel at science, math, and coding tasks.",
            "extendedThinking": true,
            "id": "openai-o-4-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "openai/o4-mini",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 5.5e-7,
                "inputCacheHit": 1.38e-7,
                "output": 0.0000022
            },
            "description": "o3-mini is OpenAI's most recent small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. o3-mini also supports key developer features, like Structured Outputs, function calling, Batch API, and more. Like other models in the o-series, it is designed to excel at science, math, and coding tasks.",
            "extendedThinking": true,
            "id": "openai-o-4-mini:flex",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "openai/o4-mini:flex",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 2.75e-7,
                "output": 0.0000044
            },
            "description": "o3-mini is OpenAI's most recent small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. o3-mini also supports key developer features, like Structured Outputs, function calling, Batch API, and more. Like other models in the o-series, it is designed to excel at science, math, and coding tasks.",
            "extendedThinking": true,
            "id": "openai-o-4-mini:high",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "openai/o4-mini:high",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 2.75e-7,
                "output": 0.0000044
            },
            "description": "o3-mini is OpenAI's most recent small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. o3-mini also supports key developer features, like Structured Outputs, function calling, Batch API, and more. Like other models in the o-series, it is designed to excel at science, math, and coding tasks.",
            "extendedThinking": true,
            "id": "openai-o-4-mini:low",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "openai/o4-mini:low",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 2.75e-7,
                "output": 0.0000044
            },
            "description": "o3-mini is OpenAI's most recent small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. o3-mini also supports key developer features, like Structured Outputs, function calling, Batch API, and more. Like other models in the o-series, it is designed to excel at science, math, and coding tasks.",
            "extendedThinking": true,
            "id": "openai-o-4-mini:medium",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "openai/o4-mini:medium",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 5e-7,
                "output": 0.000008
            },
            "description": "Optimized for fast reasoning and minimal latency, O4 Mini Deep Research supports caching and high-speed inference. Ideal for lightweight agent use.",
            "extendedThinking": true,
            "id": "openai-o-4-mini-deep-research",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 100000,
                "output": 200000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai/o4-mini-deep-research",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-07-17T17:00:50.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 5e-7,
                "output": 0.000008
            },
            "description": "GPT-4.1 is a flagship large language model optimized for advanced instruction following, real-world software engineering, and long-context reasoning. It supports a 1 million token context window and outperforms GPT-4o and GPT-4.5 across coding (54.6% SWE-bench Verified), instruction compliance (87.4% IFEval), and multimodal understanding benchmarks. It is tuned for precise code diffs, agent reliability, and high recall in large document contexts, making it ideal for agents, IDE tooling, and enterprise knowledge retrieval.",
            "extendedThinking": false,
            "id": "openai-responses-gpt-4-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai-responses/gpt-4.1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:05.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 4e-7,
                "inputCacheHit": 1e-7,
                "output": 0.0000016
            },
            "description": "GPT-4.1 Mini is a mid-sized model delivering performance competitive with GPT-4o at substantially lower latency and cost. It retains a 1 million token context window and scores 45.1% on hard instruction evals, 35.8% on MultiChallenge, and 84.1% on IFEval. Mini also shows strong coding ability (e.g., 31.6% on Aiders polyglot diff benchmark) and vision understanding, making it suitable for interactive applications with tight performance constraints.",
            "extendedThinking": false,
            "id": "openai-responses-gpt-4-1-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai-responses/gpt-4.1-mini",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:23:01.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 2.5e-8,
                "output": 4e-7
            },
            "description": "For tasks that demand low latency, GPT4.1 nano is the fastest and cheapest model in the GPT-4.1 series. It delivers exceptional performance at a small size with its 1 million token context window, and scores 80.1% on MMLU, 50.3% on GPQA, and 9.8% on Aider polyglot coding  even higher than GPT4o mini. Its ideal for tasks like classification or autocompletion.",
            "extendedThinking": false,
            "id": "openai-responses-gpt-4-1-nano",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1047576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai-responses/gpt-4.1-nano",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-14T18:22:49.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 1.25e-7,
                "output": 0.00001
            },
            "description": "GPT-5 is OpenAI's flagship model for coding, reasoning, and agentic tasks across domains.",
            "extendedThinking": true,
            "id": "openai-responses-gpt-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai-responses/gpt-5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-08-07T17:08:26.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 1.25e-7,
                "output": 0.00001
            },
            "description": "GPT-5.1-Codex is a version of GPT-5 optimized for agentic coding tasks in Codex or similar environments",
            "extendedThinking": true,
            "id": "openai-responses-gpt-5-1-codex",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai-responses/gpt-5.1-codex",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-12-02T23:43:36.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 1.25e-7,
                "output": 0.00001
            },
            "description": "GPT-5-Codex is a version of GPT-5 optimized for agentic coding tasks in Codex or similar environments",
            "extendedThinking": true,
            "id": "openai-responses-gpt-5-codex",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai-responses/gpt-5-codex",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-09-24T11:05:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2.5e-7,
                "inputCacheHit": 2.5e-8,
                "output": 0.000002
            },
            "description": "GPT-5 mini is a faster, more cost-efficient version of GPT-5. It's great for well-defined tasks and precise prompts.",
            "extendedThinking": true,
            "id": "openai-responses-gpt-5-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai-responses/gpt-5-mini",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-08-07T17:05:19.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 5e-8,
                "inputCacheHit": 5e-9,
                "output": 4e-7
            },
            "description": "GPT-5 nano is OpenAI's fastest, cheapest version of GPT-5. It's great for summarization and classification tasks.",
            "extendedThinking": true,
            "id": "openai-responses-gpt-5-nano",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai-responses/gpt-5-nano",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-08-07T17:07:35.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000015,
                "inputCacheHit": 0.000015,
                "output": 0.00012
            },
            "description": "GPT-5 Pro is OpenAIs extended-reasoning tier of GPT-5, built to push reliability on hard problems, long tool chains, and agentic workflows. It keeps GPT-5s multimodal skills and very large context (API page lists up to 400K tokens) while allocating more compute to think longer and plan better, improving code generation, math, and complex writing beyond standard GPT-5/Thinking. OpenAI positions Pro as the version that uses extended reasoning for even more comprehensive and accurate answers, targeting high-stakes tasks and enterprise use.",
            "extendedThinking": true,
            "id": "openai-responses-gpt-5-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 272000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai-responses/gpt-5-pro",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-10-06T11:05:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 5.5e-7,
                "output": 0.0000044
            },
            "description": "o3-mini is OpenAI's most recent small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. o3-mini also supports key developer features, like Structured Outputs, function calling, Batch API, and more. Like other models in the o-series, it is designed to excel at science, math, and coding tasks.",
            "extendedThinking": true,
            "id": "openai-responses-o-3-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "openai-responses/o3-mini",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-01-31T19:28:41.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00002,
                "inputCacheHit": 0.00002,
                "output": 0.00008
            },
            "description": "The o3 series of models are trained with reinforcement learning to perform complex reasoning. o1 models think before they answer, producing a long internal chain of thought before responding to the user. The o1 reasoning model is designed to solve hard problems across domains. The knowledge cutoff for o1 and o1-mini models is October, 2023.",
            "extendedThinking": true,
            "id": "openai-responses-o-3-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "openai-responses/o3-pro",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-06-11T00:32:32.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000011,
                "inputCacheHit": 2.75e-7,
                "output": 0.0000044
            },
            "description": "o3-mini is OpenAI's most recent small reasoning model, providing high intelligence at the same cost and latency targets of o1-mini. o3-mini also supports key developer features, like Structured Outputs, function calling, Batch API, and more. Like other models in the o-series, it is designed to excel at science, math, and coding tasks.",
            "extendedThinking": true,
            "id": "openai-responses-o-4-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 100000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "openai-responses/o4-mini",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-04-16T17:29:02.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 3e-7,
                "output": 5e-7
            },
            "description": "Gemma 3 1B is the smallest of the new Gemma 3 family. It handles context windows up to 32k tokens, understands over 140 languages, and offers improved math, reasoning, and chat capabilities, including structured outputs and function calling. Note: Gemma 3 1B is not multimodal. For the smallest multimodal Gemma 3 model, please see [Gemma 3 4B](google/gemma-3-4b-it)",
            "extendedThinking": false,
            "id": "parasail-parasail-gemma-3-27-b-it",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "parasail/parasail-gemma3-27b-it",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-03-14T14:45:56.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 9.9e-7,
                "inputCacheHit": 9.9e-7,
                "output": 0.00000299
            },
            "extendedThinking": false,
            "id": "parasail-parasail-kimi-k-2-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "parasail/parasail-kimi-k2-instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-08-18T16:23:40.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 7e-7,
                "inputCacheHit": 7e-7,
                "output": 7e-7
            },
            "extendedThinking": false,
            "id": "parasail-parasail-qwen-25-vl-72-b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "parasail/parasail-qwen25-vl-72b-instruct",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-02-06T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.5e-7,
                "inputCacheHit": 1.5e-7,
                "output": 8.5e-7
            },
            "extendedThinking": false,
            "id": "parasail-parasail-qwen-3-235-b-a-22-b-instruct-2507",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "parasail/parasail-qwen3-235b-a22b-instruct-2507",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-07-21T16:23:40.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000001,
                "inputCacheHit": 0.000001,
                "output": 0.000001
            },
            "description": "Lightweight offering with search grounding, quicker and cheaper than Sonar Pro.",
            "extendedThinking": false,
            "id": "perplexity-sonar",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "perplexity/sonar",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-03-07T02:08:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 0.000003,
                "output": 0.000015
            },
            "description": "Premier search offering with search grounding, supporting advanced queries and follow-ups.",
            "extendedThinking": false,
            "id": "perplexity-sonar-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 204800,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "perplexity/sonar-pro",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-03-07T02:08:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 0.000002,
                "output": 0.000008
            },
            "description": "Premier reasoning offering powered by DeepSeek R1 with Chain of Thought (CoT).",
            "extendedThinking": false,
            "id": "perplexity-sonar-reasoning-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "perplexity/sonar-reasoning-pro",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-03-07T02:08:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": true,
            "id": "smart-task",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "smart/task",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-02-06T18:18:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 0.000003,
                "output": 0.000007
            },
            "description": "DeepSeek-R1-Distill-Qwen-7B is a 7 billion parameter dense language model distilled from DeepSeek-R1, leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's larger models. The distillation process transfers advanced reasoning, math, and code capabilities into a smaller, more efficient model architecture based on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189), and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive accuracy relative to larger models while maintaining smaller inference costs.",
            "extendedThinking": false,
            "id": "together-deepseek-ai-deep-seek-r1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 64000,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "together/deepseek-ai/DeepSeek-R1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-05-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 0.00000125,
                "output": 0.00000125
            },
            "description": "DeepSeek-R1-Distill-Qwen-7B is a 7 billion parameter dense language model distilled from DeepSeek-R1, leveraging reinforcement learning-enhanced reasoning data generated by DeepSeek's larger models. The distillation process transfers advanced reasoning, math, and code capabilities into a smaller, more efficient model architecture based on Qwen2.5-Math-7B. This model demonstrates strong performance across mathematical benchmarks (92.8% pass@1 on MATH-500), coding tasks (Codeforces rating 1189), and general reasoning (49.1% pass@1 on GPQA Diamond), achieving competitive accuracy relative to larger models while maintaining smaller inference costs.",
            "extendedThinking": false,
            "id": "together-deepseek-ai-deep-seek-v3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "together/deepseek-ai/DeepSeek-V3",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-05-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 6e-8,
                "inputCacheHit": 6e-8,
                "output": 6e-8
            },
            "description": "A lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response times are needed most.",
            "extendedThinking": false,
            "id": "together-meta-llama-llama-3-2-3b-instruct-turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "together/meta-llama/Llama-3.2-3B-Instruct-Turbo",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-01-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 8.8e-7,
                "inputCacheHit": 8.8e-7,
                "output": 8.8e-7
            },
            "description": "A lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response times are needed most.",
            "extendedThinking": false,
            "id": "together-meta-llama-llama-3-3-70b-instruct-turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-01-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2e-7,
                "inputCacheHit": 2e-7,
                "output": 2e-7
            },
            "description": "A lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response times are needed most.",
            "extendedThinking": false,
            "id": "together-meta-llama-llama-guard-2-8-b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "together/meta-llama/LlamaGuard-2-8b",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-01-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 8.8e-7,
                "inputCacheHit": 8.8e-7,
                "output": 8.8e-7
            },
            "description": "A lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response times are needed most.",
            "extendedThinking": false,
            "id": "together-meta-llama-meta-llama-3-1-70b-instruct-turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "together/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-01-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.8e-7,
                "inputCacheHit": 1.8e-7,
                "output": 1.8e-7
            },
            "description": "A lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response times are needed most.",
            "extendedThinking": false,
            "id": "together-meta-llama-meta-llama-3-1-8b-instruct-turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "together/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-01-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 1e-7,
                "output": 1e-7
            },
            "description": "A lightweight and ultra-fast variant of Llama 3.3 70B, for use when quick response times are needed most.",
            "extendedThinking": false,
            "id": "together-meta-llama-meta-llama-3-8b-instruct-lite",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "together/meta-llama/Meta-Llama-3-8B-Instruct-Lite",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-01-30T19:03:57.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0000012,
                "inputCacheHit": 0.0000012,
                "output": 0.0000012
            },
            "description": "Qwen3, the latest generation in the Qwen large language model series, features both dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual support, and advanced agent tasks. Its unique ability to switch seamlessly between a thinking mode for complex reasoning and a non-thinking mode for efficient dialogue ensures versatile, high-quality performance.\n\nSignificantly outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics, coding, commonsense reasoning, creative writing, and interactive dialogue capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3 billion activated), 48 layers, 128 experts (8 activated per task), and supports up to 131K token contexts with YaRN, setting a new standard among open-source models.",
            "extendedThinking": false,
            "id": "together-qwen-qwen-2-5-72b-instruct-turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "together/Qwen/Qwen2.5-72B-Instruct-Turbo",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-28T23:16:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 3e-7,
                "output": 3e-7
            },
            "description": "Qwen3, the latest generation in the Qwen large language model series, features both dense and mixture-of-experts (MoE) architectures to excel in reasoning, multilingual support, and advanced agent tasks. Its unique ability to switch seamlessly between a thinking mode for complex reasoning and a non-thinking mode for efficient dialogue ensures versatile, high-quality performance.\n\nSignificantly outperforming prior models like QwQ and Qwen2.5, Qwen3 delivers superior mathematics, coding, commonsense reasoning, creative writing, and interactive dialogue capabilities. The Qwen3-30B-A3B variant includes 30.5 billion parameters (3.3 billion activated), 48 layers, 128 experts (8 activated per task), and supports up to 131K token contexts with YaRN, setting a new standard among open-source models.",
            "extendedThinking": false,
            "id": "together-qwen-qwen-2-5-7b-instruct-turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "together/Qwen/Qwen2.5-7B-Instruct-Turbo",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-04-28T23:16:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's previous most intelligent model. High level of intelligence and capability. Excells in coding.",
            "extendedThinking": false,
            "id": "vertex-claude-3-5-sonnet",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-3-5-sonnet",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-06-20T01:00:00.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's previous most intelligent model. High level of intelligence and capability. Excells in coding.",
            "extendedThinking": false,
            "id": "vertex-claude-3-5-sonnet@europe-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-3-5-sonnet@europe-west1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-06-20T01:00:00.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's previous most intelligent model. High level of intelligence and capability. Excells in coding.",
            "extendedThinking": false,
            "id": "vertex-claude-3-5-sonnet@us-east-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 8192
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-3-5-sonnet@us-east5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2024-06-20T01:00:00.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "vertex-claude-3-7-sonnet",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-3-7-sonnet",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2024-06-20T01:00:00.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "vertex-claude-3-7-sonnet@europe-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-3-7-sonnet@europe-west1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2024-06-20T01:00:00.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "vertex-claude-3-7-sonnet@us-east-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-3-7-sonnet@us-east5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2024-06-20T01:00:00.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000001,
                "inputCacheHit": 1e-7,
                "output": 0.000005
            },
            "description": "Anthropic Haiku 4.5",
            "extendedThinking": false,
            "id": "vertex-claude-haiku-4-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-haiku-4-5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000001,
                "inputCacheHit": 1e-7,
                "output": 0.000005
            },
            "description": "Anthropic Haiku 4.5",
            "extendedThinking": false,
            "id": "vertex-claude-haiku-4-5-@europe-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-haiku-4-5@europe-west1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000001,
                "inputCacheHit": 1e-7,
                "output": 0.000005
            },
            "description": "Anthropic Haiku 4.5",
            "extendedThinking": false,
            "id": "vertex-claude-haiku-4-5-@us-east-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-haiku-4-5@us-east5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000015,
                "inputCacheHit": 0.0000015,
                "output": 0.000075
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "vertex-claude-opus-4",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-opus-4",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000015,
                "inputCacheHit": 0.0000015,
                "output": 0.000075
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "vertex-claude-opus-4-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-opus-4-1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000015,
                "inputCacheHit": 0.0000015,
                "output": 0.000075
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "vertex-claude-opus-4-1-@europe-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-opus-4-1@europe-west1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000015,
                "inputCacheHit": 0.0000015,
                "output": 0.000075
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "vertex-claude-opus-4-1-@us-east-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-opus-4-1@us-east5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000005,
                "inputCacheHit": 5e-7,
                "output": 0.000025
            },
            "extendedThinking": true,
            "id": "vertex-claude-opus-4-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-opus-4-5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-11-24T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000005,
                "inputCacheHit": 5e-7,
                "output": 0.000025
            },
            "extendedThinking": true,
            "id": "vertex-claude-opus-4-5-@europe-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-opus-4-5@europe-west1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-11-24T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000005,
                "inputCacheHit": 5e-7,
                "output": 0.000025
            },
            "extendedThinking": true,
            "id": "vertex-claude-opus-4-5-@us-east-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-opus-4-5@us-east5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-11-24T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000015,
                "inputCacheHit": 0.0000015,
                "output": 0.000075
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "vertex-claude-opus-4-@europe-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-opus-4@europe-west1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000015,
                "inputCacheHit": 0.0000015,
                "output": 0.000075
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "vertex-claude-opus-4-@us-east-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-opus-4@us-east5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "vertex-claude-sonnet-4",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-sonnet-4",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "vertex-claude-sonnet-4-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-sonnet-4-5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "vertex-claude-sonnet-4-5-@europe-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-sonnet-4-5@europe-west1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "vertex-claude-sonnet-4-5-@us-east-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-sonnet-4-5@us-east5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "vertex-claude-sonnet-4-@europe-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-sonnet-4@europe-west1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 3e-7,
                "output": 0.000015
            },
            "description": "Anthropic's most intelligent model. The first hybrid reasoning model on the market with the highest level of intelligence and capability with toggleable extended thinking. Top-tier results in reasoning, coding, multilingual tasks, long-context handling, honesty, and image processing.",
            "extendedThinking": true,
            "id": "vertex-claude-sonnet-4-@us-east-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 64000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/claude-sonnet-4@us-east5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-22T17:12:51.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash@europe-central-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash@europe-central2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash@europe-north-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash@europe-north1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash@europe-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash@europe-west1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash@europe-west-4",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash@europe-west4",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash@europe-west-8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash@europe-west8",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash@us-central-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash@us-central1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash@us-east-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash@us-east1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash@us-east-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash@us-east5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash@us-south-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash@us-south1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 7.5e-8,
                "output": 0.0000025
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash@us-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash@us-west1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 3e-7,
                "output": 0.00003
            },
            "description": "Google's first hybrid reasoning model which supports a 1M token context window and has thinking budgets. Most balanced Gemini model, optimized for low latency use cases.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash-image-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash-image-preview",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-09-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 1e-8,
                "output": 4e-7
            },
            "description": "Google's smallest and most cost effective model, built for at scale usage.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash-lite",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash-lite",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 1e-8,
                "output": 4e-7
            },
            "description": "Google's smallest and most cost effective model, built for at scale usage.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash-lite@europe-central-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash-lite@europe-central2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 1e-8,
                "output": 4e-7
            },
            "description": "Google's smallest and most cost effective model, built for at scale usage.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash-lite@europe-north-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash-lite@europe-north1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 1e-8,
                "output": 4e-7
            },
            "description": "Google's smallest and most cost effective model, built for at scale usage.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash-lite@europe-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash-lite@europe-west1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 1e-8,
                "output": 4e-7
            },
            "description": "Google's smallest and most cost effective model, built for at scale usage.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash-lite@europe-west-4",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash-lite@europe-west4",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 1e-8,
                "output": 4e-7
            },
            "description": "Google's smallest and most cost effective model, built for at scale usage.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash-lite@europe-west-8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash-lite@europe-west8",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 1e-8,
                "output": 4e-7
            },
            "description": "Google's smallest and most cost effective model, built for at scale usage.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash-lite@us-central-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash-lite@us-central1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 1e-8,
                "output": 4e-7
            },
            "description": "Google's smallest and most cost effective model, built for at scale usage.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash-lite@us-east-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash-lite@us-east1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 1e-8,
                "output": 4e-7
            },
            "description": "Google's smallest and most cost effective model, built for at scale usage.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash-lite@us-east-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash-lite@us-east5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 1e-8,
                "output": 4e-7
            },
            "description": "Google's smallest and most cost effective model, built for at scale usage.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash-lite@us-south-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash-lite@us-south1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": 1e-8,
                "output": 4e-7
            },
            "description": "Google's smallest and most cost effective model, built for at scale usage.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-flash-lite@us-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-flash-lite@us-west1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-20T18:25:24.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-pro",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-pro@europe-central-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-pro@europe-central2",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-pro@europe-north-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-pro@europe-north1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-pro@europe-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-pro@europe-west1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-pro@europe-west-4",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-pro@europe-west4",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-pro@europe-west-8",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-pro@europe-west8",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-pro@us-central-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-pro@us-central1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-pro@us-east-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-pro@us-east1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-pro@us-east-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-pro@us-east5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-pro@us-south-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-pro@us-south1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000125,
                "inputCacheHit": 3.1e-7,
                "output": 0.00001
            },
            "description": "Gemini 2.5 Pro is Googles state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks. It employs thinking capabilities, enabling it to reason through responses with enhanced accuracy and nuanced context handling. Gemini 2.5 Pro achieves top-tier performance on multiple benchmarks, including first-place positioning on the LMArena leaderboard, reflecting superior human-preference alignment and complex problem-solving abilities.",
            "extendedThinking": true,
            "id": "vertex-gemini-2-5-pro@us-west-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-2.5-pro@us-west1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 5e-7,
                "inputCacheHit": 5e-8,
                "output": 0.000003
            },
            "description": "Gemini 3 Flash Preview is designed to deliver strong agentic capabilities (near-Pro level) at substantial speed and value. Making it perfect for engaging multi-turn chats, and collaborating back and forth with your coding agent without getting out of flow. Compared to 2.5 Flash it delivers significant improvements across the board.",
            "extendedThinking": true,
            "id": "vertex-gemini-3-flash-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-3-flash-preview",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-12-18T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 2e-7,
                "output": 0.000012
            },
            "description": "Gemini 3 Pro Image, or Gemini 3 Pro (with Nano Banana), is designed to tackle the most challenging image generation by incorporating state-of-the-art reasoning capabilities. It's the best model for complex and multi-turn image generation and editing, having improved accuracy and enhanced image quality.",
            "extendedThinking": true,
            "id": "vertex-gemini-3-pro-image-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 32768
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-3-pro-image-preview",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 2e-7,
                "output": 0.000012
            },
            "description": "Gemini 3 Pro is designed to tackle the most challenging agentic problems with strong coding and state-of-the-art reasoning capabilities. It is the best model for complex multimodal understanding. Compared to Gemini 2.5 Pro, it improves significantly on complex instruction following and delivers outcomes with better output efficiency.",
            "extendedThinking": true,
            "id": "vertex-gemini-3-pro-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 65535
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "vertex/gemini-3-pro-preview",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-05-07T01:41:53.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000002,
                "inputCacheHit": 0.000002,
                "output": 0.00001
            },
            "description": "x AI's Our previous generation chat model.\n",
            "extendedThinking": false,
            "id": "xai-grok-2-1212",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "xai/grok-2-1212",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-10-16T10:16:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000005,
                "inputCacheHit": 0.000005,
                "output": 0.000025
            },
            "description": "Excels at enterprise use cases like data extraction, coding, and text summarization. Possesses deep domain knowledge in finance, healthcare, law, and science.",
            "extendedThinking": false,
            "id": "xai-grok-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "xai/grok-3",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-10-16T10:16:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 3e-7,
                "output": 5e-7
            },
            "description": "A lightweight model that thinks before responding. Fast, smart, and great for logic-based tasks that do not require deep domain knowledge. The raw thinking traces are accessible.",
            "extendedThinking": true,
            "id": "xai-grok-3-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "xai/grok-3-mini",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-10-16T10:16:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 3e-7,
                "output": 5e-7
            },
            "description": "A lightweight model that thinks before responding. Fast, smart, and great for logic-based tasks that do not require deep domain knowledge. The raw thinking traces are accessible.",
            "extendedThinking": true,
            "id": "xai-grok-3-mini:high",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "xai/grok-3-mini:high",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-10-16T10:16:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 3e-7,
                "inputCacheHit": 3e-7,
                "output": 5e-7
            },
            "description": "A lightweight model that thinks before responding. Fast, smart, and great for logic-based tasks that do not require deep domain knowledge. The raw thinking traces are accessible.",
            "extendedThinking": true,
            "id": "xai-grok-3-mini:low",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "xai/grok-3-mini:low",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-10-16T10:16:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000003,
                "inputCacheHit": 7.5e-7,
                "output": 0.000015
            },
            "description": "xAI's latest and greatest flagship model, offering unparalleled performance in natural language, math and reasoning - the perfect jack of all trades.",
            "extendedThinking": false,
            "id": "xai-grok-4",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "xai/grok-4",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-10-16T10:16:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2e-7,
                "inputCacheHit": 5e-8,
                "output": 5e-7
            },
            "description": "A frontier multimodal model optimized specifically for high-performance agentic tool calling.",
            "extendedThinking": false,
            "id": "xai-grok-4-1-fast-non-reasoning",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2000000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "xai/grok-4-1-fast-non-reasoning",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-12-01T17:14:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2e-7,
                "inputCacheHit": 5e-8,
                "output": 5e-7
            },
            "description": "A frontier multimodal model optimized specifically for high-performance agentic tool calling.",
            "extendedThinking": false,
            "id": "xai-grok-4-1-fast-reasoning",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2000000,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "xai/grok-4-1-fast-reasoning",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-12-01T17:14:44.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2e-7,
                "inputCacheHit": 5e-8,
                "output": 5e-7
            },
            "description": "xAI's latest advancement in cost-efficient reasoning models",
            "extendedThinking": false,
            "id": "xai-grok-4-fast",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2000000,
                "output": 30000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "xai/grok-4-fast",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-10-16T10:16:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2e-7,
                "inputCacheHit": 5e-8,
                "output": 5e-7
            },
            "description": "xAI's latest advancement in cost-efficient reasoning models",
            "extendedThinking": false,
            "id": "xai-grok-4-fast-non-reasoning",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2000000,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "xai/grok-4-fast-non-reasoning",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-10-16T10:16:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 2e-7,
                "inputCacheHit": 2e-8,
                "output": 0.0000015
            },
            "description": "A speedy and economical reasoning model that excels at agentic coding",
            "extendedThinking": false,
            "id": "xai-grok-code-fast-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 10000
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "xai/grok-code-fast-1",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": false,
            "releaseDate": "2025-10-16T10:16:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 6e-7,
                "inputCacheHit": 1.1e-7,
                "output": 0.0000022
            },
            "description": "GLM-4.5 and GLM-4.5-Air are Z AI's latest flagship models, purpose-built as foundational models for agent-oriented applications. Both leverage a Mixture-of-Experts (MoE) architecture. GLM-4.5 has a total parameter count of 355B with 32B active parameters per forward pass, while GLM-4.5-Air adopts a more streamlined design with 106B total parameters and 12B active parameters.",
            "extendedThinking": true,
            "id": "zai-glm-4-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 98304
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "zai/GLM-4.5",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-10-16T10:16:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 6e-7,
                "inputCacheHit": 1.1e-7,
                "output": 0.0000022
            },
            "description": "GLM-4.6 is Z AIs latest flagship model, designed to push agentic and coding performance further. It expands the context window from 128K to 200K tokens, improves reasoning and tool-use capabilities, and delivers stronger results in coding benchmarks and real-world development workflows. GLM-4.6 demonstrates refined writing quality, more capable agent behavior, and higher token efficiency (15% fewer tokens vs. GLM-4.5).\n\nEvaluations show clear gains over GLM-4.5 across reasoning, agents, and coding, reaching near parity with Claude Sonnet 4 in practical tasks while outperforming other open-source baselines. GLM-4.6 is available through the Z.ai API platform, OpenRouter, coding agents (Claude Code, Roo Code, Cline, Kilo Code), and soon as downloadable weights on HuggingFace and ModelScope.",
            "extendedThinking": true,
            "id": "zai-glm-4-6",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 128000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "zai/GLM-4.6",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-10-16T10:16:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 6e-7,
                "inputCacheHit": 1.1e-7,
                "output": 0.0000022
            },
            "description": "GLM-4.7 is Z AIs latest flagship model, designed to push agentic and coding performance further. It expands the context window from 128K to 200K tokens, improves reasoning and tool-use capabilities, and delivers stronger results in coding benchmarks and real-world development workflows. GLM-4.6 demonstrates refined writing quality, more capable agent behavior, and higher token efficiency (15% fewer tokens vs. GLM-4.5).\n\nEvaluations show clear gains over GLM-4.5 across reasoning, agents, and coding, reaching near parity with Claude Sonnet 4 in practical tasks while outperforming other open-source baselines. GLM-4.6 is available through the Z.ai API platform, OpenRouter, coding agents (Claude Code, Roo Code, Cline, Kilo Code), and soon as downloadable weights on HuggingFace and ModelScope.",
            "extendedThinking": true,
            "id": "zai-glm-4-7",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 128000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "zai/GLM-4.7",
            "openWeights": false,
            "ownedBy": "system",
            "provider": "Requesty",
            "providerDoc": "https://docs.requesty.ai/",
            "providerEnv": ["REQUESTY_API_KEY"],
            "providerId": "requesty",
            "providerModelsDevId": "requesty",
            "providerNpm": "@ai-sdk/requesty",
            "reasoning": true,
            "releaseDate": "2025-12-16T10:16:28.000Z",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "requesty"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "1gpt-oss-120-b-llama",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "1GPT-OSS-120BLlama",
            "openWeights": true,
            "provider": "Together AI",
            "providerDoc": "https://docs.together.ai/",
            "providerEnv": ["TOGETHER_API_KEY"],
            "providerId": "together-ai",
            "providerModelsDevId": "together-ai",
            "providerNpm": "@ai-sdk/together",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "together"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "252-ftogetherai-52386018",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "252Ftogetherai-52386018",
            "openWeights": false,
            "provider": "Together AI",
            "providerDoc": "https://docs.together.ai/",
            "providerEnv": ["TOGETHER_API_KEY"],
            "providerId": "together-ai",
            "providerModelsDevId": "together-ai",
            "providerNpm": "@ai-sdk/together",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "together"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "2-b-together",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "2BTogether",
            "openWeights": false,
            "provider": "Together AI",
            "providerDoc": "https://docs.together.ai/",
            "providerEnv": ["TOGETHER_API_KEY"],
            "providerId": "together-ai",
            "providerModelsDevId": "together-ai",
            "providerNpm": "@ai-sdk/together",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "together"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ai-together",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "AITogether",
            "openWeights": false,
            "provider": "Together AI",
            "providerDoc": "https://docs.together.ai/",
            "providerEnv": ["TOGETHER_API_KEY"],
            "providerId": "together-ai",
            "providerModelsDevId": "together-ai",
            "providerNpm": "@ai-sdk/together",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "together"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "content-together",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "contentTogether",
            "openWeights": false,
            "provider": "Together AI",
            "providerDoc": "https://docs.together.ai/",
            "providerEnv": ["TOGETHER_API_KEY"],
            "providerId": "together-ai",
            "providerModelsDevId": "together-ai",
            "providerNpm": "@ai-sdk/together",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "together"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "how-to-use-qwen-code",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "how-to-use-qwen-code",
            "openWeights": false,
            "provider": "Together AI",
            "providerDoc": "https://docs.together.ai/",
            "providerEnv": ["TOGETHER_API_KEY"],
            "providerId": "together-ai",
            "providerModelsDevId": "together-ai",
            "providerNpm": "@ai-sdk/together",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "together"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "i-together",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ITogether",
            "openWeights": false,
            "provider": "Together AI",
            "providerDoc": "https://docs.together.ai/",
            "providerEnv": ["TOGETHER_API_KEY"],
            "providerId": "together-ai",
            "providerModelsDevId": "together-ai",
            "providerNpm": "@ai-sdk/together",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "together"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "maverick-qwen",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MaverickQwen",
            "openWeights": false,
            "provider": "Together AI",
            "providerDoc": "https://docs.together.ai/",
            "providerEnv": ["TOGETHER_API_KEY"],
            "providerId": "together-ai",
            "providerModelsDevId": "together-ai",
            "providerNpm": "@ai-sdk/together",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "together"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0015,
                "inputCacheHit": null,
                "output": 0.0015
            },
            "extendedThinking": false,
            "id": "meta-llama",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "meta-llama",
            "openWeights": true,
            "provider": "Together AI",
            "providerDoc": "https://docs.together.ai/",
            "providerEnv": ["TOGETHER_API_KEY"],
            "providerId": "together-ai",
            "providerModelsDevId": "together-ai",
            "providerNpm": "@ai-sdk/together",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "together"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0015,
                "inputCacheHit": null,
                "output": 0.0015
            },
            "extendedThinking": false,
            "id": "meta-llama-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta-Llama-3",
            "openWeights": true,
            "provider": "Together AI",
            "providerDoc": "https://docs.together.ai/",
            "providerEnv": ["TOGETHER_API_KEY"],
            "providerId": "together-ai",
            "providerModelsDevId": "together-ai",
            "providerNpm": "@ai-sdk/together",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "together"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "models-llama",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "modelsLlama",
            "openWeights": true,
            "provider": "Together AI",
            "providerDoc": "https://docs.together.ai/",
            "providerEnv": ["TOGETHER_API_KEY"],
            "providerId": "together-ai",
            "providerModelsDevId": "together-ai",
            "providerNpm": "@ai-sdk/together",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "together"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "quickstart-llama",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "QuickstartLlama",
            "openWeights": true,
            "provider": "Together AI",
            "providerDoc": "https://docs.together.ai/",
            "providerEnv": ["TOGETHER_API_KEY"],
            "providerId": "together-ai",
            "providerModelsDevId": "together-ai",
            "providerNpm": "@ai-sdk/together",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "together"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "salesforce-llamarank",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "salesforce-llamarank",
            "openWeights": true,
            "provider": "Together AI",
            "providerDoc": "https://docs.together.ai/",
            "providerEnv": ["TOGETHER_API_KEY"],
            "providerId": "together-ai",
            "providerModelsDevId": "together-ai",
            "providerNpm": "@ai-sdk/together",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "together"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "scout-qwen-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ScoutQwen2",
            "openWeights": false,
            "provider": "Together AI",
            "providerDoc": "https://docs.together.ai/",
            "providerEnv": ["TOGETHER_API_KEY"],
            "providerId": "together-ai",
            "providerModelsDevId": "together-ai",
            "providerNpm": "@ai-sdk/together",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "together"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "together-and-llamarank",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "together-and-llamarank",
            "openWeights": true,
            "provider": "Together AI",
            "providerDoc": "https://docs.together.ai/",
            "providerEnv": ["TOGETHER_API_KEY"],
            "providerId": "together-ai",
            "providerModelsDevId": "together-ai",
            "providerNpm": "@ai-sdk/together",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "together"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "using-together-with-mastra",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "using-together-with-mastra",
            "openWeights": false,
            "provider": "Together AI",
            "providerDoc": "https://docs.together.ai/",
            "providerEnv": ["TOGETHER_API_KEY"],
            "providerId": "together-ai",
            "providerModelsDevId": "together-ai",
            "providerNpm": "@ai-sdk/together",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "together"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "using-together-with-vercels-ai-sdk",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "using-together-with-vercels-ai-sdk",
            "openWeights": false,
            "provider": "Together AI",
            "providerDoc": "https://docs.together.ai/",
            "providerEnv": ["TOGETHER_API_KEY"],
            "providerId": "together-ai",
            "providerModelsDevId": "together-ai",
            "providerNpm": "@ai-sdk/together",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "together"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "workflows-together",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "WorkflowsTogether",
            "openWeights": false,
            "provider": "Together AI",
            "providerDoc": "https://docs.together.ai/",
            "providerEnv": ["TOGETHER_API_KEY"],
            "providerId": "together-ai",
            "providerModelsDevId": "together-ai",
            "providerNpm": "@ai-sdk/together",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "together"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "solar-10.7b-v1.0 model from Upstage",
            "id": "solar-10-7b-v1-0",
            "knowledge": "Mar 2025",
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "solar-10.7b-v1.0",
            "openWeights": false,
            "provider": "Upstage",
            "providerDoc": "https://console.upstage.ai/docs/models/history#solar-107b-v10",
            "providerEnv": ["UPSTAGE_API_KEY"],
            "providerId": "upstage",
            "providerModelsDevId": "upstage",
            "providerNpm": "@ai-sdk/upstage",
            "reasoning": false,
            "releaseDate": "2025-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "upstage"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "solar-docvision-preview model from Upstage",
            "id": "solar-docvision-preview",
            "knowledge": "Mar 2025",
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "solar-docvision-preview",
            "openWeights": false,
            "provider": "Upstage",
            "providerDoc": "https://console.upstage.ai/docs/models/history#solar-docvision-preview",
            "providerEnv": ["UPSTAGE_API_KEY"],
            "providerId": "upstage",
            "providerModelsDevId": "upstage",
            "providerNpm": "@ai-sdk/upstage",
            "reasoning": false,
            "releaseDate": "2025-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "upstage"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "solar-embedding-1-large-passage beta model from Upstage",
            "id": "solar-embedding-1-large-passage-beta",
            "knowledge": "Mar 2025",
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "solar-embedding-1-large-passage beta",
            "openWeights": false,
            "provider": "Upstage",
            "providerDoc": "https://console.upstage.ai/docs/models/history#solar-embedding-1-large-passage-beta",
            "providerEnv": ["UPSTAGE_API_KEY"],
            "providerId": "upstage",
            "providerModelsDevId": "upstage",
            "providerNpm": "@ai-sdk/upstage",
            "reasoning": false,
            "releaseDate": "2025-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "upstage"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "solar-embedding-1-large-query beta model from Upstage",
            "id": "solar-embedding-1-large-query-beta",
            "knowledge": "Mar 2025",
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "solar-embedding-1-large-query beta",
            "openWeights": false,
            "provider": "Upstage",
            "providerDoc": "https://console.upstage.ai/docs/models/history#solar-embedding-1-large-query-beta",
            "providerEnv": ["UPSTAGE_API_KEY"],
            "providerId": "upstage",
            "providerModelsDevId": "upstage",
            "providerNpm": "@ai-sdk/upstage",
            "reasoning": false,
            "releaseDate": "2025-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "upstage"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "Solar LLM model from Upstage",
            "id": "solar-llm",
            "knowledge": "Mar 2025",
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Solar LLM",
            "openWeights": false,
            "provider": "Upstage",
            "providerDoc": "https://console.upstage.ai/docs/models/history#solar-llm",
            "providerEnv": ["UPSTAGE_API_KEY"],
            "providerId": "upstage",
            "providerModelsDevId": "upstage",
            "providerNpm": "@ai-sdk/upstage",
            "reasoning": false,
            "releaseDate": "2025-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "upstage"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "solar-mini-240612 model from Upstage",
            "id": "solar-mini-240612",
            "knowledge": "Mar 2025",
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "solar-mini-240612",
            "openWeights": false,
            "provider": "Upstage",
            "providerDoc": "https://console.upstage.ai/docs/models/history#solar-mini-240612",
            "providerEnv": ["UPSTAGE_API_KEY"],
            "providerId": "upstage",
            "providerModelsDevId": "upstage",
            "providerNpm": "@ai-sdk/upstage",
            "reasoning": false,
            "releaseDate": "2025-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "upstage"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "solar-mini-250123 model from Upstage",
            "id": "solar-mini-250123",
            "knowledge": "Mar 2025",
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "solar-mini-250123",
            "openWeights": false,
            "provider": "Upstage",
            "providerDoc": "https://console.upstage.ai/docs/models/history#solar-mini-250123",
            "providerEnv": ["UPSTAGE_API_KEY"],
            "providerId": "upstage",
            "providerModelsDevId": "upstage",
            "providerNpm": "@ai-sdk/upstage",
            "reasoning": false,
            "releaseDate": "2025-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "upstage"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "solar-mini-250422 model from Upstage",
            "id": "solar-mini-250422",
            "knowledge": "Mar 2025",
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "solar-mini-250422",
            "openWeights": false,
            "provider": "Upstage",
            "providerDoc": "https://console.upstage.ai/docs/models/history#solar-mini-250422",
            "providerEnv": ["UPSTAGE_API_KEY"],
            "providerId": "upstage",
            "providerModelsDevId": "upstage",
            "providerNpm": "@ai-sdk/upstage",
            "reasoning": false,
            "releaseDate": "2025-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "upstage"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "solar-mini-ja-240612 model from Upstage",
            "id": "solar-mini-ja-240612",
            "knowledge": "Mar 2025",
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "solar-mini-ja-240612",
            "openWeights": false,
            "provider": "Upstage",
            "providerDoc": "https://console.upstage.ai/docs/models/history#solar-mini-ja-240612",
            "providerEnv": ["UPSTAGE_API_KEY"],
            "providerId": "upstage",
            "providerModelsDevId": "upstage",
            "providerNpm": "@ai-sdk/upstage",
            "reasoning": false,
            "releaseDate": "2025-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "upstage"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "solar-mini-ja-250123 model from Upstage",
            "id": "solar-mini-ja-250123",
            "knowledge": "Mar 2025",
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "solar-mini-ja-250123",
            "openWeights": false,
            "provider": "Upstage",
            "providerDoc": "https://console.upstage.ai/docs/models/history#solar-mini-ja-250123",
            "providerEnv": ["UPSTAGE_API_KEY"],
            "providerId": "upstage",
            "providerModelsDevId": "upstage",
            "providerNpm": "@ai-sdk/upstage",
            "reasoning": false,
            "releaseDate": "2025-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "upstage"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "solar-pro-241126 model from Upstage",
            "id": "solar-pro-241126",
            "knowledge": "Mar 2025",
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "solar-pro-241126",
            "openWeights": false,
            "provider": "Upstage",
            "providerDoc": "https://console.upstage.ai/docs/models/history#solar-pro-241126",
            "providerEnv": ["UPSTAGE_API_KEY"],
            "providerId": "upstage",
            "providerModelsDevId": "upstage",
            "providerNpm": "@ai-sdk/upstage",
            "reasoning": true,
            "releaseDate": "2025-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "upstage"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "solar-pro-250422 model from Upstage",
            "id": "solar-pro-250422",
            "knowledge": "Mar 2025",
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "solar-pro-250422",
            "openWeights": false,
            "provider": "Upstage",
            "providerDoc": "https://console.upstage.ai/docs/models/history#solar-pro-250422",
            "providerEnv": ["UPSTAGE_API_KEY"],
            "providerId": "upstage",
            "providerModelsDevId": "upstage",
            "providerNpm": "@ai-sdk/upstage",
            "reasoning": true,
            "releaseDate": "2025-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "upstage"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "solar-pro2-250710 model from Upstage",
            "id": "solar-pro2-250710",
            "knowledge": "Mar 2025",
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "solar-pro2-250710",
            "openWeights": false,
            "provider": "Upstage",
            "providerDoc": "https://console.upstage.ai/docs/models/history#solar-pro2-250710",
            "providerEnv": ["UPSTAGE_API_KEY"],
            "providerId": "upstage",
            "providerModelsDevId": "upstage",
            "providerNpm": "@ai-sdk/upstage",
            "reasoning": true,
            "releaseDate": "2025-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "upstage"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "solar-pro2-250909 model from Upstage",
            "id": "solar-pro2-250909",
            "knowledge": "Mar 2025",
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "solar-pro2-250909",
            "openWeights": false,
            "provider": "Upstage",
            "providerDoc": "https://console.upstage.ai/docs/models/history#solar-pro2-250909",
            "providerEnv": ["UPSTAGE_API_KEY"],
            "providerId": "upstage",
            "providerModelsDevId": "upstage",
            "providerNpm": "@ai-sdk/upstage",
            "reasoning": true,
            "releaseDate": "2025-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "upstage"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "solar-pro2-251215 model from Upstage",
            "id": "solar-pro2-251215",
            "knowledge": "Mar 2025",
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "solar-pro2-251215",
            "openWeights": false,
            "provider": "Upstage",
            "providerDoc": "https://console.upstage.ai/docs/models/history#solar-pro2-251215",
            "providerEnv": ["UPSTAGE_API_KEY"],
            "providerId": "upstage",
            "providerModelsDevId": "upstage",
            "providerNpm": "@ai-sdk/upstage",
            "reasoning": true,
            "releaseDate": "2025-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "upstage"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "solar-pro2-preview model from Upstage",
            "id": "solar-pro2-preview",
            "knowledge": "Mar 2025",
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "solar-pro2-preview",
            "openWeights": false,
            "provider": "Upstage",
            "providerDoc": "https://console.upstage.ai/docs/models/history#solar-pro2-preview",
            "providerEnv": ["UPSTAGE_API_KEY"],
            "providerId": "upstage",
            "providerModelsDevId": "upstage",
            "providerNpm": "@ai-sdk/upstage",
            "reasoning": true,
            "releaseDate": "2025-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "upstage"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "description": "solar-pro-preview model from Upstage",
            "id": "solar-pro-preview",
            "knowledge": "Mar 2025",
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "solar-pro-preview",
            "openWeights": false,
            "provider": "Upstage",
            "providerDoc": "https://console.upstage.ai/docs/models/history#solar-pro-preview",
            "providerEnv": ["UPSTAGE_API_KEY"],
            "providerId": "upstage",
            "providerModelsDevId": "upstage",
            "providerNpm": "@ai-sdk/upstage",
            "reasoning": true,
            "releaseDate": "2025-12-15",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "upstage"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "4-nwqv-0-zkit-3-b-9-v-6-h",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "4nwqv0zkit3b9v6h",
            "openWeights": false,
            "provider": "V0",
            "providerDoc": "https://v0.dev/docs",
            "providerEnv": ["V0_API_KEY"],
            "providerId": "v0",
            "providerModelsDevId": "v0",
            "providerNpm": "@ai-sdk/v0",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "v0"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "5v0h3h13h14",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "5V0H3H13H14",
            "openWeights": false,
            "provider": "V0",
            "providerDoc": "https://v0.dev/docs",
            "providerEnv": ["V0_API_KEY"],
            "providerId": "v0",
            "providerModelsDevId": "v0",
            "providerNpm": "@ai-sdk/v0",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "v0"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "classic-v-0",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "classic-v0",
            "openWeights": false,
            "provider": "V0",
            "providerDoc": "https://v0.dev/docs",
            "providerEnv": ["V0_API_KEY"],
            "providerId": "v0",
            "providerModelsDevId": "v0",
            "providerNpm": "@ai-sdk/v0",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "v0"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "create-v-0-sdk-app",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "create-v0-sdk-app",
            "openWeights": false,
            "provider": "V0",
            "providerDoc": "https://v0.dev/docs",
            "providerEnv": ["V0_API_KEY"],
            "providerId": "v0",
            "providerModelsDevId": "v0",
            "providerNpm": "@ai-sdk/v0",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "v0"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "featuresv-0",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Featuresv0",
            "openWeights": false,
            "provider": "V0",
            "providerDoc": "https://v0.dev/docs",
            "providerEnv": ["V0_API_KEY"],
            "providerId": "v0",
            "providerModelsDevId": "v0",
            "providerNpm": "@ai-sdk/v0",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "v0"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "logo-particles-v-0-aws-ad-fq-yl-ef-vd-c",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "logo-particles-v0-aws-AdFqYlEFVdC",
            "openWeights": false,
            "provider": "V0",
            "providerDoc": "https://v0.dev/docs",
            "providerEnv": ["V0_API_KEY"],
            "providerId": "v0",
            "providerModelsDevId": "v0",
            "providerNpm": "@ai-sdk/v0",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "v0"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "pagev-0",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "pagev0",
            "openWeights": false,
            "provider": "V0",
            "providerDoc": "https://v0.dev/docs",
            "providerEnv": ["V0_API_KEY"],
            "providerId": "v0",
            "providerModelsDevId": "v0",
            "providerNpm": "@ai-sdk/v0",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "v0"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "product-home-enterprise-pricingv-0",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "ProductHomeEnterprisePricingv0",
            "openWeights": false,
            "provider": "V0",
            "providerDoc": "https://v0.dev/docs",
            "providerEnv": ["V0_API_KEY"],
            "providerId": "v0",
            "providerModelsDevId": "v0",
            "providerNpm": "@ai-sdk/v0",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "v0"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "what-can-you-do-with-v-0",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "what-can-you-do-with-v0",
            "openWeights": false,
            "provider": "V0",
            "providerDoc": "https://v0.dev/docs",
            "providerEnv": ["V0_API_KEY"],
            "providerId": "v0",
            "providerModelsDevId": "v0",
            "providerNpm": "@ai-sdk/v0",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "v0"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "what-makes-v-0-different",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "what-makes-v0-different",
            "openWeights": false,
            "provider": "V0",
            "providerDoc": "https://v0.dev/docs",
            "providerEnv": ["V0_API_KEY"],
            "providerId": "v0",
            "providerModelsDevId": "v0",
            "providerNpm": "@ai-sdk/v0",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "v0"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "who-is-v-0-for",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "who-is-v0-for",
            "openWeights": false,
            "provider": "V0",
            "providerDoc": "https://v0.dev/docs",
            "providerEnv": ["V0_API_KEY"],
            "providerId": "v0",
            "providerModelsDevId": "v0",
            "providerNpm": "@ai-sdk/v0",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "v0"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "why-should-i-choose-v-0",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "why-should-i-choose-v0",
            "openWeights": false,
            "provider": "V0",
            "providerDoc": "https://v0.dev/docs",
            "providerEnv": ["V0_API_KEY"],
            "providerId": "v0",
            "providerModelsDevId": "v0",
            "providerNpm": "@ai-sdk/v0",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "v0"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "about-venice",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "about-venice",
            "openWeights": false,
            "provider": "Venice",
            "providerDoc": "https://docs.venice.ai/",
            "providerEnv": ["VENICE_API_KEY"],
            "providerId": "venice",
            "providerModelsDevId": "venice",
            "providerNpm": "@ai-sdk/venice",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "venice"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "ask-venice",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "AskVenice",
            "openWeights": false,
            "provider": "Venice",
            "providerDoc": "https://docs.venice.ai/",
            "providerEnv": ["VENICE_API_KEY"],
            "providerId": "venice",
            "providerModelsDevId": "venice",
            "providerNpm": "@ai-sdk/venice",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "venice"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "askvenice",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "askvenice",
            "openWeights": false,
            "provider": "Venice",
            "providerDoc": "https://docs.venice.ai/",
            "providerEnv": ["VENICE_API_KEY"],
            "providerId": "venice",
            "providerModelsDevId": "venice",
            "providerNpm": "@ai-sdk/venice",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "venice"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "character-slug",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "character_slug",
            "openWeights": false,
            "provider": "Venice",
            "providerDoc": "https://docs.venice.ai/",
            "providerEnv": ["VENICE_API_KEY"],
            "providerId": "venice",
            "providerModelsDevId": "venice",
            "providerNpm": "@ai-sdk/venice",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "venice"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "disable-thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "disable_thinking",
            "openWeights": false,
            "provider": "Venice",
            "providerDoc": "https://docs.venice.ai/",
            "providerEnv": ["VENICE_API_KEY"],
            "providerId": "venice",
            "providerModelsDevId": "venice",
            "providerNpm": "@ai-sdk/venice",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "venice"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "enable-web-citations",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "enable_web_citations",
            "openWeights": false,
            "provider": "Venice",
            "providerDoc": "https://docs.venice.ai/",
            "providerEnv": ["VENICE_API_KEY"],
            "providerId": "venice",
            "providerModelsDevId": "venice",
            "providerNpm": "@ai-sdk/venice",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "venice"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "enable-web-scraping",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "enable_web_scraping",
            "openWeights": false,
            "provider": "Venice",
            "providerDoc": "https://docs.venice.ai/",
            "providerEnv": ["VENICE_API_KEY"],
            "providerId": "venice",
            "providerModelsDevId": "venice",
            "providerNpm": "@ai-sdk/venice",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "venice"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "enable-web-search",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "enable_web_search",
            "openWeights": false,
            "provider": "Venice",
            "providerDoc": "https://docs.venice.ai/",
            "providerEnv": ["VENICE_API_KEY"],
            "providerId": "venice",
            "providerModelsDevId": "venice",
            "providerNpm": "@ai-sdk/venice",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "venice"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "how-to-use-venice-api",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "how-to-use-venice-api",
            "openWeights": false,
            "provider": "Venice",
            "providerDoc": "https://docs.venice.ai/",
            "providerEnv": ["VENICE_API_KEY"],
            "providerId": "venice",
            "providerModelsDevId": "venice",
            "providerNpm": "@ai-sdk/venice",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "venice"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "include-venice-system-prompt",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "include_venice_system_prompt",
            "openWeights": false,
            "provider": "Venice",
            "providerDoc": "https://docs.venice.ai/",
            "providerEnv": ["VENICE_API_KEY"],
            "providerId": "venice",
            "providerModelsDevId": "venice",
            "providerNpm": "@ai-sdk/venice",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "venice"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "introducing-the-venice-token-vvv",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "introducing-the-venice-token-vvv",
            "openWeights": false,
            "provider": "Venice",
            "providerDoc": "https://docs.venice.ai/",
            "providerEnv": ["VENICE_API_KEY"],
            "providerId": "venice",
            "providerModelsDevId": "venice",
            "providerNpm": "@ai-sdk/venice",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "venice"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "page-venice",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "pageVenice",
            "openWeights": false,
            "provider": "Venice",
            "providerDoc": "https://docs.venice.ai/",
            "providerEnv": ["VENICE_API_KEY"],
            "providerId": "venice",
            "providerModelsDevId": "venice",
            "providerNpm": "@ai-sdk/venice",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "venice"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "strip-thinking-response",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "strip_thinking_response",
            "openWeights": false,
            "provider": "Venice",
            "providerDoc": "https://docs.venice.ai/",
            "providerEnv": ["VENICE_API_KEY"],
            "providerId": "venice",
            "providerModelsDevId": "venice",
            "providerNpm": "@ai-sdk/venice",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "venice"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "what-can-i-do-with-venice-api",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "what-can-i-do-with-venice-api",
            "openWeights": false,
            "provider": "Venice",
            "providerDoc": "https://docs.venice.ai/",
            "providerEnv": ["VENICE_API_KEY"],
            "providerId": "venice",
            "providerModelsDevId": "venice",
            "providerNpm": "@ai-sdk/venice",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "venice"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00005,
                "inputCacheHit": null,
                "output": 0.00022
            },
            "extendedThinking": false,
            "id": "alibaba/qwen-3-14b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-14B",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/alibaba",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "alibaba/qwen-3-235b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 235B A22B Instruct 2507",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/alibaba",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "alibaba/qwen3-235b-a22b-thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262114,
                "output": 262114
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 235B A22B Thinking 2507",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/alibaba",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00006,
                "inputCacheHit": null,
                "output": 0.00022
            },
            "extendedThinking": false,
            "id": "alibaba/qwen-3-30b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3-30B-A3B",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/alibaba",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "alibaba/qwen-3-32b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 40960,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen 3.32B",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/alibaba",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "alibaba/qwen3-coder",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 66536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 Coder 480B A35B Instruct",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/alibaba",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "alibaba/qwen3-coder-30b-a3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 160000,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen 3 Coder 30B A3B Instruct",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/alibaba",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "alibaba/qwen3-coder-plus",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1000000,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 Coder Plus",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/alibaba",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "alibaba/qwen3-embedding-0.6b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 Embedding 0.6B",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/alibaba",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "alibaba/qwen3-embedding-4b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 Embedding 4B",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/alibaba",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "alibaba/qwen3-embedding-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 Embedding 8B",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/alibaba",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "alibaba/qwen3-max",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 Max",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/alibaba",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "alibaba/qwen3-max-preview",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 Max Preview",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/alibaba",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "alibaba/qwen3-next-80b-a3b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 Next 80B A3B Instruct",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/alibaba",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "alibaba/qwen3-next-80b-a3b-thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 Next 80B A3B Thinking",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/alibaba",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "alibaba/qwen3-vl-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 129024
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 VL 235B A22B Instruct",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/alibaba",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "alibaba/qwen3-vl-thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 VL 235B A22B Thinking",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/alibaba",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "amazon/nova-2-lite",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1000000,
                "output": 1000000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nova 2 Lite",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/amazon",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "amazon/nova-lite",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 300000,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nova Lite",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/amazon",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "amazon/nova-micro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nova Micro",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/amazon",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "amazon/nova-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 300000,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nova Pro",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/amazon",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "amazon/titan-embed-text-v2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Titan Text Embeddings V2",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/amazon",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bfl/flux-kontext-max",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 512,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FLUX.1 Kontext Max",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/bfl",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bfl/flux-kontext-pro",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 512,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FLUX.1 Kontext Pro",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/bfl",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bfl/flux-pro-1.0-fill",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FLUX.1 Fill [pro]",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/bfl",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bfl/flux-pro-1.1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FLUX1.1 [pro]",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/bfl",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bfl/flux-pro-1.1-ultra",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "FLUX1.1 [pro] Ultra",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/bfl",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "bytedance/seed-1.6",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 32000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Seed 1.6",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/bytedance",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "cohere/embed-v4.0",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Embed v4.0",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/cohere",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-v3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek V3 0324",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/deepseek",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00023,
                "inputCacheHit": null,
                "output": 0.0009
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-v3.1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 163840,
                "output": 128000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek-V3.1",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/deepseek",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "deepseek/deepseek-v3.2-thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 64000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek V3.2 Thinking",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/deepseek",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-2.0-flash",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1000000,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemini 2.0 Flash",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/google",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-2.0-flash-lite",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1048576,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemini 2.0 Flash Lite",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/google",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-3-flash",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 1000000,
                "output": 64000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemini 3 Flash",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/google",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-3-pro-image",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Nano Banana Pro (Gemini 3 Pro Image)",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/google",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemini-embedding-001",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemini Embedding 001",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/google",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/gemma-2-9b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Gemma 2 9B IT",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/google",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/imagen-4.0-fast-generate-001",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 480,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Imagen 4 Fast",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/google",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/imagen-4.0-generate-001",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 480,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Imagen 4",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/google",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/imagen-4.0-ultra-generate-001",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 480,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Imagen 4 Ultra",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/google",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/text-embedding-005",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Text Embedding 005",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/google",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "google/text-multilingual-embedding-002",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Text Multilingual Embedding 002",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/google",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "inception/mercury-coder-small",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32000,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mercury Coder Small Beta",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/inception",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "kwaipilot/kat-coder-pro-v1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 32000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "KAT-Coder-Pro V1",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/kwaipilot",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "meituan/longcat-flash-thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "LongCat Flash Thinking",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/meituan",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta/llama-3.1-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.1 70B Instruct",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/meta",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta/llama-3.1-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.1 8B Instruct",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/meta",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta/llama-3.2-11b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.2 11B Vision Instruct",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/meta",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta/llama-3.2-1b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.2 1B Instruct",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/meta",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta/llama-3.2-3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.2 3B Instruct",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/meta",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta/llama-3.2-90b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.2 90B Vision Instruct",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/meta",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta/llama-3.3-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3.3 70B Instruct",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/meta",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta/llama-3-70b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3 70B Instruct",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/meta",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta/llama-3-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 3 8B Instruct",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/meta",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta/llama-4-maverick",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 4 Maverick 17B Instruct",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/meta",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "meta/llama-4-scout",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 8192
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Llama 4 Scout 17B Instruct",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/meta",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "minimax/minimax-m2.1-lightning",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 204800,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiniMax M2.1 Lightning",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/minimax",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.3,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "mistral/codestral",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Codestral",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/mistral",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.3,
                "inputCacheHit": null,
                "output": 0.9
            },
            "extendedThinking": false,
            "id": "mistral/codestral-embed",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Codestral Embed",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/mistral",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mistral/devstral-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 256000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Devstral 2",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/mistral",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mistral/devstral-small",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 64000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Devstral Small 1.1",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/mistral",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mistral/devstral-small-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 256000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Devstral Small 2",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/mistral",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mistral/magistral-medium",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 64000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Magistral Medium 2509",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/mistral",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mistral/magistral-small",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 64000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Magistral Small 2509",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/mistral",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mistral/ministral-14b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 256000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Ministral 14B",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/mistral",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mistral/ministral-3b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Ministral 3B",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/mistral",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mistral/ministral-8b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Ministral 8B",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/mistral",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral/mistral-embed",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Embed",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/mistral",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral/mistral-large",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32000,
                "output": 4000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Large",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/mistral",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral/mistral-large-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 256000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Large 3",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/mistral",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral/mistral-medium",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 64000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Medium 3.1",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/mistral",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral/mistral-nemo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 60288,
                "output": 16000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Nemo",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/mistral",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral/mistral-saba-24b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Saba 24B",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/mistral",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-14",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0003
            },
            "extendedThinking": false,
            "id": "mistral/mistral-small",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32000,
                "output": 4000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mistral Small",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/mistral",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mistral/mixtral-8x22b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": 2048
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Mixtral MoE 8x22B Instruct",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/mistral",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mistral/pixtral-12b",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Pixtral 12B 2409",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/mistral",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "mistral/pixtral-large",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 4000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Pixtral Large",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/mistral",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "moonshotai/kimi-k2-thinking-turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262114,
                "output": 262114
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kimi K2 Thinking Turbo",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/moonshotai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "moonshotai/kimi-k2-turbo",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Kimi K2 Turbo",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/moonshotai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00125,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "openai/gpt-5.1-instant",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 16384
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GPT-5.1 Instant",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/openai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "openai/gpt-5.1-thinking",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 400000,
                "output": 128000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GPT 5.1 Thinking",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/openai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00013,
                "inputCacheHit": null,
                "output": 0
            },
            "extendedThinking": false,
            "id": "openai/text-embedding-3-large",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "text-embedding-3-large",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/openai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00002,
                "inputCacheHit": null,
                "output": 0
            },
            "extendedThinking": false,
            "id": "openai/text-embedding-3-small",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "text-embedding-3-small",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/openai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0004,
                "inputCacheHit": null,
                "output": 0.0004
            },
            "extendedThinking": false,
            "id": "openai/text-embedding-ada-002",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "text-embedding-ada-002",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/openai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "stealth/sonoma-dusk-alpha",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2000000,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Sonoma Dusk Alpha",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/stealth",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "stealth/sonoma-sky-alpha",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2000000,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Sonoma Sky Alpha",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/stealth",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.003,
                "inputCacheHit": null,
                "output": 0.015
            },
            "extendedThinking": false,
            "id": "vercel/v0-1.0-md",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 32000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "v0-1.0-md",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.003,
                "inputCacheHit": null,
                "output": 0.015
            },
            "extendedThinking": false,
            "id": "vercel/v0-1.5-md",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "v0-1.5-md",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "voyage/voyage-3.5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "voyage-3.5",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/voyage",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "voyage/voyage-3.5-lite",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "voyage-3.5-lite",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/voyage",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "voyage/voyage-3-large",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "voyage-3-large",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/voyage",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "voyage/voyage-code-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "voyage-code-2",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/voyage",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "voyage/voyage-code-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "voyage-code-3",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/voyage",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "voyage/voyage-finance-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "voyage-finance-2",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/voyage",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "voyage/voyage-law-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "voyage-law-2",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/voyage",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "xai/grok-2",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 4000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Grok 2",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/xai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "xai/grok-2-vision",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": 32768
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Grok 2 Vision",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/xai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "xai/grok-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Grok 3 Beta",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/xai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "xai/grok-3-fast",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Grok 3 Fast Beta",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/xai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "xai/grok-3-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Grok 3 Mini Beta",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/xai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "xai/grok-3-mini-fast",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Grok 3 Mini Fast Beta",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/xai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "xai/grok-4",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 256000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Grok 4",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/xai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "xai/grok-4.1-fast-non-reasoning",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2000000,
                "output": 30000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Grok 4.1 Fast Non-Reasoning",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/xai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "xai/grok-4.1-fast-reasoning",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2000000,
                "output": 30000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Grok 4.1 Fast Reasoning",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/xai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "xai/grok-4-fast-non-reasoning",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2000000,
                "output": 256000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Grok 4 Fast Non-Reasoning",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/xai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "xai/grok-4-fast-reasoning",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 2000000,
                "output": 256000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Grok 4 Fast Reasoning",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/xai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "xai/grok-code-fast-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 256000,
                "output": 256000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Grok Code Fast 1",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/xai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "xiaomi/mimo-v2-flash",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": 32000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MiMo V2 Flash",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/xiaomi",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.0003,
                "inputCacheHit": null,
                "output": 0.0015
            },
            "extendedThinking": false,
            "id": "zai/glm-4.5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": 131072
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.5",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/zai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "zai/glm-4.5-air",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 96000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM 4.5 Air",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/zai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "zai/glm-4.5v",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": 66000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM 4.5V",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/zai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "zai/glm-4.6",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 200000,
                "output": 96000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM 4.6",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/zai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "zai/glm-4.6v",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 24000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.6V",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/zai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "zai/glm-4.6v-flash",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 128000,
                "output": 24000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM-4.6V-Flash",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/zai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "zai/glm-4.7",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 202752,
                "output": 120000
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "GLM 4.7",
            "openWeights": false,
            "provider": "Vercel",
            "providerDoc": "https://sdk.vercel.ai/docs",
            "providerEnv": ["VERCEL_AI_API_KEY"],
            "providerId": "vercel/zai",
            "providerModelsDevId": "vercel",
            "providerNpm": "@ai-sdk/vercel",
            "reasoning": false,
            "releaseDate": "2025-08-21",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "vercel"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000135,
                "inputCacheHit": null,
                "output": 0.0000054
            },
            "description": "Optimized for precise reasoning tasks including complex coding, math, and structured document analysis",
            "extendedThinking": false,
            "id": "deepseek-ai-deep-seek-r1-0528",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 164864,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek R1-0528",
            "openWeights": false,
            "provider": "Weights & Biases",
            "providerDoc": "https://docs.wandb.ai/guides/inference/models/",
            "providerEnv": ["WANDB_API_KEY"],
            "providerId": "weights-biases",
            "providerModelsDevId": "weights-biases",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-05-28",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "weights & biases"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000114,
                "inputCacheHit": null,
                "output": 0.00000275
            },
            "description": "Robust Mixture-of-Experts model tailored for high-complexity language processing and comprehensive document analysis",
            "extendedThinking": false,
            "id": "deepseek-ai-deep-seek-v3-0324",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 164864,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek V3-0324",
            "openWeights": false,
            "provider": "Weights & Biases",
            "providerDoc": "https://docs.wandb.ai/guides/inference/models/",
            "providerEnv": ["WANDB_API_KEY"],
            "providerId": "weights-biases",
            "providerModelsDevId": "weights-biases",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "weights & biases"
        },
        {
            "attachment": false,
            "cost": {
                "input": 5.5e-7,
                "inputCacheHit": null,
                "output": 0.00000165
            },
            "description": "A large hybrid model that supports both thinking and non-thinking modes via prompt templates",
            "extendedThinking": false,
            "id": "deepseek-ai-deep-seek-v3-1",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "DeepSeek V3.1",
            "openWeights": false,
            "provider": "Weights & Biases",
            "providerDoc": "https://docs.wandb.ai/guides/inference/models/",
            "providerEnv": ["WANDB_API_KEY"],
            "providerId": "weights-biases",
            "providerModelsDevId": "weights-biases",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "weights & biases"
        },
        {
            "attachment": false,
            "cost": {
                "input": 8e-7,
                "inputCacheHit": null,
                "output": 8e-7
            },
            "description": "Efficient conversational model optimized for responsive multilingual chatbot interactions",
            "extendedThinking": false,
            "id": "meta-llama-llama-3-1-70b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta Llama 3.1 70B",
            "openWeights": false,
            "provider": "Weights & Biases",
            "providerDoc": "https://docs.wandb.ai/guides/inference/models/",
            "providerEnv": ["WANDB_API_KEY"],
            "providerId": "weights-biases",
            "providerModelsDevId": "weights-biases",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "weights & biases"
        },
        {
            "attachment": false,
            "cost": {
                "input": 7.1e-7,
                "inputCacheHit": null,
                "output": 7.1e-7
            },
            "description": "Multilingual model excelling in conversational tasks, detailed instruction-following, and coding",
            "extendedThinking": false,
            "id": "meta-llama-llama-3-3-70b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta Llama 3.3 70B",
            "openWeights": false,
            "provider": "Weights & Biases",
            "providerDoc": "https://docs.wandb.ai/guides/inference/models/",
            "providerEnv": ["WANDB_API_KEY"],
            "providerId": "weights-biases",
            "providerModelsDevId": "weights-biases",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "weights & biases"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1.7e-7,
                "inputCacheHit": null,
                "output": 6.6e-7
            },
            "description": "Multi-modal model integrating text and image understanding, ideal for visual tasks and combined analysis",
            "extendedThinking": false,
            "id": "meta-llama-llama-4-scout-17b-16e-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 65536,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Meta Llama 4 Scout 17Bx16E",
            "openWeights": false,
            "provider": "Weights & Biases",
            "providerDoc": "https://docs.wandb.ai/guides/inference/models/",
            "providerEnv": ["WANDB_API_KEY"],
            "providerId": "weights-biases",
            "providerModelsDevId": "weights-biases",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "weights & biases"
        },
        {
            "attachment": false,
            "cost": {
                "input": 8e-8,
                "inputCacheHit": null,
                "output": 3.5e-7
            },
            "description": "Compact, efficient model ideal for fast responses in resource-constrained environments",
            "extendedThinking": false,
            "id": "microsoft-phi-4-mini-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Microsoft Phi 4 Mini 3.8B",
            "openWeights": false,
            "provider": "Weights & Biases",
            "providerDoc": "https://docs.wandb.ai/guides/inference/models/",
            "providerEnv": ["WANDB_API_KEY"],
            "providerId": "weights-biases",
            "providerModelsDevId": "weights-biases",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "weights & biases"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.00000135,
                "inputCacheHit": null,
                "output": 0.000004
            },
            "description": "Mixture-of-Experts model optimized for complex tool use, reasoning, and code synthesis",
            "extendedThinking": false,
            "id": "moonshotai-kimi-k2-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "MoonshotAI Kimi K2",
            "openWeights": false,
            "provider": "Weights & Biases",
            "providerDoc": "https://docs.wandb.ai/guides/inference/models/",
            "providerEnv": ["WANDB_API_KEY"],
            "providerId": "weights-biases",
            "providerModelsDevId": "weights-biases",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "weights & biases"
        },
        {
            "attachment": false,
            "cost": {
                "input": 5e-8,
                "inputCacheHit": null,
                "output": 2.2e-7
            },
            "description": "An efficient multilingual, dense, instruction-tuned model, optimized by OpenPipe for building agents with finetuning.",
            "extendedThinking": false,
            "id": "open-pipe-qwen-3-14b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 8192,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "OpenPipe Qwen3 14B Instruct",
            "openWeights": false,
            "provider": "Weights & Biases",
            "providerDoc": "https://docs.wandb.ai/guides/inference/models/",
            "providerEnv": ["WANDB_API_KEY"],
            "providerId": "weights-biases",
            "providerModelsDevId": "weights-biases",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "weights & biases"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": null,
                "output": 1e-7
            },
            "description": "Efficient multilingual, Mixture-of-Experts, instruction-tuned model, optimized for logical reasoning",
            "extendedThinking": false,
            "id": "qwen-qwen-3-235b-a22b-instruct-2507",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 268288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 235B A22B-2507",
            "openWeights": false,
            "provider": "Weights & Biases",
            "providerDoc": "https://docs.wandb.ai/guides/inference/models/",
            "providerEnv": ["WANDB_API_KEY"],
            "providerId": "weights-biases",
            "providerModelsDevId": "weights-biases",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "weights & biases"
        },
        {
            "attachment": false,
            "cost": {
                "input": 1e-7,
                "inputCacheHit": null,
                "output": 1e-7
            },
            "description": "High-performance Mixture-of-Experts model optimized for structured reasoning, math, and long-form generation",
            "extendedThinking": false,
            "id": "qwen-qwen-3-235b-a22b-thinking-2507",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 268288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 235B A22B Thinking-2507",
            "openWeights": false,
            "provider": "Weights & Biases",
            "providerDoc": "https://docs.wandb.ai/guides/inference/models/",
            "providerEnv": ["WANDB_API_KEY"],
            "providerId": "weights-biases",
            "providerModelsDevId": "weights-biases",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "weights & biases"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.000001,
                "inputCacheHit": null,
                "output": 0.0000015
            },
            "description": "Mixture-of-Experts model optimized for coding tasks such as function calling, tooling use, and long-context reasoning",
            "extendedThinking": false,
            "id": "qwen-qwen-3-coder-480b-a35b-instruct",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 268288,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Qwen3 Coder 480B A35B",
            "openWeights": false,
            "provider": "Weights & Biases",
            "providerDoc": "https://docs.wandb.ai/guides/inference/models/",
            "providerEnv": ["WANDB_API_KEY"],
            "providerId": "weights-biases",
            "providerModelsDevId": "weights-biases",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "weights & biases"
        },
        {
            "attachment": false,
            "cost": {
                "input": 5.5e-7,
                "inputCacheHit": null,
                "output": 0.000002
            },
            "description": "Mixture-of-Experts model with user-controllable thinking/non-thinking modes for reasoning, code, and agents",
            "extendedThinking": false,
            "id": "zai-org-glm-4-5",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 134144,
                "output": 65536
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "Z.AI GLM 4.5",
            "openWeights": false,
            "provider": "Weights & Biases",
            "providerDoc": "https://docs.wandb.ai/guides/inference/models/",
            "providerEnv": ["WANDB_API_KEY"],
            "providerId": "weights-biases",
            "providerModelsDevId": "weights-biases",
            "providerNpm": "@ai-sdk/openai-compatible",
            "reasoning": true,
            "releaseDate": "2025-07-25",
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "weights & biases"
        },
        {
            "attachment": false,
            "cost": {
                "input": null,
                "inputCacheHit": null,
                "output": null
            },
            "extendedThinking": false,
            "id": "grok-2-image-1212",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": null,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["image"]
            },
            "name": "grok-2-image-1212",
            "openWeights": false,
            "provider": "XAI",
            "providerDoc": "https://docs.x.ai/docs/models",
            "providerEnv": ["XAI_API_KEY"],
            "providerId": "xai",
            "providerModelsDevId": "xai",
            "providerNpm": "@ai-sdk/xai",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "xai"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.002,
                "inputCacheHit": null,
                "output": 0.01
            },
            "extendedThinking": false,
            "id": "grok-2-vision-1212",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 32768,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "grok-2-vision-1212",
            "openWeights": false,
            "provider": "XAI",
            "providerDoc": "https://docs.x.ai/docs/models",
            "providerEnv": ["XAI_API_KEY"],
            "providerId": "xai",
            "providerModelsDevId": "xai",
            "providerNpm": "@ai-sdk/xai",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": true,
            "icon": "xai"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.003,
                "inputCacheHit": null,
                "output": 0.015
            },
            "extendedThinking": false,
            "id": "grok-3",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "grok-3",
            "openWeights": false,
            "provider": "XAI",
            "providerDoc": "https://docs.x.ai/docs/models",
            "providerEnv": ["XAI_API_KEY"],
            "providerId": "xai",
            "providerModelsDevId": "xai",
            "providerNpm": "@ai-sdk/xai",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "xai"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.003,
                "inputCacheHit": null,
                "output": 0.015
            },
            "extendedThinking": false,
            "id": "grok-3-fast",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "grok-3-fast",
            "openWeights": false,
            "provider": "XAI",
            "providerDoc": "https://docs.x.ai/docs/models",
            "providerEnv": ["XAI_API_KEY"],
            "providerId": "xai",
            "providerModelsDevId": "xai",
            "providerNpm": "@ai-sdk/xai",
            "reasoning": false,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": false,
            "vision": false,
            "icon": "xai"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.003,
                "inputCacheHit": null,
                "output": 0.015
            },
            "extendedThinking": false,
            "id": "grok-3-mini",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "grok-3-mini",
            "openWeights": false,
            "provider": "XAI",
            "providerDoc": "https://docs.x.ai/docs/models",
            "providerEnv": ["XAI_API_KEY"],
            "providerId": "xai",
            "providerModelsDevId": "xai",
            "providerNpm": "@ai-sdk/xai",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "xai"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.003,
                "inputCacheHit": null,
                "output": 0.015
            },
            "extendedThinking": false,
            "id": "grok-3-mini-fast",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 131072,
                "output": null
            },
            "modalities": {
                "input": ["text"],
                "output": ["text"]
            },
            "name": "grok-3-mini-fast",
            "openWeights": false,
            "provider": "XAI",
            "providerDoc": "https://docs.x.ai/docs/models",
            "providerEnv": ["XAI_API_KEY"],
            "providerId": "xai",
            "providerModelsDevId": "xai",
            "providerNpm": "@ai-sdk/xai",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": false,
            "icon": "xai"
        },
        {
            "attachment": false,
            "cost": {
                "input": 0.003,
                "inputCacheHit": null,
                "output": 0.015
            },
            "extendedThinking": false,
            "id": "grok-4-0709",
            "knowledge": null,
            "lastUpdated": null,
            "limit": {
                "context": 262144,
                "output": null
            },
            "modalities": {
                "input": ["text", "image"],
                "output": ["text"]
            },
            "name": "grok-4-0709",
            "openWeights": false,
            "provider": "XAI",
            "providerDoc": "https://docs.x.ai/docs/models",
            "providerEnv": ["XAI_API_KEY"],
            "providerId": "xai",
            "providerModelsDevId": "xai",
            "providerNpm": "@ai-sdk/xai",
            "reasoning": true,
            "releaseDate": null,
            "streamingSupported": true,
            "temperature": true,
            "toolCall": true,
            "vision": true,
            "icon": "xai"
        }
    ]
}
